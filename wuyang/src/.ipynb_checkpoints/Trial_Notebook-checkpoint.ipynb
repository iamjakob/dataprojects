{
 "metadata": {
  "name": "",
  "signature": "sha256:3590dff353464ae4ec08a86fcaaade3ea1748e6a89db39ddf334beeb11bac5b9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Quandl\n",
      "import os.path as path\n",
      "import time\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import multiprocessing\n",
      "import sklearn as sk\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import ensemble\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import preprocessing\n",
      "from sklearn import utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# index_code = \"YAHOO/INDEX_NDX\"\n",
      "# fund_code = \"GOOG/NYSE_SQQQ\"\n",
      "# direction = -3\n",
      "index_code = \"YAHOO/INDEX_GSPC\"\n",
      "fund_code = \"GOOG/NYSEARCA_SSO\"\n",
      "direction = 2\n",
      "start_date = \"2005-01-01\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file fund_index_pair.py\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os.path as path\n",
      "import Quandl\n",
      "\n",
      "class fund_index_pair:    \n",
      "    def __init__(self, fund_code, index_code, direction=1, start_date=\"2005-01-01\"):\n",
      "        self.fund_code = fund_code\n",
      "        self.index_code = index_code\n",
      "        self.start_date = start_date\n",
      "        self.direction = direction\n",
      "        \n",
      "    def load(self):\n",
      "        # If this is the first time of getting the data, send queries to Quandl website and download data there.\n",
      "        #    Then, store the date in local directories as csv files\n",
      "        # If the data has already been downloaded, load the local csv.\n",
      "        fund_code = self.fund_code\n",
      "        index_code = self.index_code\n",
      "        start_date = self.start_date\n",
      "        fund_file_name = \"../data/\" + fund_code.replace(\"/\", \"_\") + \".csv\"\n",
      "        index_file_name = \"../data/\" + index_code.replace(\"/\", \"_\") + \".csv\"\n",
      "\n",
      "        if path.isfile(fund_file_name): # file exists at local\n",
      "            fund_data = pd.io.parsers.read_csv(fund_file_name, index_col=0) # the csv file has to be parsed to have date as index\n",
      "        else: # download from Quandl and save it to local as csv file\n",
      "            fund_data = Quandl.get(fund_code, trim_start=start_date, authtoken=\"XANwfFd9CmdoE3PdFzRg\")\n",
      "            fund_data.to_csv(fund_file_name)\n",
      "        if path.isfile(index_file_name):\n",
      "            index_data = pd.io.parsers.read_csv(index_file_name, index_col=0) # the csv file has to be parsed to have date as index\n",
      "        else:\n",
      "            index_data = Quandl.get(index_code, trim_start=start_date, authtoken=\"XANwfFd9CmdoE3PdFzRg\")\n",
      "            index_data.to_csv(index_file_name)\n",
      "\n",
      "        # rename columns so that the two dataframes don't share any common names\n",
      "        index_data.columns = map(''.join, zip([index_code+'_']*index_data.shape[1], list(index_data.columns))) # rename the columns with index_code as prefix\n",
      "        fund_data.columns = map(''.join, zip([fund_code+'_']*fund_data.shape[1], list(fund_data.columns))) # rename the columns with fund_code as prefix    \n",
      "        # join the two data frames by date\n",
      "        self.data = fund_data.join(index_data, how='inner')\n",
      "        if index_code+'_Adjusted Close' not in self.data.columns: # if no adjusted close, copy close to make name uniform across differnet data\n",
      "            self.data[index_code+'_Adjusted Close'] = self.data[index_code+'_Close']\n",
      "\n",
      "    # Remove Outliers\n",
      "    def remove_outliers_by_moving_average(self, window_size=3, threshold=0.3):\n",
      "        # This function returns the indexes of samples that moves far away (greater than a threshold)\n",
      "        # from the moving average of samples before it\n",
      "        # ser: series containing the data\n",
      "        # window_size: window size for moving average\n",
      "        # threshold: threshold to be considered large\n",
      "        # Note: the first window_size samples are simply considered normal\n",
      "        \n",
      "        target_series = self.data[self.index_code+'_Adjusted Close']\n",
      "\n",
      "        moving_avg = pd.rolling_mean(target_series, window=window_size)\n",
      "        outlier_index = target_series[np.abs(target_series/moving_avg - 1) > threshold].index\n",
      "\n",
      "        self.data = self.data.drop(outlier_index)\n",
      "        \n",
      "    def extend_data(self): \n",
      "        # expand the data with several differential values\n",
      "        # the difference of movement between index and fund is the target variable\n",
      "        # it could be further binarized depending on the application scenario\n",
      "        # these new columns are probably useful for predictions\n",
      "\n",
      "        # nan's are filled by interpolation.\n",
      "        self.data = self.data.interpolate()\n",
      "\n",
      "        # daily changes of fund close price and index adjusted close price\n",
      "        self.data['fund_daily_change'] = (self.data[self.fund_code+'_Close'] - self.data[self.fund_code+'_Close'].shift(1))/self.data[self.fund_code+'_Close'].shift(1).astype(float)   # daily change of fund close price\n",
      "        self.data['index_daily_change'] = (self.data[self.index_code+'_Adjusted Close'] - self.data[self.index_code+'_Adjusted Close'].shift(1))/self.data[self.index_code+'_Adjusted Close'].shift(1).astype(float)  # daily change of index adjusted close price\n",
      "        self.data['fund_innerDay_change'] = (self.data[self.fund_code+'_Close'] - self.data[self.fund_code+'_Open'])/self.data[self.fund_code+'_Open'].astype(float)   # daily change of fund close price\n",
      "        self.data['index_innerDay_change'] = (self.data[self.index_code+'_Adjusted Close'] - self.data[self.index_code+'_Open'])/self.data[self.index_code+'_Open'].astype(float)  # daily change of index adjusted close price\n",
      "                \n",
      "        # difference between fund's target from the its performance\n",
      "        self.data['diff_changes'] = self.data['fund_daily_change'] - self.data['index_daily_change']*self.direction;\n",
      "        \n",
      "        # measuring volatility by the difference between high and low over open price\n",
      "        self.data['fund_daily_volatility'] = (self.data[self.fund_code+'_High']-self.data[self.fund_code+'_Low'])/self.data[self.fund_code+'_Open'].astype(float)\n",
      "        self.data['index_daily_volatility'] = (self.data[self.index_code+'_High']-self.data[self.index_code+'_Low'])/self.data[self.index_code+'_Open'].astype(float)\n",
      "\n",
      "        # open price, since we try to predict the change of close price we could include the open price of that day as a signal\n",
      "        self.data['onDay_fund_openMove'] = (self.data[self.fund_code+'_Open'].shift(-1)-self.data[self.fund_code+'_Close'])/self.data[self.fund_code+'_Close'].astype(float)\n",
      "        self.data['onDay_index_openMove'] = (self.data[self.index_code+'_Open'].shift(-1)-self.data[self.index_code+'_Adjusted Close'])/self.data[self.index_code+'_Adjusted Close'].astype(float)\n",
      "\n",
      "        # absolute changes, maybe more useful\n",
      "        self.data['fund_abs_daily_change'] = self.data['fund_daily_change'].abs()\n",
      "        self.data['index_abs_daily_change'] = self.data['index_daily_change'].abs()\n",
      "        self.data['fund_abs_innerDay_change'] = self.data['fund_innerDay_change'].abs()\n",
      "        self.data['index_abs_innerDay_change'] = self.data['index_innerDay_change'].abs()\n",
      "        self.data['abs_diff_changes'] = self.data['diff_changes'].abs()\n",
      "        self.data['onDay_fund_abs_openMove'] = self.data['onDay_fund_openMove'].abs()\n",
      "        self.data['onDay_index_abs_openMove'] = self.data['onDay_index_openMove'].abs()\n",
      "    \n",
      "        # potential targets\n",
      "        self.data['next_day_diff'] = self.data['diff_changes'].shift(-1)\n",
      "        self.data['next_day_abs_diff'] = self.data['abs_diff_changes'].shift(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting fund_index_pair.py\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index = fund_index_pair(fund_code, index_code, start_date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "Index([u'GOOG/NYSEARCA_SSO_Open', u'GOOG/NYSEARCA_SSO_High', u'GOOG/NYSEARCA_SSO_Low', u'GOOG/NYSEARCA_SSO_Close', u'GOOG/NYSEARCA_SSO_Volume', u'YAHOO/INDEX_GSPC_Open', u'YAHOO/INDEX_GSPC_High', u'YAHOO/INDEX_GSPC_Low', u'YAHOO/INDEX_GSPC_Close', u'YAHOO/INDEX_GSPC_Volume', u'YAHOO/INDEX_GSPC_Adjusted Close'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Check sample data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fund_and_index.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            GOOG/NYSEARCA_SSO_Open  GOOG/NYSEARCA_SSO_High  \\\n",
        "Date                                                         \n",
        "2006-06-21                   70.88                   71.81   \n",
        "2006-06-22                   71.08                   71.08   \n",
        "2006-06-23                   70.32                   71.38   \n",
        "2006-06-26                   70.75                   71.17   \n",
        "2006-06-27                   71.37                   71.37   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low  GOOG/NYSEARCA_SSO_Close  \\\n",
        "Date                                                         \n",
        "2006-06-21                  70.82                    71.50   \n",
        "2006-06-22                  70.26                    70.74   \n",
        "2006-06-23                  70.13                    70.73   \n",
        "2006-06-26                  70.51                    71.14   \n",
        "2006-06-27                  69.88                    69.88   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume  YAHOO/INDEX_GSPC_Open  \\\n",
        "Date                                                          \n",
        "2006-06-21                    277300                1240.09   \n",
        "2006-06-22                    136600                1251.92   \n",
        "2006-06-23                     44600                1245.59   \n",
        "2006-06-26                     37700                1244.50   \n",
        "2006-06-27                    114700                1250.55   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High  YAHOO/INDEX_GSPC_Low  \\\n",
        "Date                                                      \n",
        "2006-06-21                1257.96               1240.09   \n",
        "2006-06-22                1251.92               1241.53   \n",
        "2006-06-23                1253.13               1241.43   \n",
        "2006-06-26                1250.92               1243.68   \n",
        "2006-06-27                1253.37               1238.94   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close  YAHOO/INDEX_GSPC_Volume  \\\n",
        "Date                                                          \n",
        "2006-06-21                 1252.20               2361230000   \n",
        "2006-06-22                 1245.60               2148180000   \n",
        "2006-06-23                 1244.50               2017270000   \n",
        "2006-06-26                 1250.56               1878580000   \n",
        "2006-06-27                 1239.20               2203130000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close  \n",
        "Date                                         \n",
        "2006-06-21                          1252.20  \n",
        "2006-06-22                          1245.60  \n",
        "2006-06-23                          1244.50  \n",
        "2006-06-26                          1250.56  \n",
        "2006-06-27                          1239.20  \n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fund_and_index.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            GOOG/NYSEARCA_SSO_Open  GOOG/NYSEARCA_SSO_High  \\\n",
        "Date                                                         \n",
        "2014-06-06                  113.88                  114.53   \n",
        "2014-06-09                  114.40                  115.28   \n",
        "2014-06-10                  114.42                  114.77   \n",
        "2014-06-11                  113.93                  114.17   \n",
        "2014-06-12                  113.62                  113.79   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low  GOOG/NYSEARCA_SSO_Close  \\\n",
        "Date                                                         \n",
        "2014-06-06                 113.79                   114.46   \n",
        "2014-06-09                 114.25                   114.71   \n",
        "2014-06-10                 113.94                   114.75   \n",
        "2014-06-11                 113.41                   113.95   \n",
        "2014-06-12                 111.81                   112.33   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume  YAHOO/INDEX_GSPC_Open  \\\n",
        "Date                                                          \n",
        "2014-06-06                   2702307                1942.41   \n",
        "2014-06-09                   2914509                1948.97   \n",
        "2014-06-10                   1916191                1950.34   \n",
        "2014-06-11                   3050908                1949.37   \n",
        "2014-06-12                   4473983                1943.35   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High  YAHOO/INDEX_GSPC_Low  \\\n",
        "Date                                                      \n",
        "2014-06-06                1949.44               1942.41   \n",
        "2014-06-09                1955.55               1947.16   \n",
        "2014-06-10                1950.86               1944.64   \n",
        "2014-06-11                1949.37               1940.08   \n",
        "2014-06-12                1943.35               1925.78   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close  YAHOO/INDEX_GSPC_Volume  \\\n",
        "Date                                                          \n",
        "2014-06-06                 1949.44               2864300000   \n",
        "2014-06-09                 1951.27               2812180000   \n",
        "2014-06-10                 1950.79               2702360000   \n",
        "2014-06-11                 1943.89               2710620000   \n",
        "2014-06-12                 1930.11               3040480000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close  \n",
        "Date                                         \n",
        "2014-06-06                          1949.44  \n",
        "2014-06-09                          1951.27  \n",
        "2014-06-10                          1950.79  \n",
        "2014-06-11                          1943.89  \n",
        "2014-06-12                          1930.11  \n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index[index_code+'_Adjusted Close'].plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEPCAYAAACneLThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXmYVMW1wH/ALKAswyarMKK4oAiKC+6jIqKJG0aFqBHF\nqM8YzWIUjE99iVFjYgJq0A83MCq4RAkmgILaioKQIKMgu7LNIIvI4iCy9vvj3KJu3+nuudPr7e7z\n+77+6lbdrfrMnXOrT506BxRFURRFURRFURRFURRFURRFURRFURRFURRFURRFURQPBwLvAZ8D84Fb\nnfZWwFRgCfA2UOY6ZziwFFgE9He19wHmOftGprXXiqIoii/aA72d7abAYuAI4GHgDqf9TuAhZ7sH\nUAkUA+XAMqCBs282cIKzPQkYkMZ+K4qiKAkwAeiHjNLbOW3tnTrIKP5O1/FTgL5AB2Chq30Q8GRa\ne6ooiqLQsB7HlgPHALMQBb/OaV+HVfgdgSrXOVVApyjt1U67oiiKkkb8KvmmwD+A24BvPfvCzkdR\nFEUJGEU+jilGFPzfEXMNyOi9PbAWMcWsd9qrkclaQ2dkBF/tbLvbq7036tixY3jNmjX16L6iKIoC\nfAEcEm1HXSP5BsAzwAJghKt9InCNs30NVvlPROztJcBBQHdkwnUtsBU40bnm1a5z9rFmzRrC4bB+\nwmHuvfferPchKB+VhcpCZRH/AxwcS4nXNZI/BbgK+AyY67QNR7xpXgGGAiuAy519C5z2BcBu4Gas\nKedmYAzQBPGumVLHvQuaFStWZLsLgUFlYVFZWFQW/qhLyX9I7NF+vxjtDzgfL3OAnj77pSiKoqSA\n+njXKBlkyJAh2e5CYFBZWFQWFpWFPxrUfUhGCTv2JUVRFMUnDRo0gBj6XEfyASUUCmW7C4FBZWFR\nWVgmTw5luws5gSp5RVFyjh074PzzYc6cbPck+Ki5RlGUnGP1aujSBV56CQYPznZvso+aaxRFySu+\n/lrKTZuy249cQJV8QFHbq0VlYVFZCKLkQ2zenO2eBB9V8oqi5Bz33w9du8JVV2W7J8FHbfKKouQc\nPXrAk0/C6adnuyfBIJ5NXpW8oig5xcaN0KYNrF8PbdtmuzfBQCdecxC1vVpUFhaVBaxcKeX8+aGs\n9iNXUCWvKErOsGwZvPAC9O8PDYJmhwgoQROTmmsURdnHnj0wfjxceaXUzzkHpk2T+gsvZLdvQULN\nNYqi5CSrV4sHzebNsHChKHiAkpLs9iuXUCUfUNT2alFZWApFFkuWwLx5sM7JJP3uu+JRYwiFCkcW\nyeIn/Z+iKEpGOewwKfs5WSsuvTRyf+/eme1PLqM2eUVRAke8SdUjjoAZM6CsLHP9CTrxbPI6klcU\nJVDs3Bl739KlcEjUdNVKLNQmH1DU3mhRWVgKQRYTJsRudyv4QpBFKtCRvKIoWeOZZ2DrVnj/fXjt\nNSgqkrZotGqV2b7lC2qTVxQla7ht78OHwx13QMuWtm30aLjnHli7Vrxtjjoq833MBdQmryhK4Ni7\nN7LeqBH87neyHQrJC6BvXzj8cAlEpiP5xFCbfEBRe6NFZWHJJ1msXx9Zb9JEgo+BKPXTT5dFT6Wl\n0uYe4UN+ySKd+FHyzwLrgHmuthOA2cBc4D/A8a59w4GlwCKgv6u9j3ONpcDIxLusKEo+sGaNxIQ3\nbNsmCv0HP4g04xgLbpMmme1fvuBHyT8HDPC0PQz8L3AMcI9TB+gBXOGUA4BRWDvRE8BQoLvz8V5T\ncVFRUZHtLgQGlYUln2RRXQ1HHgn33iv17dth7FhR8m6+/z76+fkki3TixyY/HSj3tH0FtHC2y4Bq\nZ/siYBywC1gBLANOBFYCzZDRP8DzwMXAlMS6rShKrrJrF1RVwV//Kj7x990HBxwAn30mC5369o08\n/pRTYOLErHQ1L0jUJj8MeARYBfwJMdEAdASqXMdVAZ2itFc77UoM1N5oUVlY8kEWJSXQrRu89x4c\n7xh699tPRvLffQf77x95fFERXHBB7evkgywyQaLeNc8AtwJvAJchdvtzUtGhIUOGUF5eDkBZWRm9\ne/fe97PM/FG1Xlh1Q1D6k816ZWVloPpT3/qkSQBSh5AzqVpBkybw5ZchvvkG9t/f3/UqKyuz/n2y\nVQ+FQowZMwZgn76MhV8/+XLgTaCnU98KNHddYzNivhnmtD3klFOAexFzzXvAEU77YOAM4CbPfdRP\nXlHyGG9MmnHjYNAgeO45uO46aduyBZo3r32uEpt0xJNfhihpgLOAJc72RGAQUAIchEywzgbWIi+G\nE52OXA3EWLysKEqhsHq1lKtW2bamTbPTl3zFj5IfB8wADgNWA9cCNyAeNZXA/U4dYAHwilNOBm4G\nzND8ZuBpxIVyGTrpGhevqaKQUVlYcl0WJvH22LFSGrfI00+3xzT0OfTMdVlkCj82+cEx2k+M0f6A\n8/EyB2vuURSlgNiwAd54Q8qFC8WbZr/94CbHYHvmmdntXz6jsWsURUk7v/qVuEyCKPo2bWof07Mn\nzJ9vFz8p/tEcr4qiZJUdO+x2NAUPsHt3ZvpSaKiSDyhqb7SoLCy5KotRo+o+ZtGi+l0zV2WRaVTJ\nK4qSVnbtynYPChu1ySuKklY+/hhOOkncJTduhF69oh/XvLkk6P7gg8z2Lx/QePKKomSNjRvhvPOg\nc2f5xGLFCgl5oKQWNdcEFLU3WlQWllySRU2NlJs3144FH41Wreq3ECqXZJFNVMkripJyFiyAZs1k\n+9tv7baSedQmryhKyvnvfyXC5Hffwd/+Jjla//znbPcqf1E/eUVR0sqnn8I779j6d99JuWED/OY3\nkgVKyQ6q5AOK2hstKgtLUGXxox9Bv362vm2blBs2SPnvf6f+nkGVRdBQJa8oSlIsWQJ798r2N99I\nuW6dlMcdJ2Ust0kl/ahNXlGUpPDGiA+HYfBgGD/etlVVQSfNBZc21CavKEpa8CbZPvlkKcePhxYt\nbHurVpnrkxKJKvmAovZGi8rCEjRZmGxOM2ZIlqf27W0USfdEbOPGqb930GQRVFTJK4rii3AYtm6N\nbDOLl046CVq3ltR927ZJrPg+feAGJ52Q16SjZA5V8gHFJO9VVBZusimLM8+MNMGAZHYyceJbtBBX\nyS+/tMd1756+/uhz4Q9V8oqi+OL996X8/HPbtmULlJXJdvPmkvWpVy+r5Is0OlbWUSUfUNTeaFFZ\nWIIgi6OOgspKMctUVVmFbpQ9WDNOOl0ngyCLXECVvKIo9eaYY+DhhyVGzRFHSFvr1nb/hRdKeeaZ\n1odeyQ6q5AOK2hstKgtLtmQRDksY4OHDbdvu3RJ8rGNHqRcX233uFH/pmnTV58IfquQVRamTBQtg\n50748EPb1rCh+Mm7I0zOni2lWfmqZB9V8gFF7Y0WlYUlW7I46igpL77Ytm3bJnZ490jdKPyhQ9Pf\nJ30u/OFHyT8LrAPmedp/DiwE5gN/dLUPB5YCi4D+rvY+zjWWAiMT7K+iKFnghBPgrLPg5z+3bZs2\n1V7JevjhYtpp3z6z/VNi48dadhpQAzwP9HTazgTuAs4HdgFtgQ1AD+Al4HigEzAN6A6EgdnALU45\nCXgUmOK5l8auUZQA0q+fhAw+91w7ci8tFXv8l19mt29K8rFrpgObPG3/AzyIKHgQBQ9wETDOaV8B\nLANOBDoAzRAFD/LCcP3wUxQlyHz9NbRtG9m2YwcsX56d/ij+SdQm3x04HfgYCAFOQFE6AlWu46qQ\nEb23vdppV2Kg9kaLysKSLVl88411kZw8WbI9Adx/f1a6A+hz4ZdE16MVAS2Bvohp5hWgWyo6NGTI\nEMrLywEoKyujd+/e+1ylzB9V64VVNwSlP9msV1ZWZvR+e/dCixYVrF4Nn38eYvlyGDCgguefBwg5\nE7LZkUdlZWVG7xekeigUYsyYMQD79GUs/HqwlgNvYm3yk4GHAGehM8sQhX+9U3/IKacA9wIrgfcA\nZ9kEg4EzgJs891GbvKIEhB07JHrkoEESOnjvXmuPf+01uOwy2LVLQxcEgXTEk58AnOVsHwqUAF8D\nE4FBTv0gxKwzG1gLbEXs8w2Aq51rKIoSUNavl9Ik/3C7SpqxmCr44ONHyY8DZiDKfDVwLeJW2Q1x\niRwH/MQ5dgFiulmAjPZvRjxrcLafRlwol1Hbs0Zx4TVVFDIqC0smZWHys0Zj167Y+zKFPhf+8PMe\nHhyj/eoY7Q84Hy9zsOYeRVECTDgMo0fb+s6dkfu9njZKcAlaKP+cscl/841koL861qtOUXKUDRvg\n0UcjPWei/Vtu3SrhhZXsE88mrxa1BHnqKRg2TFb4HX98tnujKKnjiCNg48a6j1MFnxto7JoYLF4M\nxx5bO92ZYdgwKaur03N/tTdaVBaWdMti925/Cj4I6HPhD1XyMbjjDpg7Fz77rPa+PXvs9qpVmr9S\nyR9WrbLbP/tZ9vqhpA5V8g67dsG779p6N2dp18sv1z7222/t9m23pac/ZgGEorJwk25ZzJwJF1wA\nf/87jBgBt9+e1tslhT4X/lAl7/CPf8DZZ8voZeVKWLRI2p95pvaxxoRz2WWZ65+ipJvvv4d58+Ck\nk+Cqq8QH/sEHJY+rkruokkdW8r3zjmyPGiUjmCmOF7+xvRu++Qa6dpXtm7zrdVOI2hstKgtLOmXR\npAm89ZbN2Qqi6IM6warPhT9UySPuYk8/besjRthtr719zRq77U53VlWFouQsmzdLuXBh7RjxSm4T\ntCnDjPvJ79ghLpDzvClRXLi7tGABHHkk3HMPnHee/LQFseF/8YXYMrdtS+8oX1FSyY4dMnrfsUPq\nH38MJ56Y3T4p9SOen3zBK3k/njHuLn3yiaQ2++QT+RznBFkuKZF/EnO9HFnTpSiccAL85z+2rkHH\nco90BCjLOy65JLJ+7rnw9tsyGevm++/FdtmgAWzfbtu9y76TRe2NFpWFJR2ycCt4yB0Fr8+FPwpa\nyU+bZrdfeily3zPPSJjVHTugSxfrG799u7SDrHb98Y9hwIBI88xhh0HfvjqaV4LP11/b7UsvzV4/\nlPRR0Er+nHPstlHchg4dJIdlTQ2sXi0/YefMgc8/t8e2aQMvvghnnBHpgbB4McyaJaP+RFEfYIvK\nwpJqWfzrX3DMMeJC3CnHcrXpc+GPHPlhlno2ubLWGj/gL7+Ezp2t10xpqbhMgih5Y3/3upQVF8tS\n8L17I9u/+05MO4oSVJYtg4sugoEDJSl3qs2OSvYp2JH8ggVSjhxplfZBB0W6RZaW2pfB44/bdm88\nm+JiMe/ccENku9fWWR/U3mhRWVhSLYsVK8Bkj+vbF554IqWXTyv6XPijYJW85KiEW2+NfUzjxjaE\nwQsv2PZ77ok8rn17Kd9/P7J99erk+qgo6WTePDE3mhAeSn5SsC6U554rynns2NjHfPWV/ISN1m4U\nO8BHH8Gpp4ppxu1xM2oU/M//pK7PiuKHyy+HJ5+se1GTcffdswcaFuxwLz8oaBfKcFgCLs2fH9m+\ne7fE54hHrAff+8/TtKmUbgUPYpNXlEzz6qtw4IGixBs0kMVNXpYvl7JTJ1Xw+U7e/3lDIfEgcIcq\nAIkDH22U7qZdu+jtbrs9QLNmdvtvf7PbySh5tTdaVBaWumRhXH3dz96sWbWPM55fr76amn5lA30u\n/JHXSn7mTDjrLNk2IxeQ4GOLF/tzGfMuhnr++dqrZM1IHmTlqyk/+aT+fVaUZKipgf32i2zbf//I\n+qxZcP31cPTRNiyHkr/krZJfuxauuMLWTVyOmhp4+GHZdkfbi4U3K320nK7uf6I9e+TXwxNPJOeO\npj7AFpWFpS5ZLF1ae8Wq17X3rrtgxgzxHstl9LnwR94q+WHDIr1bdu+WslkzeO89scfXN25NLNwj\np61bZXFUhw61/7kUJd0cf3xtF98PPoist20rZTKL9ZTcIa+U/IIFkslm3DjrNXPPPeL+uHu3Hc0D\n/O//+rvmiy/CySfLtjt7vZsGDaz7pNtcU9+R/DvvyC8NUHujG5WFxa8spk2zuRBefNHOL4XDNttZ\nruRyjYU+F/7wo+SfBdYB0YLx/hrYC7j9TYYDS4FFQH9Xex/nGkuBkYl0ti769IFHHpF4Moa+feGo\no8Ts4k7bd8AB/q554IE27Opvfxv7OHM981O5pETMNmvX+rvP5s3Qrx9MmuTveCV/2bGj/msszPN9\nwQUwfrzMJT3wADz1lOxfv15K90pvs5pbyW/8KPnngAFR2g8EzgFWutp6AFc45QBgFNZ38wlgKNDd\n+US7ZsJ4Y8WcdppkuTnrLFG8u3dHKvmyMv/XbtSo7mPM9cyx27eLuaZDh7rP3b4dWraUbfNrQ+2N\nlkKTRePGEhQvGrFkMWyYrNzevt26+DZoAN2722O+/x5at46s5zKF9lwkih8lPx3YFKX9L8AdnraL\ngHHALmAFsAw4EegANANmO8c9D1xc/+5GZ8uWyGBjAMceC/37y+RSUZGYcubMkVF9fddbGXt+PMzi\nKDOSd/8z1cWYMXZ7UzRJKwWDNzF8TU3tyf9oVFZKOW1adG8vgLvvTr5/Su6RqE3+IqAK+MzT3tFp\nN1QBnaK0VzvtKaGsTEbpp58uCnztWvjrX+1+4zt82WXW5l0fhgyB3/++7uP+9Ccbl/7YY/1f3716\n9p//lBGY2hsthSSLRx+NrDdrBj/6ka1Hk8UHH8C770aeYzjxRPj3v8Wc+Mgj0jZ/vvyv5DqF9Fwk\nQyJRKPcD7kJMNYaUhUcYMmQI5U7EpLKyMnr37r3vZ5n5o7rr1dUAUu/bN0QoRK3jDzuswrl6yFH4\nsa8Xq96rV93HH3dciHnzpC6eO7L/gw8q6NYNli2Lfv7AgbZ/8s9a//7lc90QlP6kqz5pkvm+Un/t\nNanPmWOPr6ysrHX+P/5RwV13wddfh5g4EY48MnL/qadWOKuxpX7kkRW8/jpMmRL9/yVX6pXOz5eg\n9CeT9VAoxBjHBGD0ZbKUYydeeyITscudjzHNtAOGOR/DFMRc0x5Y6GofDDwZ5T5hv+zaFQ6/+qp8\nZPwubbEwx9TjFkkD4XC3blKed170Y8aPj+xbpvuoBIePP5a/fZcu4XCHDvZZuOqq+OedfXY4PGlS\n7P07doTDxcXh8BlnhMNTp6a0y0pAAGIaoRMx18xzFPpBzqcKONZR/BOBQUCJs687YodfC2x1FH4D\n4GpgQgL33seMGWJ+uewy2xa0tGWjRtlVtbt3i/+ye/IXYNAgu63BzAqb3bvFXXflSgmCZ9i2LfY5\nf/2ruN66TX5eiovFrv/BBzYnglI4+FHy44AZwKHAauBaz373G2QB8IpTTgZudu2/GXgacaFchozy\nE2bZMrt9663w2GP+zstkvOw+fawHw969otBjhXUNhyP/Ab2mikKmEGQRDosbrTdDGUQGvjOy2LlT\njr/zTmmPl5zGnVy+Pl5lQacQnotU4GfsO7iO/V619YDz8TIHMfUkzd694gtsGDGi7tWrV14p6fq8\niT3SSWmpdYls1Ag++8zm1Ny4UfrTsiWccIK0XXKJZKf6wx8y10clGBx/vHh//eAHtffNnFm7rbRU\nPLiM5020l4ObXr3g00+T76eiJIsv+5OxwzdqFGz79aJF4fChh0a3t48aZeuvv27P2bkz2N+pUFi8\nWD6ZYM8e+yzcfru0mXqnTlLu3Rt5jveZWrky/j1uuEGfq3yGFNvks86mTbLgY/16+PDDbPcmNo0b\nx17x6g5jfPDBdtvMK3TunL5+KXVTUQGHHQZr1qT/XiZLGUSuxL7wQqhyHI/nOW4Pe/bYVayGm26K\nvXjK4CdOk5Kf5JyS37RJTC5HHy2K/pRTst2j2DRuXDtYFIi56dJLbd0dxdL8M1ZXh9Lat1wiG7ZX\nM/HpNZ8sXgwDUrhWe9s2uPZam7jD+LgvXRqZtcz4uL/+eqiWydGE3YiHn7DauYba5P2Rc0p+xQop\nr7suq93wRSw7qXd0Hyvka4YyIRY00V7CbiorJZ6Qif0SCkm4jGnTantKJYKJh9SmjZRGyR9yiJ0k\nve8+O1KPtpjPz3Py29/Chg1JdVXJUXJOyb/4ogQdixbXPWhEU97NmtVOExhdyVdosDIHsxgk1Wzf\nLjkFvKEkvErzBz+wUUvNytJzzok0syTKf/4j5YMPSp7g006rfUzr1jZi5P77V9Ta7yfaacOG9kWS\nL6Trucg3ckrJ19TIz9ZoOSuDiFd5z5olo7/p0yPbvSN+40rpJzCakjhvvy3lggVShsMygr7W6ySM\n/VvOmGHbqqpqH1dfmjaFyZPll+n06dFt661bi1fWv/5VOzzwHXfAeecl3w8lf8kpJW/S6eVKXkrv\nZNfhh0vpVSLugFIgo7vjjgulrV+5Rrpsrxc7IfJOPVUU7Pjx8MUXMlo/7TQJfGcwWcTcaxniLVLy\nQ2UlLFpUOz2fl3btJF/BBRfA6NGhfe1btsAf/1j3pGu+ojZ5f+SMkt+7VzIuQWTAplzg17+GqVMl\nFKw7eFTLljJCi+b5sHixjtDSiTfJ+s9+Zkfmq1dL9MbmzWH0aGkzIaPdNvFk50yOOQZWrYK6Qo90\n6WLnBEy0SZD+KUpd5ISSD4fhV7/Kdi8Sp7hYEoJA5Kj98MNjhyT+9tuKtPcrV0iH7XXlysj6vHnw\n5pvWW+udd6Q0yt28FNwTtcnEY3e/ZOryfIlcpVoBBC+ERzZQm7w/ckLJf/45jBwJ558vP29zjaOO\nstvuGCNT4gR2eOONyNyxkFiYZCU6o0eLG66b6dNtWGrjr/7DH0p8GPPcbd5sj09GyS9dKuVll1n3\nyVh4R+wPPaSrVxX/BF7Jv/469HSCIRxwgCxQySXCYQmpYDBJlCH+z+3160O1vmuzZuIGN2tWavsY\ndNJhex0xQkbz7rwDnTuL99bQofCb39j2bt1g3TrZ3rRJAs+Z7UTZsAHOPBNeeaXuY0tK3LUQd9wB\nPXokfu98QW3y/gj8jz73oiGTIi+XifyHjU1RUaRrnNk2I0z1oU+McFiSu4Mo2P795dfV4MFik+/Y\nEZ5+OvKcdu1kbcPLL4tyvu46WRF74YWJ9+OppxL7Zdamja5eVXKbWjEZWreWmBv33BMOV1VlIShE\nihk4UL7PpZfGP87EvTF89JHGm08Fa9ZYGX74obRt3x5frsuX15b9tm3hcGmpxJ1JhPr+HSdNkuM7\nd07sfkp+Q5zYNYEbydfU2MnJbdvEP7mqKn+WZZuRvIlOGYviYliyRFZWNmokCcmV5PnFL+y2Cc9r\n1imcdFL0c9xxhgz77Sfnb95sE2d7ufFGOPJICYXtxkzeusNl14XxtKrLfq8oXgL3yDRrJu5it98u\nyn7NmvyKgW2UfF0/uZcuDQESnjiagve6AOYzqbK97tplvWag9pxIcXH082LFam/cOP7LevRoScxt\nQnEYTEgOd2A6P3TrBt27h+p3Uh6jNnl/BG4kD7VHTl4vk1zmvPNkObzX7uultFSU0K9/HX3//Pk2\nDr3ij7FjZcXonXeKq6RXycZS8rEoKan7FxnI33yhK/llkyZw1131uxfIhPucOfU/TylsAjeSj0Y+\nTTQNGiTWWHdI2WhUVFTEDZ7lJ/JgvpAqf2gjz5//XFaPep+reErehPe97TbbVlrqL26Mcb/cvVtc\nH194QZJ41Jc2beDccyvqf2Keon7y/gicknfbN7/4wt9IqVAwLwhDIZlskmX+fPlVNHBg7PmdeAuM\nrrtO3ChHjLBtS5f6Tye5dau8RP7+d6mbwGSKkm4CreS7dfPvcphvhEKhCPdRqP3CqyvmSb6QCtvr\n5MlSPvRQ9P1vvAF/+Uvs8xs2jP7ryx3fxo030uibb0pp4sInuoJb7dAWlYU/Aqfk6+NxkO+4F+oA\n/PjH2elHPlBdLeF8u3ePvv/ii2Pvi8WVV8qCpmh4feB/97vIunvls6Kkk6BZu8Nud89CX/ATDke6\nzBl5uG3JhS4jP8ybJyEMPv44tXMZQ4bIoqghQ2rvW7kyMvBY+/Y2WczTT8uqWkVJFQ1EKUTV54Eb\nyS9fLuWf/5zdfgSBfJpwziYmBnyqQwE0aiSTqdHwhiF2myHdoS0UJd0ETsmXl8uEYizXwULBbW9s\n2zYy1dywYZnvTzZJxPY6d65M3IPkH3jsscgwz6mgqMgGNPMyYUJkfcsW+5JJZp5J7dAWlYU//Cj5\nZ4F1wDxX25+AhcCnwOtAC9e+4cBSYBHQ39Xex7nGUmBkvBvGWnxSqOzaFRmiONfi6deHVHlTHXus\nZHmqqpIFUOnwtnOP5L1B40zuVpC/15YtcNBBUtcwwUom8aPknwO8+enfBo4EegFLEMUO0AO4wikH\nAKOwdqIngKFAd+eTwpz3+YfxAe7YEQ48MHJfnz52+8svM9endLNxo6wi9a4QTcYfev16Sc7hDvec\nKsxIvqZG8g4PHVr7F+g110hWqZoaO7/iDldcX9Q33KKy8IcfJT8d8AZVnQrsdbZnAZ2d7YuAccAu\nYAWwDDgR6AA0A2Y7xz0PXJxopwuJ+fNr54R1MyCPXpUm0fRbbyV/LaPUa2rSt2K6USP5lWViuz/7\nrPjRu+30Y8bYtI9mhbKu/VAySSps8tcBk5ztjoA7vXEV0ClKe7XTrsTA2BtbtrT5RaORj6atm26K\nrCdiezWKffr09K0nKCqSGEtXXWXb9u61CUGuuUZKMxfQvbuksEzGw0ft0BaVhT+StQ7+FtgJvJSC\nvgAwZMgQyh3fs7KyMnr37r3vZ5n5o2pd6hByRo3B6E8y9W++ke8jRO431Od6GzfK9e6+G1q2TE//\na2qkvmJFhekhAF99JfWLLw4RCkHTplJftCjEfffBIYckfv/KyspA/L2CUK90Et4GpT+ZrIdCIcaM\nGQOwT18mSzmRE68AQ4CPgMautmHOxzAFMde0RyZqDYOBJ6PcJ9thmXMGE4/8zDOz3ZPU8MMfpi5e\n/o4dEus93fH3n3km8h7m8/TT4fCPf2yPmzBB2mfPTk8/FIU48eQTNdcMAH6D2ODdmS4nAoOAEuAg\nZIJ1NrAW2Ooo/AbA1YDHyUypDyWOG16KXuJZ51//Ss117r5bAodlwu7dMMZ/j9cbymzHS/eoKOnC\nj5IfB8yioDSuAAAXLElEQVQADgNWIzb4x4CmyATsXMSLBmAB8IpTTgZuxr5hbgaeRlwolyGjfCUG\nXlNFLIxbXi5T5czWTJ0q3jAgitLgVxYAf/iDlJMnw2mnyXaseDXJ0qhR9PblyyN94Y2Sd7clSn1k\nke+oLPzhxyY/OErbs3GOf8D5eJkD9PTTKcU/e/fWfUzQMS6iZ5xhw/2Wl0u8mfrgDvEwYACcfbaM\ntmMp42Qxq7O9PPww/PKXtp5KJa8o9SVoC+cd85JSFyUldrSbyyJ76im44QbZ9sbmqe/3mj8fevZM\n7NxEuOEGG2feS48e8Pnnsm3i2GzYYN1EFSWV5FTsGsUfuazY3UxxjHap+EViFHyseDKpJt4vhAUL\n7LZR7KWl6e2PokRDlXxAqcveOHVqZvqRSqZNqx1n/dtvZTQcLRibUdZ+bK/btsmq0xEj0mee8eKe\neH3ssch9l1xit/ffX+YdUhE7R+3QFpWFP1TJ5ygVFbVz4QaZ22+Hc86Bxx+3bdu3y8uqf//o59Rn\n+X/TphJK2BsCIp24lfzJJ0cGkbvllshjY2WjUpR0o0o+oNgFT7HJ1Ig1FZiMSO5MSm+9BYceCl26\nRD/HKPm6ZGFWmALOoqrM4A401rhx5MRqukIp+HkuCgWVhT9UyecwuRLN0D1/4I6r/t//SrTIWGzy\nRkyKgYndXlSU2Vg+7pds48aRicDTpeQVpb6okg8ofuyNuaLkf/ITKW+8MTLWTk2NDdoVDaPkvbIY\nPlxs+Gay1ozk77oLOncmY7jNNY0bR84rpEvJqx3aorLwhyr5HCZXzDUvvCBls2aRduvq6siRvRdj\neqmpifS+MYubzMKpyy+X8tprU9Nfv5iRe69e9nssWSKljuSVoKBKPqDUxyYfRHfKnTvFO8a7KMid\n4Prdd+GUU2JfY9UqOf6CCyp47jlpcyfnMDb7oiKJQZ/pEA933CH5WisrZSQP1k1SbfLpR2XhD1Xy\neUCsFHTZ4tVXRdkVF4tLI8iovEkT60LZu7e0HXxw7fOvvx4OOEAU/IYN0mZG7a+8Yo+rqZFUkbt3\nZ9ZMY2jRonZCbqPk8zEEtJKbqJIPKH7sjS+/LOXOnenti1/My2bOnNr7WrYUxffnP8vkqEm0Ec0/\n/qmn4Lbb4Pe/h27dAEL7Ru1lZVLut59MuJosWUExXZl+pCuEgdqhLSoLf6iSz2GOPlrs3O5gXtli\n9Ggxm2zfDn/8Y+Q+E33RCf+9L/NThw6xr+f2VAExzTz+ONxzD5x3niTeGDsWFi1KTf9TRYsW0r9o\nLy9FyQaq5AOKX3tjcXEwlPyTTnaAQYMi23/4Q1i9WrZ79bLtDRvCjBmxrxf566SCzZvhL3+R2nnn\nwWefwXPPQevWyfY8tRQXw6RJdR+XKGqHtqgs/KFKPscJipI//3wpP/pIynnzZEL4zTftSP7WW+3x\np5wSf6L0SVdKmS5dZCRvwhzs3GndRysq4PnnU/ENFCU/USUfUPzaG4uLg2GTHz1aytNPFzu6SaQd\ni3jJySHSB71jxxBvv21/EaxdK8lBQDxwCsldUe3QFpWFP1TJ5zjukMOZZvdusT3/7W/WC2br1vie\nJcZl8tBD41/73HPttjcxSlmZxIbp1Qu+/DJ9iboVJR9QJR9QcsEmbzxkbrlFRtMjRsA778QPEmZc\nKt3+89F48kkbybFPn4qIl8IvfiFl8+awcWNhjeTVDm1RWfhDlXyOk00l777vd99B+/ay7c5v6sVM\nvh5zTPxrN2wIr78u248+ar1tNm60I/f586XUkbyixEaVfECpj00+W0p+40a7XVpqV33G81kvLoYJ\nE6x/ux8GDgztW9XrDoNgYtsU0khe7dAWlYU/VMnnOCUl2Zt4XbTIermUlFglb8pYXHSR/+BqEyaI\nG2a00A1PPCFl167+rqUohYgq+YCSCzb5qir4v/+T7QYN4LjjZDteZMn6ctFFcPbZFVH33XSTKP9C\nGsmrHdqisvCHKvkcJ1tKfuZMSVBtYs80aCALk84/XxSzoijBQJV8QAmyTf7ddyXd3Rtv2MBgxg7/\n73+nPtVdKBQqqNF6PNQObVFZ+MOPkn8WWAfMc7W1AqYCS4C3gTLXvuHAUmAR4M7e2ce5xlJgZOJd\nVtxkQ8l/+KHd7tQJ5s61K13TxU9/Cv36pfceipKP+AmjdBpQAzwP9HTaHga+dso7gZbAMKAH8BJw\nPNAJmAZ0B8LAbOAWp5wEPApM8dwrHA5icPQAM3AgXHklXHppZu63fr2sal28WOo7dqQv4qKiKP5o\nIBHxoupzPyP56YA32+aFwFhneyxwsbN9ETAO2AWsAJYBJwIdgGaIggd5YZhzlCRwj+Rnzkz//dq1\nswoeVMErStBJ1CbfDjHh4JTtnO2OQJXruCpkRO9tr3balRj4tTdu2waDB4uXyckny2RoujAx3TON\n2l4tKguLysIfqUgFHXY+KWHIkCGUO+EJy8rK6N279z5XKfNH1bqtf/01QIWTVi/EzJnQtWt67jdx\notShgtatYePGEKFQ+r+vIQjyzna9srIyUP3JZr3SSVAQlP5ksh4KhRgzZgzAPn0ZC7+pDcqBN7E2\n+UVABbAWMcW8BxyO2OUBnFTLTAHuBVY6xxzhtA8GzgBu8txHbfL1ZPBgGD8evvpKknCsXCmhedPB\n22/DffeJWWj6dGjTBg4/PD33UhTFP8na5KMxEbjG2b4GmOBqHwSUAAchk66zkZfBVsQ+3wC42nWO\nkgQtWkhpsiyl8x153XU2BnyXLqrgFSUX8KPkxwEzgMOA1cC1yEj9HMSF8izsyH0B8IpTTgZuxppy\nbgaeRlwol1Hbs0Zx4TVVxKKh5y9oEmukmm3boLpaJl379JEJ2EzhVxaFgMrCorLwhx+b/OAY7bG8\nlh9wPl7mYM09Sorw5hJNl5Jfv17Kl1+GQw5Jzz0URUk9QUs3rDb5enLLLZK0wzBvXt1ZmRJhwQLx\nxV+4MPXXVhQlOdJhk1cCQqZG8ps2Scx4RVFyC1XyAcWvvTFTSn7mzPRduy7U9mpRWVhUFv5QJZ/j\npEvJ9+sn1zaLqzZvhhtvTM21FUXJHKrkA4pZAFEXXiXvDVYWDifmVvnOO1KaCddHHoG2bet/nVTg\nVxaFgMrCorLwhyr5HMer5N1xZUBcLDt29H+9jRvh++9t3djhDzgAzj03sT4qipI9VMkHlERt8j/9\nae1j1q71d8/162UVq8mdevbZ8PjjEhNny5bI/KqZRG2vFpWFRWXhj1TErlECzqGH+jtu1iwpN22C\nww6DVaus2aZRI9h///T0T1GU9KFKPqAkapM3fP219Z+PdYyXe++VculSUeiffGL3FRVJWONsoLZX\ni8rCorLwhyr5HKcoyl8wHI6cJPXa6WMxd66UFzuR/u+/H+6+W7abNk28j4qiZA+1yQcUv/bGli1r\nt6XKjXLoULudzRyranu1qCwsKgt/qJLPcYYOhdtuk+2f/1zKEk+2Jr9mlsGeKEWlpXZ79erE+qco\nSnZRJR9Q/Nob27aFESNk++CDoUmTxO+5Y4fdvvxyCWP8l78kfr1UobZXi8rCorLwhyr5PKJhw0hF\nbdizx9+CKLd//JNPyvV++cvU9U9RlMyjSj6gJGJvjKXIS0pg+XJYtiz++bNmwaRJEsLAbeu//PLs\nhhdW26tFZWFRWfhDlXwesXNnpB3d8P33Ysrp3l3S93nZvh0uu0xWu55wgs02ZXj5ZXGrVBQl99B4\n8nlCgwbw4IPy2bo1ct/hh8OiRbbuFfHcuXDssdH3KYoSfDSefIGwa1ekgq+ulgTfXbvGP88oeEVR\n8g9V8gElEXujNwJlx47Qvj18+aW/86MtrAoCanu1qCwsKgt/qJLPE0aOhOuvr+0jD/Ht6du32+1e\nvVLfL0VRsova5POM3r3h00/hiCMkLyvAWWfBe+/ZY9wifvBBuOsu2X7/fTj99Mz1VVGU1KA2+QJi\n714p27e3bV7FvWWLLY2CB/HAURQlv1AlH1AStTcaJe8OZeBdBfvVV1IuXGjb3nsPOnVK6JZpR22v\nFpWFRWXhj2SV/HDgc2Ae8BJQCrQCpgJLgLeBMs/xS4FFQP8k761EIZqSN+aZGTPgyCOtHd49wu/Z\nMzP9UxQlsySj5MuBnwLHAj2BRsAgYBii5A8F3nHqAD2AK5xyADAqyfvnNYnG5TBK/rrrbJtR8ied\nJNEkjReO2xsnWjTLoKAxSiwqC4vKwh/JKNmtwC5gPyQu/X7AGuBCYKxzzFjAiU7ORcA455wVwDLg\nhCTur0TBKPmBA2u3gYzwd+6MPOe++yROjaIo+Ucy/9rfAI8AqxDlvhkZwbcD1jnHrHPqAB2BKtf5\nVUBArcDZJ1mbvJvrr4fRo2W7pMQqeTPaz2aseD+o7dWisrCoLPyRzPKXg4FfIGabLcCrwFWeY8LO\nJxa19g0ZMoTy8nIAysrK6N27976fZeaPqvXY9ZoagNr7f/pTu3/XLtn/7LOyv3Hj4PQ/Wt0QlP5k\ns15ZWRmo/mSzXllZGaj+ZLIeCoUYM2YMwD59GYtk/OSvAM4BrnfqVwN9gbOAM4G1QAfgPeBwrG3+\nIaecAtwLzHJdU/3kk6RrV0nAHUuMl1wCF14I115rc7+OHQs/+Unm+qgoSmpJl5/8IkSpN3Eu3g9Y\nALwJXOMccw0wwdmeiEzMlgAHAd2B2UncX4lCNHONm6OPlrDDhjZtameEUhQlf0hGyX8KPA/8F/jM\naRuNjNTPQVwoz8KO3BcArzjlZOBm4ptyChqvqcIvdSn5Dh1kZasZ6R9/vP/0gNkiUVnkIyoLi8rC\nH8mGpHrY+bj5BhnVR+MB56OkibqUfPPm8MEHsG2b1NU6pij5jcauyTPatYP162Mr71degSuukLg2\nPXrA2rVyjqIouYvGrikg9uyJv99MtpqAZargFSW/USUfUBK1Nw4cCAMGxN5vlPzUqQldPiuo7dWi\nsrCoLPwR0DQRSqKYRU+xMIlBSkvhKu+qBkVR8g61yRcYu3eLieaoo8Qm/8QT2e6RoijJojZ5ZR9F\nRbIYau1aaNo0271RFCXdqJIPKOm0N5aWwqZN0KxZ2m6RUtT2alFZWFQW/lAlX4CUlMCGDbLaVVGU\n/EZt8gXIpZfC66/DxIlwwQXZ7o2iKMmiNnklgn/+U8qghzNQFCV5VMkHlHTaG42vfK4oebW9WlQW\nFpWFP1TJFyA33ihlrih5RVESR23yBcjKlVBeLom9Tzop271RFCVZ1CavRGBcJ725XhVFyT9UyQeU\ndNobW7WSsrQ0bbdIKWp7tagsLCoLf2jsmgJl5061yStKIaA2eUVRlBxHbfKKoigFiir5gKL2RovK\nwqKysKgs/KFKXlEUJY9Rm7yiKEqOozZ5RVGUAiVZJV8GvAYsBBYAJwKtgKnAEuBt5xjDcGApsAjo\nn+S98xq1N1pUFhaVhUVl4Y9klfxIYBJwBHA0oryHIUr+UOAdpw7QA7jCKQcAo1Jw/7ylsrIy210I\nDCoLi8rCorLwRzJKtgVwGvCsU98NbAEuBMY6bWOBi53ti4BxwC5gBbAMOCGJ++c1mzdvznYXAoPK\nwqKysKgs/JGMkj8I2AA8B3wCPAXsD7QD1jnHrHPqAB2BKtf5VUCnJO6vKIqi1EEySr4IOBYxuxwL\nbMOaZgxh5xMLdaWJwYoVK7LdhcCgsrCoLCwqi/TTHljuqp8K/BuZhG3vtHVA7PQgLwD3S2AKMlHr\nZhn2xaAf/ehHP/rx91lGmvgAmWAFuA942Pnc6bQNAx5ytnsAlUAJYur5guD56SuKoiguegH/AT4F\nXkcmY1sB04juQnkX8sZZBJyb0Z4qiqIoiqIoSiFxIPAe8DkwH7jVaU9kwVMJMBpYjNjtB8a4Zx9g\nnnONkZ59l7v68mKM83/lHPMp8ouii2vfFGAT8GaMc+ORSllci3zHT4HJQOsY90xWFqcjnk+7gEtd\n7WcCc12f7Yjrq1/qK4tWzvHfAo95rhXvO/o9LhlZAOzBymJCnD5EI1WyaIKd05oPPBjnnsnKohR4\n2Tn/Y6Cr0x6k58IwEfmusUiXLCC55yJnaA/0drabIgr6CMTufofTfie17e7FQDlimjF29/8Dfue6\ndizFNhvrPz8JWTgF0B35J23h1NvEOL8CaOxs3wSMd+07C/ghiSn5VMmiBNiIPOAAfwTujXHPZGXR\nFeiJrFfwKjZDS6c/jWPsj0Z9ZbEfcApwI7X/mWN9Ry/plMW3Mc7xQ6pk0QQ4w9kuRua70iWLmxGv\nOJAFiuOjHJPt5wJkIPgi8Fmce6ZTFsk8FznLBKAfMjI1/u/tsR40w7GTrhDpQbMKeZDj0QEZyRgG\nAU862w8D19Wzv8cAH3raKkhMyXtJVBYNEYXfBVH6TwDXR7l+KmXxHLGV/A3A3+txrWjUJQvDECL/\nmeN9R3welwpZpPKfOVFZeBkBDI3SngpZuP8vi5D1Ll6y+VyAvCSmIy+JWCP5dMsiL5R8ffzkyxGl\nOYv6L3gyP8/uB+YArwAHRLlHJ8/51dgFU92BwxClPRN/E7dDkbd7qiknMVl0BvYCtyE/IauRh/hZ\napNqWcRiELISOVHKqVsWhrCnHu87+j0uFbJojDyXM5GV2YlSTuKycFMGXICEBfGSCll0AlY722al\neivPMdl8LgB+D/wZ+C7OPdIti1Q9F1nFr5JvCvwDUU7et5vx04xHEaLgPkJsaDORP2B9KAYOQX7S\nDkZW2LaIc/xVyCKtP9XzPnWRjCzCQHPgUcQzqSMyShlezz7UVxax6AAcBbyVwLmQ/HORClIhiy7I\nc/ljZATdLYF+pEoWRYhyHYmE/6gP+fJc9Eb+Bv8kcTfroDwXWcePki9G/mB/x04+rCNywdN6Z7sa\nmXwxdHbaNiJv5Ned9tcQBdwQsVvPRfzszWjXfb55U69GzCx7kId/CfK2vt85/xPXef0Qd80LkYk2\nN8konlTI4ghkEdlyp/1V4GTSJwtDtO99OfI32RPj+8ajPrKIRTXRv2OmZfGVUy4HQsgItD6kQhYG\n45zwqFNvROplUY11SChClN83rmtm+7noCxyH/D2mI2tx3iU9z0U8WST7XOQEDYDngb962hNZ8DQO\nmb0HscG9HOOesxAbWQMiJ1LOBcY4220QG3/LKOcfg9i8D45x/QoSs8mnShZtkQfRTAT9nti/NpKV\nhWEM0W3yH2Mn++pDfWVhGEJt22us7+glXbIoQzwszPlLgMPjnO8llbK4HxkA1TV6TVYWNyNzQSBm\nGe/EaxCeC0NX4nvXpEsWyT4XOcOpiA3ZvD3nIkJMZMFTF+B9xG1wKpFvYDfGJWoZdjRjeARxifoM\nGW1EYyryBo7m+jQdGUV8h7zpz4lxjWikUhY/wbpQ/pPYSilZWRyPfM8a4Gsi/1nKsbbI+pKILFYg\nv+i+de5r/mHifUc36ZLFyc55lU55bZw+RCNVsjDzNZ+7rhNr4jBZWZQi82LGbbDcta+c7D0Xq6it\nSMuJ712TLlmcRHLPhaIoiqIoiqIoiqIoiqIoiqIoiqIoiqIoiqIoiqIoiqIoSrYw4WTnIz7Rv6Lu\nxUhdkaXyiqIoSsBxx1Zpiyymu6+OcypITSRTRVEUJc14A2gdhKyIBVn9+AESiXAOsgoSZGXkZuQX\nwG1ITJU/IbHNP0XC9CqKoigBIFrM8E3IqL4JNn5JdySfMUhcF/dI/gbgt852qXNceao7qiiJUJTt\nDihKgCkBHkfCQu9BFD3Uttn3R7JO/cipN0fC3K5IfxcVJT6q5BUlkm6IQt+A2Oa/Aq5GQv5+H+e8\nWxB7vqIEivpkhlKUfKctkj7OhL1tDqx1tn+CKHoQE08z13lvISFrzaDpUCR/qaIoipJldhPbhfIQ\nZCK1EomBvtVpL0JS81UiE68NgD8gIWnnOfuaZ6b7iqIoiqIoiqIoiqIoiqIoiqIoiqIoiqIoiqIo\niqIoiqIoiqIoiqIoipIH/D+0FiQ/WkMqMAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x62947d0>"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove Outliers\n",
      "def outliers_by_moving_average(ser, window_size, threshold):\n",
      "    # This function returns the indexes of samples that moves far away (greater than a threshold)\n",
      "    # from the moving average of samples before it\n",
      "    # ser: series containing the data\n",
      "    # window_size: window size for moving average\n",
      "    # threshold: threshold to be considered large\n",
      "    # Note: the first window_size samples are simply considered normal\n",
      "        \n",
      "    moving_avg = pd.rolling_mean(ser, window=window_size)\n",
      "    outlier_index = ser[np.abs(ser/moving_avg - 1) > threshold].index\n",
      "        \n",
      "    return outlier_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window_size = 3\n",
      "threshold = 0.3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outlier_index = outliers_by_moving_average(fund_and_index[index_code+'_Adjusted Close'], window_size, threshold)\n",
      "fund_and_index = fund_and_index.drop(outlier_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index[index_code+'_Adjusted Close'].plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEPCAYAAACneLThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqIoiqIoiqIoiqIoipIH/D+0FiQ/WkMqMAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x5b0b910>"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index.applymap(np.isnan).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "GOOG/NYSEARCA_SSO_Open             18\n",
        "GOOG/NYSEARCA_SSO_High             18\n",
        "GOOG/NYSEARCA_SSO_Low              18\n",
        "GOOG/NYSEARCA_SSO_Close             0\n",
        "GOOG/NYSEARCA_SSO_Volume            0\n",
        "YAHOO/INDEX_GSPC_Open               0\n",
        "YAHOO/INDEX_GSPC_High               0\n",
        "YAHOO/INDEX_GSPC_Low                0\n",
        "YAHOO/INDEX_GSPC_Close              0\n",
        "YAHOO/INDEX_GSPC_Volume             0\n",
        "YAHOO/INDEX_GSPC_Adjusted Close     0\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index = fund_and_index.interpolate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fund_and_index.ix[[1,3],:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Open</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_High</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Low</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Close</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Open</th>\n",
        "      <th>YAHOO/INDEX_GSPC_High</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Low</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Close</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Adjusted Close</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2006-06-22</th>\n",
        "      <td> 71.08</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 70.26</td>\n",
        "      <td> 70.74</td>\n",
        "      <td> 136600</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1241.53</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td> 2148180000</td>\n",
        "      <td> 1245.60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-26</th>\n",
        "      <td> 70.75</td>\n",
        "      <td> 71.17</td>\n",
        "      <td> 70.51</td>\n",
        "      <td> 71.14</td>\n",
        "      <td>  37700</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 1250.92</td>\n",
        "      <td> 1243.68</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 1878580000</td>\n",
        "      <td> 1250.56</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "            GOOG/NYSEARCA_SSO_Open  GOOG/NYSEARCA_SSO_High  \\\n",
        "Date                                                         \n",
        "2006-06-22                   71.08                   71.08   \n",
        "2006-06-26                   70.75                   71.17   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low  GOOG/NYSEARCA_SSO_Close  \\\n",
        "Date                                                         \n",
        "2006-06-22                  70.26                    70.74   \n",
        "2006-06-26                  70.51                    71.14   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume  YAHOO/INDEX_GSPC_Open  \\\n",
        "Date                                                          \n",
        "2006-06-22                    136600                1251.92   \n",
        "2006-06-26                     37700                1244.50   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High  YAHOO/INDEX_GSPC_Low  \\\n",
        "Date                                                      \n",
        "2006-06-22                1251.92               1241.53   \n",
        "2006-06-26                1250.92               1243.68   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close  YAHOO/INDEX_GSPC_Volume  \\\n",
        "Date                                                          \n",
        "2006-06-22                 1245.60               2148180000   \n",
        "2006-06-26                 1250.56               1878580000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close  \n",
        "Date                                         \n",
        "2006-06-22                          1245.60  \n",
        "2006-06-26                          1250.56  "
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_preparation(fund_and_index, fund_code, index_code, direction, days_back): # feature extraction\n",
      "    # formulate the feature set for prediction use\n",
      "\n",
      "    # nan's are filled by interpolation.\n",
      "    fund_and_index = fund_and_index.interpolate()\n",
      "        \n",
      "    # daily changes of fund close price and index adjusted close price\n",
      "    fund_and_index['fund_daily_change'] = (fund_and_index[fund_code+'_Close'] - fund_and_index[fund_code+'_Close'].shift(1))/fund_and_index[fund_code+'_Close'].astype(float)   # daily change of fund close price\n",
      "    fund_and_index['index_daily_change'] = (fund_and_index[index_code+'_Adjusted Close'] - fund_and_index[index_code+'_Adjusted Close'].shift(1))/fund_and_index[index_code+'_Adjusted Close'].astype(float)  # daily change of index adjusted close price\n",
      "    fund_and_index['diff_changes'] = fund_and_index['fund_daily_change'] - fund_and_index['index_daily_change']*direction;\n",
      "    \n",
      "    # absolute changes, maybe more useful\n",
      "    fund_and_index['fund_abs_daily_change'] = fund_and_index['fund_daily_change'].abs()\n",
      "    fund_and_index['index_abs_daily_change'] = fund_and_index['index_daily_change'].abs()\n",
      "    fund_and_index['abs_diff_changes'] = fund_and_index['diff_changes'].abs()\n",
      "            \n",
      "    # concatenate the data of past as features\n",
      "    ## maybe should exclude some features\n",
      "    features = fund_and_index\n",
      "    for i_dayback in xrange(1, days_back):\n",
      "        features = features.join(fund_and_index.shift(i_dayback), rsuffix='_prev'+str(i_dayback))\n",
      "\n",
      "    # open price, since we try to predict the change of close price we could include the open price of that day as a signal\n",
      "    features['next_day_fund_open'] = fund_and_index[fund_code+'_Open'].shift(-1)\n",
      "    features['next_day_index_open'] = fund_and_index[index_code+'_Open'].shift(-1)\n",
      "    fund_and_index['next_day_fund_open'] = fund_and_index[fund_code+'_Open'].shift(-1)\n",
      "    fund_and_index['next_day_index_open'] = fund_and_index[index_code+'_Open'].shift(-1)\n",
      "        \n",
      "    # target variable, next day's difference of changes\n",
      "#     fund_and_index['target'] = fund_and_index['abs_diff_changes'].shift(-1) # maybe only absolute difference is easier to calculate\n",
      "    \n",
      "    return features, fund_and_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "days_back = 3\n",
      "features, ex_fund_and_index = feature_preparation(fund_and_index, fund_code, index_code, direction, days_back)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ex_fund_and_index.shape\n",
      "ex_fund_and_index.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2006, 19)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Open</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_High</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Low</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Close</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Open</th>\n",
        "      <th>YAHOO/INDEX_GSPC_High</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Low</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Close</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Adjusted Close</th>\n",
        "      <th>fund_daily_change</th>\n",
        "      <th>index_daily_change</th>\n",
        "      <th>diff_changes</th>\n",
        "      <th>fund_abs_daily_change</th>\n",
        "      <th>index_abs_daily_change</th>\n",
        "      <th>abs_diff_changes</th>\n",
        "      <th>next_day_fund_open</th>\n",
        "      <th>next_day_index_open</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2006-06-21</th>\n",
        "      <td> 70.88</td>\n",
        "      <td> 71.81</td>\n",
        "      <td> 70.82</td>\n",
        "      <td> 71.50</td>\n",
        "      <td> 277300</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1257.96</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td> 2361230000</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 1251.92</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-22</th>\n",
        "      <td> 71.08</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 70.26</td>\n",
        "      <td> 70.74</td>\n",
        "      <td> 136600</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1241.53</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td> 2148180000</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td>-0.010744</td>\n",
        "      <td>-0.005299</td>\n",
        "      <td>-0.000146</td>\n",
        "      <td> 0.010744</td>\n",
        "      <td> 0.005299</td>\n",
        "      <td> 0.000146</td>\n",
        "      <td> 70.32</td>\n",
        "      <td> 1245.59</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-23</th>\n",
        "      <td> 70.32</td>\n",
        "      <td> 71.38</td>\n",
        "      <td> 70.13</td>\n",
        "      <td> 70.73</td>\n",
        "      <td>  44600</td>\n",
        "      <td> 1245.59</td>\n",
        "      <td> 1253.13</td>\n",
        "      <td> 1241.43</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 2017270000</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td>-0.000141</td>\n",
        "      <td>-0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 0.000141</td>\n",
        "      <td> 0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 70.75</td>\n",
        "      <td> 1244.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-26</th>\n",
        "      <td> 70.75</td>\n",
        "      <td> 71.17</td>\n",
        "      <td> 70.51</td>\n",
        "      <td> 71.14</td>\n",
        "      <td>  37700</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 1250.92</td>\n",
        "      <td> 1243.68</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 1878580000</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td>-0.003928</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td> 0.003928</td>\n",
        "      <td> 71.37</td>\n",
        "      <td> 1250.55</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-27</th>\n",
        "      <td> 71.37</td>\n",
        "      <td> 71.37</td>\n",
        "      <td> 69.88</td>\n",
        "      <td> 69.88</td>\n",
        "      <td> 114700</td>\n",
        "      <td> 1250.55</td>\n",
        "      <td> 1253.37</td>\n",
        "      <td> 1238.94</td>\n",
        "      <td> 1239.20</td>\n",
        "      <td> 2203130000</td>\n",
        "      <td> 1239.20</td>\n",
        "      <td>-0.018031</td>\n",
        "      <td>-0.009167</td>\n",
        "      <td> 0.000303</td>\n",
        "      <td> 0.018031</td>\n",
        "      <td> 0.009167</td>\n",
        "      <td> 0.000303</td>\n",
        "      <td> 70.09</td>\n",
        "      <td> 1238.99</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "            GOOG/NYSEARCA_SSO_Open  GOOG/NYSEARCA_SSO_High  \\\n",
        "Date                                                         \n",
        "2006-06-21                   70.88                   71.81   \n",
        "2006-06-22                   71.08                   71.08   \n",
        "2006-06-23                   70.32                   71.38   \n",
        "2006-06-26                   70.75                   71.17   \n",
        "2006-06-27                   71.37                   71.37   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low  GOOG/NYSEARCA_SSO_Close  \\\n",
        "Date                                                         \n",
        "2006-06-21                  70.82                    71.50   \n",
        "2006-06-22                  70.26                    70.74   \n",
        "2006-06-23                  70.13                    70.73   \n",
        "2006-06-26                  70.51                    71.14   \n",
        "2006-06-27                  69.88                    69.88   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume  YAHOO/INDEX_GSPC_Open  \\\n",
        "Date                                                          \n",
        "2006-06-21                    277300                1240.09   \n",
        "2006-06-22                    136600                1251.92   \n",
        "2006-06-23                     44600                1245.59   \n",
        "2006-06-26                     37700                1244.50   \n",
        "2006-06-27                    114700                1250.55   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High  YAHOO/INDEX_GSPC_Low  \\\n",
        "Date                                                      \n",
        "2006-06-21                1257.96               1240.09   \n",
        "2006-06-22                1251.92               1241.53   \n",
        "2006-06-23                1253.13               1241.43   \n",
        "2006-06-26                1250.92               1243.68   \n",
        "2006-06-27                1253.37               1238.94   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close  YAHOO/INDEX_GSPC_Volume  \\\n",
        "Date                                                          \n",
        "2006-06-21                 1252.20               2361230000   \n",
        "2006-06-22                 1245.60               2148180000   \n",
        "2006-06-23                 1244.50               2017270000   \n",
        "2006-06-26                 1250.56               1878580000   \n",
        "2006-06-27                 1239.20               2203130000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close  fund_daily_change  \\\n",
        "Date                                                             \n",
        "2006-06-21                          1252.20                NaN   \n",
        "2006-06-22                          1245.60          -0.010744   \n",
        "2006-06-23                          1244.50          -0.000141   \n",
        "2006-06-26                          1250.56           0.005763   \n",
        "2006-06-27                          1239.20          -0.018031   \n",
        "\n",
        "            index_daily_change  diff_changes  fund_abs_daily_change  \\\n",
        "Date                                                                  \n",
        "2006-06-21                 NaN           NaN                    NaN   \n",
        "2006-06-22           -0.005299     -0.000146               0.010744   \n",
        "2006-06-23           -0.000884      0.001626               0.000141   \n",
        "2006-06-26            0.004846     -0.003928               0.005763   \n",
        "2006-06-27           -0.009167      0.000303               0.018031   \n",
        "\n",
        "            index_abs_daily_change  abs_diff_changes  next_day_fund_open  \\\n",
        "Date                                                                       \n",
        "2006-06-21                     NaN               NaN               71.08   \n",
        "2006-06-22                0.005299          0.000146               70.32   \n",
        "2006-06-23                0.000884          0.001626               70.75   \n",
        "2006-06-26                0.004846          0.003928               71.37   \n",
        "2006-06-27                0.009167          0.000303               70.09   \n",
        "\n",
        "            next_day_index_open  \n",
        "Date                             \n",
        "2006-06-21              1251.92  \n",
        "2006-06-22              1245.59  \n",
        "2006-06-23              1244.50  \n",
        "2006-06-26              1250.55  \n",
        "2006-06-27              1238.99  "
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.max_columns', 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check\n",
      "features.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Open</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_High</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Low</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Close</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Open</th>\n",
        "      <th>YAHOO/INDEX_GSPC_High</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Low</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Close</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Volume</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Adjusted Close</th>\n",
        "      <th>fund_daily_change</th>\n",
        "      <th>index_daily_change</th>\n",
        "      <th>diff_changes</th>\n",
        "      <th>fund_abs_daily_change</th>\n",
        "      <th>index_abs_daily_change</th>\n",
        "      <th>abs_diff_changes</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Open_prev1</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_High_prev1</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Low_prev1</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Close_prev1</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Volume_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Open_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_High_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Low_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Close_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Volume_prev1</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Adjusted Close_prev1</th>\n",
        "      <th>fund_daily_change_prev1</th>\n",
        "      <th>index_daily_change_prev1</th>\n",
        "      <th>diff_changes_prev1</th>\n",
        "      <th>fund_abs_daily_change_prev1</th>\n",
        "      <th>index_abs_daily_change_prev1</th>\n",
        "      <th>abs_diff_changes_prev1</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Open_prev2</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_High_prev2</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Low_prev2</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Close_prev2</th>\n",
        "      <th>GOOG/NYSEARCA_SSO_Volume_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Open_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_High_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Low_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Close_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Volume_prev2</th>\n",
        "      <th>YAHOO/INDEX_GSPC_Adjusted Close_prev2</th>\n",
        "      <th>fund_daily_change_prev2</th>\n",
        "      <th>index_daily_change_prev2</th>\n",
        "      <th>diff_changes_prev2</th>\n",
        "      <th>fund_abs_daily_change_prev2</th>\n",
        "      <th>index_abs_daily_change_prev2</th>\n",
        "      <th>abs_diff_changes_prev2</th>\n",
        "      <th>next_day_fund_open</th>\n",
        "      <th>next_day_index_open</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2006-06-21</th>\n",
        "      <td> 70.88</td>\n",
        "      <td> 71.81</td>\n",
        "      <td> 70.82</td>\n",
        "      <td> 71.50</td>\n",
        "      <td> 277300</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1257.96</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td> 2361230000</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 1251.92</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-22</th>\n",
        "      <td> 71.08</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 70.26</td>\n",
        "      <td> 70.74</td>\n",
        "      <td> 136600</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1241.53</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td> 2148180000</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td>-0.010744</td>\n",
        "      <td>-0.005299</td>\n",
        "      <td>-0.000146</td>\n",
        "      <td> 0.010744</td>\n",
        "      <td> 0.005299</td>\n",
        "      <td> 0.000146</td>\n",
        "      <td> 70.88</td>\n",
        "      <td> 71.81</td>\n",
        "      <td> 70.82</td>\n",
        "      <td> 71.50</td>\n",
        "      <td> 277300</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1257.96</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td> 2361230000</td>\n",
        "      <td> 1252.20</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>     NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>        NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 70.32</td>\n",
        "      <td> 1245.59</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-23</th>\n",
        "      <td> 70.32</td>\n",
        "      <td> 71.38</td>\n",
        "      <td> 70.13</td>\n",
        "      <td> 70.73</td>\n",
        "      <td>  44600</td>\n",
        "      <td> 1245.59</td>\n",
        "      <td> 1253.13</td>\n",
        "      <td> 1241.43</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 2017270000</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td>-0.000141</td>\n",
        "      <td>-0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 0.000141</td>\n",
        "      <td> 0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 70.26</td>\n",
        "      <td> 70.74</td>\n",
        "      <td> 136600</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1241.53</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td> 2148180000</td>\n",
        "      <td> 1245.60</td>\n",
        "      <td>-0.010744</td>\n",
        "      <td>-0.005299</td>\n",
        "      <td>-0.000146</td>\n",
        "      <td> 0.010744</td>\n",
        "      <td> 0.005299</td>\n",
        "      <td> 0.000146</td>\n",
        "      <td> 70.88</td>\n",
        "      <td> 71.81</td>\n",
        "      <td> 70.82</td>\n",
        "      <td> 71.50</td>\n",
        "      <td> 277300</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1257.96</td>\n",
        "      <td> 1240.09</td>\n",
        "      <td> 1252.2</td>\n",
        "      <td> 2361230000</td>\n",
        "      <td> 1252.2</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 70.75</td>\n",
        "      <td> 1244.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-26</th>\n",
        "      <td> 70.75</td>\n",
        "      <td> 71.17</td>\n",
        "      <td> 70.51</td>\n",
        "      <td> 71.14</td>\n",
        "      <td>  37700</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 1250.92</td>\n",
        "      <td> 1243.68</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 1878580000</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td>-0.003928</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td> 0.003928</td>\n",
        "      <td> 70.32</td>\n",
        "      <td> 71.38</td>\n",
        "      <td> 70.13</td>\n",
        "      <td> 70.73</td>\n",
        "      <td>  44600</td>\n",
        "      <td> 1245.59</td>\n",
        "      <td> 1253.13</td>\n",
        "      <td> 1241.43</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 2017270000</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td>-0.000141</td>\n",
        "      <td>-0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 0.000141</td>\n",
        "      <td> 0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 71.08</td>\n",
        "      <td> 70.26</td>\n",
        "      <td> 70.74</td>\n",
        "      <td> 136600</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1251.92</td>\n",
        "      <td> 1241.53</td>\n",
        "      <td> 1245.6</td>\n",
        "      <td> 2148180000</td>\n",
        "      <td> 1245.6</td>\n",
        "      <td>-0.010744</td>\n",
        "      <td>-0.005299</td>\n",
        "      <td>-0.000146</td>\n",
        "      <td> 0.010744</td>\n",
        "      <td> 0.005299</td>\n",
        "      <td> 0.000146</td>\n",
        "      <td> 71.37</td>\n",
        "      <td> 1250.55</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006-06-27</th>\n",
        "      <td> 71.37</td>\n",
        "      <td> 71.37</td>\n",
        "      <td> 69.88</td>\n",
        "      <td> 69.88</td>\n",
        "      <td> 114700</td>\n",
        "      <td> 1250.55</td>\n",
        "      <td> 1253.37</td>\n",
        "      <td> 1238.94</td>\n",
        "      <td> 1239.20</td>\n",
        "      <td> 2203130000</td>\n",
        "      <td> 1239.20</td>\n",
        "      <td>-0.018031</td>\n",
        "      <td>-0.009167</td>\n",
        "      <td> 0.000303</td>\n",
        "      <td> 0.018031</td>\n",
        "      <td> 0.009167</td>\n",
        "      <td> 0.000303</td>\n",
        "      <td> 70.75</td>\n",
        "      <td> 71.17</td>\n",
        "      <td> 70.51</td>\n",
        "      <td> 71.14</td>\n",
        "      <td>  37700</td>\n",
        "      <td> 1244.50</td>\n",
        "      <td> 1250.92</td>\n",
        "      <td> 1243.68</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 1878580000</td>\n",
        "      <td> 1250.56</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td>-0.003928</td>\n",
        "      <td> 0.005763</td>\n",
        "      <td> 0.004846</td>\n",
        "      <td> 0.003928</td>\n",
        "      <td> 70.32</td>\n",
        "      <td> 71.38</td>\n",
        "      <td> 70.13</td>\n",
        "      <td> 70.73</td>\n",
        "      <td>  44600</td>\n",
        "      <td> 1245.59</td>\n",
        "      <td> 1253.13</td>\n",
        "      <td> 1241.43</td>\n",
        "      <td> 1244.5</td>\n",
        "      <td> 2017270000</td>\n",
        "      <td> 1244.5</td>\n",
        "      <td>-0.000141</td>\n",
        "      <td>-0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 0.000141</td>\n",
        "      <td> 0.000884</td>\n",
        "      <td> 0.001626</td>\n",
        "      <td> 70.09</td>\n",
        "      <td> 1238.99</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "            GOOG/NYSEARCA_SSO_Open  GOOG/NYSEARCA_SSO_High  \\\n",
        "Date                                                         \n",
        "2006-06-21                   70.88                   71.81   \n",
        "2006-06-22                   71.08                   71.08   \n",
        "2006-06-23                   70.32                   71.38   \n",
        "2006-06-26                   70.75                   71.17   \n",
        "2006-06-27                   71.37                   71.37   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low  GOOG/NYSEARCA_SSO_Close  \\\n",
        "Date                                                         \n",
        "2006-06-21                  70.82                    71.50   \n",
        "2006-06-22                  70.26                    70.74   \n",
        "2006-06-23                  70.13                    70.73   \n",
        "2006-06-26                  70.51                    71.14   \n",
        "2006-06-27                  69.88                    69.88   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume  YAHOO/INDEX_GSPC_Open  \\\n",
        "Date                                                          \n",
        "2006-06-21                    277300                1240.09   \n",
        "2006-06-22                    136600                1251.92   \n",
        "2006-06-23                     44600                1245.59   \n",
        "2006-06-26                     37700                1244.50   \n",
        "2006-06-27                    114700                1250.55   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High  YAHOO/INDEX_GSPC_Low  \\\n",
        "Date                                                      \n",
        "2006-06-21                1257.96               1240.09   \n",
        "2006-06-22                1251.92               1241.53   \n",
        "2006-06-23                1253.13               1241.43   \n",
        "2006-06-26                1250.92               1243.68   \n",
        "2006-06-27                1253.37               1238.94   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close  YAHOO/INDEX_GSPC_Volume  \\\n",
        "Date                                                          \n",
        "2006-06-21                 1252.20               2361230000   \n",
        "2006-06-22                 1245.60               2148180000   \n",
        "2006-06-23                 1244.50               2017270000   \n",
        "2006-06-26                 1250.56               1878580000   \n",
        "2006-06-27                 1239.20               2203130000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close  fund_daily_change  \\\n",
        "Date                                                             \n",
        "2006-06-21                          1252.20                NaN   \n",
        "2006-06-22                          1245.60          -0.010744   \n",
        "2006-06-23                          1244.50          -0.000141   \n",
        "2006-06-26                          1250.56           0.005763   \n",
        "2006-06-27                          1239.20          -0.018031   \n",
        "\n",
        "            index_daily_change  diff_changes  fund_abs_daily_change  \\\n",
        "Date                                                                  \n",
        "2006-06-21                 NaN           NaN                    NaN   \n",
        "2006-06-22           -0.005299     -0.000146               0.010744   \n",
        "2006-06-23           -0.000884      0.001626               0.000141   \n",
        "2006-06-26            0.004846     -0.003928               0.005763   \n",
        "2006-06-27           -0.009167      0.000303               0.018031   \n",
        "\n",
        "            index_abs_daily_change  abs_diff_changes  \\\n",
        "Date                                                   \n",
        "2006-06-21                     NaN               NaN   \n",
        "2006-06-22                0.005299          0.000146   \n",
        "2006-06-23                0.000884          0.001626   \n",
        "2006-06-26                0.004846          0.003928   \n",
        "2006-06-27                0.009167          0.000303   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Open_prev1  GOOG/NYSEARCA_SSO_High_prev1  \\\n",
        "Date                                                                     \n",
        "2006-06-21                           NaN                           NaN   \n",
        "2006-06-22                         70.88                         71.81   \n",
        "2006-06-23                         71.08                         71.08   \n",
        "2006-06-26                         70.32                         71.38   \n",
        "2006-06-27                         70.75                         71.17   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Low_prev1  GOOG/NYSEARCA_SSO_Close_prev1  \\\n",
        "Date                                                                     \n",
        "2006-06-21                          NaN                            NaN   \n",
        "2006-06-22                        70.82                          71.50   \n",
        "2006-06-23                        70.26                          70.74   \n",
        "2006-06-26                        70.13                          70.73   \n",
        "2006-06-27                        70.51                          71.14   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Volume_prev1  YAHOO/INDEX_GSPC_Open_prev1  \\\n",
        "Date                                                                      \n",
        "2006-06-21                             NaN                          NaN   \n",
        "2006-06-22                          277300                      1240.09   \n",
        "2006-06-23                          136600                      1251.92   \n",
        "2006-06-26                           44600                      1245.59   \n",
        "2006-06-27                           37700                      1244.50   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_High_prev1  YAHOO/INDEX_GSPC_Low_prev1  \\\n",
        "Date                                                                  \n",
        "2006-06-21                          NaN                         NaN   \n",
        "2006-06-22                      1257.96                     1240.09   \n",
        "2006-06-23                      1251.92                     1241.53   \n",
        "2006-06-26                      1253.13                     1241.43   \n",
        "2006-06-27                      1250.92                     1243.68   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Close_prev1  YAHOO/INDEX_GSPC_Volume_prev1  \\\n",
        "Date                                                                      \n",
        "2006-06-21                           NaN                            NaN   \n",
        "2006-06-22                       1252.20                     2361230000   \n",
        "2006-06-23                       1245.60                     2148180000   \n",
        "2006-06-26                       1244.50                     2017270000   \n",
        "2006-06-27                       1250.56                     1878580000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close_prev1  fund_daily_change_prev1  \\\n",
        "Date                                                                         \n",
        "2006-06-21                                    NaN                      NaN   \n",
        "2006-06-22                                1252.20                      NaN   \n",
        "2006-06-23                                1245.60                -0.010744   \n",
        "2006-06-26                                1244.50                -0.000141   \n",
        "2006-06-27                                1250.56                 0.005763   \n",
        "\n",
        "            index_daily_change_prev1  diff_changes_prev1  \\\n",
        "Date                                                       \n",
        "2006-06-21                       NaN                 NaN   \n",
        "2006-06-22                       NaN                 NaN   \n",
        "2006-06-23                 -0.005299           -0.000146   \n",
        "2006-06-26                 -0.000884            0.001626   \n",
        "2006-06-27                  0.004846           -0.003928   \n",
        "\n",
        "            fund_abs_daily_change_prev1  index_abs_daily_change_prev1  \\\n",
        "Date                                                                    \n",
        "2006-06-21                          NaN                           NaN   \n",
        "2006-06-22                          NaN                           NaN   \n",
        "2006-06-23                     0.010744                      0.005299   \n",
        "2006-06-26                     0.000141                      0.000884   \n",
        "2006-06-27                     0.005763                      0.004846   \n",
        "\n",
        "            abs_diff_changes_prev1  GOOG/NYSEARCA_SSO_Open_prev2  \\\n",
        "Date                                                               \n",
        "2006-06-21                     NaN                           NaN   \n",
        "2006-06-22                     NaN                           NaN   \n",
        "2006-06-23                0.000146                         70.88   \n",
        "2006-06-26                0.001626                         71.08   \n",
        "2006-06-27                0.003928                         70.32   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_High_prev2  GOOG/NYSEARCA_SSO_Low_prev2  \\\n",
        "Date                                                                    \n",
        "2006-06-21                           NaN                          NaN   \n",
        "2006-06-22                           NaN                          NaN   \n",
        "2006-06-23                         71.81                        70.82   \n",
        "2006-06-26                         71.08                        70.26   \n",
        "2006-06-27                         71.38                        70.13   \n",
        "\n",
        "            GOOG/NYSEARCA_SSO_Close_prev2  GOOG/NYSEARCA_SSO_Volume_prev2  \\\n",
        "Date                                                                        \n",
        "2006-06-21                            NaN                             NaN   \n",
        "2006-06-22                            NaN                             NaN   \n",
        "2006-06-23                          71.50                          277300   \n",
        "2006-06-26                          70.74                          136600   \n",
        "2006-06-27                          70.73                           44600   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Open_prev2  YAHOO/INDEX_GSPC_High_prev2  \\\n",
        "Date                                                                   \n",
        "2006-06-21                          NaN                          NaN   \n",
        "2006-06-22                          NaN                          NaN   \n",
        "2006-06-23                      1240.09                      1257.96   \n",
        "2006-06-26                      1251.92                      1251.92   \n",
        "2006-06-27                      1245.59                      1253.13   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Low_prev2  YAHOO/INDEX_GSPC_Close_prev2  \\\n",
        "Date                                                                   \n",
        "2006-06-21                         NaN                           NaN   \n",
        "2006-06-22                         NaN                           NaN   \n",
        "2006-06-23                     1240.09                        1252.2   \n",
        "2006-06-26                     1241.53                        1245.6   \n",
        "2006-06-27                     1241.43                        1244.5   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Volume_prev2  \\\n",
        "Date                                        \n",
        "2006-06-21                            NaN   \n",
        "2006-06-22                            NaN   \n",
        "2006-06-23                     2361230000   \n",
        "2006-06-26                     2148180000   \n",
        "2006-06-27                     2017270000   \n",
        "\n",
        "            YAHOO/INDEX_GSPC_Adjusted Close_prev2  fund_daily_change_prev2  \\\n",
        "Date                                                                         \n",
        "2006-06-21                                    NaN                      NaN   \n",
        "2006-06-22                                    NaN                      NaN   \n",
        "2006-06-23                                 1252.2                      NaN   \n",
        "2006-06-26                                 1245.6                -0.010744   \n",
        "2006-06-27                                 1244.5                -0.000141   \n",
        "\n",
        "            index_daily_change_prev2  diff_changes_prev2  \\\n",
        "Date                                                       \n",
        "2006-06-21                       NaN                 NaN   \n",
        "2006-06-22                       NaN                 NaN   \n",
        "2006-06-23                       NaN                 NaN   \n",
        "2006-06-26                 -0.005299           -0.000146   \n",
        "2006-06-27                 -0.000884            0.001626   \n",
        "\n",
        "            fund_abs_daily_change_prev2  index_abs_daily_change_prev2  \\\n",
        "Date                                                                    \n",
        "2006-06-21                          NaN                           NaN   \n",
        "2006-06-22                          NaN                           NaN   \n",
        "2006-06-23                          NaN                           NaN   \n",
        "2006-06-26                     0.010744                      0.005299   \n",
        "2006-06-27                     0.000141                      0.000884   \n",
        "\n",
        "            abs_diff_changes_prev2  next_day_fund_open  next_day_index_open  \n",
        "Date                                                                         \n",
        "2006-06-21                     NaN               71.08              1251.92  \n",
        "2006-06-22                     NaN               70.32              1245.59  \n",
        "2006-06-23                     NaN               70.75              1244.50  \n",
        "2006-06-26                0.000146               71.37              1250.55  \n",
        "2006-06-27                0.001626               70.09              1238.99  "
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### histogram of the normal 95% of the changes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diff_changes = ex_fund_and_index['diff_changes']\n",
      "diff_changes[(diff_changes < np.percentile(diff_changes, 97.5)) & (diff_changes > np.percentile(diff_changes, 2.5))].hist(bins=200)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSZIkSZIkSZIkNdf/A1lLh7+bsZcCAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x5870c90>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simple Fitting with Linear Regressions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ex_features = features\n",
      "ex_features['target'] = ex_fund_and_index['diff_changes'].shift(-1)\n",
      "ex_features = ex_features.dropna(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linRegress_target = ex_features['target']\n",
      "linRegress_features = ex_features.drop('target', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linear_regression_models_(features, target, num_cv=5):\n",
      "    # this function is a combination of linear regression models\n",
      "    \n",
      "    # standardize features\n",
      "    scaler = preprocessing.StandardScaler().fit(features)\n",
      "    scaled_features = scaler.transform(features)\n",
      "    \n",
      "    # linear regression\n",
      "    linRegress = linear_model.LinearRegression()\n",
      "    linRegress.fit(scaled_features, target)\n",
      "    linRegress_mse = metrics.mean_squared_error(target, linRegress.predict(scaled_features))\n",
      "    \n",
      "    # ridge regression\n",
      "    alphas = np.logspace(-2.0, 3.0, num=10)\n",
      "    ridge_clf = linear_model.Ridge()\n",
      "    parameters = {'alpha':alphas}\n",
      "    ridge_models = grid_search.GridSearchCV(ridge_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    ridge_models.fit(scaled_features, target)\n",
      "    ridge_mse = metrics.mean_squared_error(target, ridge_models.predict(scaled_features))\n",
      "    \n",
      "    # lasso regression\n",
      "    lasso_clf = linear_model.LassoLars()\n",
      "    lasso_models = grid_search.GridSearchCV(lasso_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    lasso_models.fit(scaled_features, target)\n",
      "    lasso_mse = metrics.mean_squared_error(target, lasso_models.predict(scaled_features))\n",
      "    \n",
      "    return [linRegress_mse, ridge_mse, lasso_mse]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linRegress_MSEs = linear_regression_models_(linRegress_features, linRegress_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print linRegress_MSEs\n",
      "print linRegress_target.var()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1.5668351803161923e-05, 1.5708400612298617e-05, 2.8702555436468324e-05]\n",
        "2.87168995421e-05\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The regression could be working but this is not a valid test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* the test samples should be separate samples\n",
      "* the train-test split should be along time direction (future should not be availalbe)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def regression_train_and_eval((train_X, train_y, test_X, test_y)):\n",
      "    # A bundle for training multiple regression models and then evaluate them\n",
      "    \n",
      "    score_criteria = 'mean_square_error'\n",
      "    num_cv = 5\n",
      "    # shuffle the training data in case cv is not shuffling at all\n",
      "    train_X, train_y = utils.shuffle(train_X, train_y, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    scaler = preprocessing.StandardScaler().fit(train_X)  # fit does nothing\n",
      "    scaled_train_X = scaler.transform(train_X)\n",
      "    scaled_test_X = scaler.transform(test_X)\n",
      "    \n",
      "    # baseline as always predict 0\n",
      "    baseline_mse = metrics.mean_squared_error(test_y, np.zeros(len(test_y)))\n",
      "    \n",
      "    # linear regression\n",
      "    linRegress = linear_model.LinearRegression()\n",
      "    linRegress.fit(scaled_train_X, train_y)\n",
      "    linRegress_mse = metrics.mean_squared_error(test_y, linRegress.predict(scaled_test_X))\n",
      "    \n",
      "    # ridge regression\n",
      "    alphas = np.logspace(-2.0, 3.0, num=10)\n",
      "    ridge_clf = linear_model.Ridge()\n",
      "    parameters = {'alpha':alphas}\n",
      "    ridge_models = grid_search.GridSearchCV(ridge_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    ridge_models.fit(scaled_train_X, train_y)\n",
      "    ridge_mse = metrics.mean_squared_error(test_y, ridge_models.predict(scaled_test_X))\n",
      "    \n",
      "    # lasso regression\n",
      "    lasso_clf = linear_model.LassoLars()\n",
      "    lasso_models = grid_search.GridSearchCV(lasso_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    lasso_models.fit(scaled_train_X, train_y)\n",
      "    lasso_mse = metrics.mean_squared_error(test_y, lasso_models.predict(scaled_test_X))\n",
      "    \n",
      "    return [baseline_mse, linRegress_mse, ridge_mse, lasso_mse], [linRegress, ridge_models.best_estimator_, lasso_models.best_estimator_]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiTimeSplit_models_train_and_eval(features, target, future_days, history_days, n_split=100):\n",
      "\n",
      "    regress_accus = []\n",
      "    regress_baseline = []\n",
      "    \n",
      "    num_of_workers = multiprocessing.cpu_count()\n",
      "    pool = multiprocessing.Pool(num_of_workers)\n",
      "    regress_accus = pool.map(regression_train_and_eval, [(features[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    target[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    features[-i_split*future_days-1:-(i_split-1)*future_days-1],\n",
      "                                                    target[-i_split*future_days-1:-(i_split-1)*future_days-1]) \n",
      "                                                   for i_split in range(1, n_split+1)])\n",
      "    pool.terminate()\n",
      "    pool.join()\n",
      "    \n",
      "\n",
      "        # classification\n",
      "        # t_accus,_ = classifiers_train_and_eval(train_data, train_label, test_data, test_label)\n",
      "        # model_accus.append(t_accus)\n",
      "        \n",
      "#     return np.mean(regress_accus, axis=0), np.mean(regress_baseline)\n",
      "    return regress_accus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "future_days = 1\n",
      "history_days = 100\n",
      "n_split = 500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file regression_bundle.py\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import multiprocessing\n",
      "from sklearn import linear_model\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import preprocessing\n",
      "from sklearn import utils\n",
      "\n",
      "def regression_train_and_eval((train_X, train_y, test_X, test_y)):\n",
      "    # A bundle for training multiple regression models and then evaluate them\n",
      "    \n",
      "    score_criteria = 'mean_square_error'\n",
      "    num_cv = 5\n",
      "    # shuffle the training data in case cv is not shuffling at all\n",
      "    train_X, train_y = utils.shuffle(train_X, train_y, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    scaler = preprocessing.StandardScaler().fit(train_X)  # fit does nothing\n",
      "    scaled_train_X = scaler.transform(train_X)\n",
      "    scaled_test_X = scaler.transform(test_X)\n",
      "    \n",
      "    # baseline as always predict 0\n",
      "    baseline_mse = metrics.mean_squared_error(test_y, np.ones(len(test_y))*train_y.mean())\n",
      "    \n",
      "    # linear regression\n",
      "    linRegress = linear_model.LinearRegression()\n",
      "    linRegress.fit(scaled_train_X, train_y)\n",
      "    linRegress_mse = metrics.mean_squared_error(test_y, linRegress.predict(scaled_test_X))\n",
      "    \n",
      "    # ridge regression\n",
      "    alphas = np.logspace(-2.0, 3.0, num=10)\n",
      "    ridge_clf = linear_model.Ridge()\n",
      "    parameters = {'alpha':alphas}\n",
      "    ridge_models = grid_search.GridSearchCV(ridge_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    ridge_models.fit(scaled_train_X, train_y)\n",
      "    ridge_mse = metrics.mean_squared_error(test_y, ridge_models.predict(scaled_test_X))\n",
      "    \n",
      "    # lasso regression\n",
      "    lasso_clf = linear_model.LassoLars()\n",
      "    lasso_models = grid_search.GridSearchCV(lasso_clf, parameters, scoring='mean_squared_error', cv=num_cv)\n",
      "    lasso_models.fit(scaled_train_X, train_y)\n",
      "    lasso_mse = metrics.mean_squared_error(test_y, lasso_models.predict(scaled_test_X))\n",
      "    \n",
      "    return [baseline_mse, linRegress_mse, ridge_mse, lasso_mse], [linRegress, ridge_models.best_estimator_, lasso_models.best_estimator_]\n",
      "\n",
      "def multiTimeSplit_models_train_and_eval(features, target, future_days, history_days, n_split=100):\n",
      "\n",
      "    regress_accus = []\n",
      "    regress_baseline = []\n",
      "    \n",
      "    num_of_workers = multiprocessing.cpu_count()\n",
      "    pool = multiprocessing.Pool(num_of_workers)\n",
      "    regress_outputs = pool.map(regression_train_and_eval, [(features[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    target[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    features[-i_split*future_days-1:-(i_split-1)*future_days-1],\n",
      "                                                    target[-i_split*future_days-1:-(i_split-1)*future_days-1]) \n",
      "                                                   for i_split in range(1, n_split+1)])\n",
      "    pool.terminate()\n",
      "    pool.join()\n",
      "    \n",
      "    regress_accus_and_models = pd.DataFrame(regress_outputs, columns=['accus', 'models'])\n",
      "    regress_accus = []\n",
      "    for i in range(len(regress_accus_and_models)):\n",
      "        regress_accus.append(regress_accus_and_models['accus'][i])\n",
      "    regress_accus = pd.DataFrame(regress_accus, columns=['baseline','linear_regression', 'ridge_regression', 'lasso_regression'])\n",
      "    \n",
      "    return regress_accus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting regression_bundle.py\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time1 = time.time()\n",
      "output = multiTimeSplit_models_train_and_eval(linRegress_features, linRegress_target, future_days, history_days, n_split)\n",
      "print time.time()-time1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "38.9194028378\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accus_and_models = pd.DataFrame(output, columns=['accus', 'models'])\n",
      "accus = []\n",
      "for i in range(len(accus_and_models)):\n",
      "    accus.append(accus_and_models['accus'][i])\n",
      "accus = pd.DataFrame(accus, columns=['baseline','linear_regression', 'ridge_regression', 'lasso_regression'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accus.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "baseline             0.000002\n",
        "linear_regression    0.000003\n",
        "ridge_regression     0.000001\n",
        "lass_regression      0.000002\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Observation: \n",
      "-- baseline is doing better\n",
      "## We simplify the problem by making it a classification problem ##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grid_search_then_eval(train_data, train_label, test_data, test_label, clf, parameters, score_criteria, num_cv):\n",
      "    import sklearn as sk\n",
      "    models = sk.grid_search.GridSearchCV(clf, parameters, scoring=score_criteria, cv=num_cv)\n",
      "    models.fit(train_data, train_label)\n",
      "    opt_model = models.best_estimator_\n",
      "    if score_criteria == 'accuracy':\n",
      "        opt_model_accu = sk.metrics.accuracy_score(test_label, opt_model.predict(test_data))\n",
      "    elif score_criteria == 'roc_auc':\n",
      "        opt_model_accu = sk.metrics.roc_auc_score(test_label, opt_model.predict(test_data))\n",
      "    return opt_model_accu, opt_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifiers_train_and_eval((train_data, train_label, test_data, test_label)):\n",
      "    # A bundle for training multiple classifiers and then evaluate them\n",
      "    \n",
      "    score_criteria = 'accuracy'\n",
      "    num_cv = 5\n",
      "    # shuffle the training data in case cv is not shuffling at all\n",
      "    train_data, train_label = sk.utils.shuffle(train_data, train_label, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    scaler = sk.preprocessing.StandardScaler().fit(train_data)  # fit does nothing\n",
      "    scaled_train_data = scaler.transform(train_data)\n",
      "    scaled_test_data = scaler.transform(test_data)\n",
      "    \n",
      "    # linear models\n",
      "    Cs = np.logspace(-3., 3., num=10)\n",
      "\n",
      "    # logistic regression\n",
      "    start_time = time.time()\n",
      "    LR_clf = linear_model.LogisticRegression()\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LR_accu, opt_LR = grid_search_then_eval(train_data, train_label, test_data, test_label, LR_clf, parameters, score_criteria, num_cv)\n",
      "#     print 'logisitc regression'\n",
      "#     print time.time()-start_time\n",
      "    \n",
      "    # linear SVM\n",
      "    start_time = time.time()\n",
      "    LinSVM_clf = svm.LinearSVC(loss='l1')\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LinSVM_accu, opt_LinSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, LinSVM_clf, parameters, score_criteria, num_cv)\n",
      "#     print 'linear SVM'\n",
      "#     print time.time()-start_time\n",
      "    \n",
      "    # non-linear models\n",
      "    # RBF SVM\n",
      "    start_time = time.time()\n",
      "    gammas = np.logspace(-3., 3., num=10)\n",
      "    RBFSVM_clf = svm.SVC(kernel='rbf')\n",
      "    parameters = {'C':Cs, 'gamma':gammas}\n",
      "    opt_RBFSVM_accu, opt_RBFSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, RBFSVM_clf, parameters, score_criteria, num_cv)\n",
      "#     print 'RBF SVM'\n",
      "#     print time.time()-start_time\n",
      "\n",
      "    \n",
      "    # Random Forest\n",
      "    start_time = time.time()\n",
      "    max_depths= range(2, 10, 2) \n",
      "    min_samples_splits= [10, 20, 40, 80, 120]\n",
      "    RF_clf = ensemble.RandomForestClassifier()\n",
      "    parameters = {'max_depth': max_depths, 'min_samples_split':min_samples_splits}\n",
      "    opt_RF_accu, opt_RF = grid_search_then_eval(train_data, train_label, test_data, test_label, RF_clf, parameters, score_criteria, num_cv)\n",
      "#     print 'Random Forrest'\n",
      "#     print time.time()-start_time\n",
      "    \n",
      "    # Adaboost Trees\n",
      "    start_time = time.time()\n",
      "    n_estimators = [100, 300, 1000]\n",
      "    AdaTree_clf = ensemble.AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': n_estimators}\n",
      "    opt_AdaTree_accu, opt_AdaTree = grid_search_then_eval(train_data, train_label, test_data, test_label, AdaTree_clf, parameters, score_criteria, num_cv)\n",
      "#     print 'Adaboost Trees'\n",
      "#     print time.time()-start_time\n",
      "    \n",
      "    return [opt_LR_accu, opt_LinSVM_accu, opt_RBFSVM_accu, opt_RF_accu, opt_AdaTree_accu], [opt_LR, opt_LinSVM, opt_RBFSVM, opt_RF, opt_AdaTree]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiTimeSplit_classifier_eval(features, labels, future_days, history_days, n_split=100):\n",
      "\n",
      "    num_of_workers = multiprocessing.cpu_count()\n",
      "    pool = multiprocessing.Pool(num_of_workers)\n",
      "    classifier_accus = pool.map(classifiers_train_and_eval, [(features[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    labels[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    features[-i_split*future_days-1:-(i_split-1)*future_days-1],\n",
      "                                                    labels[-i_split*future_days-1:-(i_split-1)*future_days-1]) \n",
      "                                                   for i_split in range(1, n_split+1)])\n",
      "    pool.terminate()\n",
      "    pool.join()\n",
      "\n",
      "    \n",
      "    return classifier_accus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file classification_bundle.py\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn import ensemble\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import preprocessing\n",
      "from sklearn import utils\n",
      "import multiprocessing\n",
      "\n",
      "def grid_search_then_eval(train_data, train_label, test_data, test_label, clf, parameters, score_criteria, num_cv):\n",
      "    models = grid_search.GridSearchCV(clf, parameters, scoring=score_criteria, cv=num_cv)\n",
      "    models.fit(train_data, train_label)\n",
      "    opt_model = models.best_estimator_\n",
      "    if score_criteria == 'accuracy':\n",
      "        opt_model_accu = metrics.accuracy_score(test_label, opt_model.predict(test_data))\n",
      "    elif score_criteria == 'roc_auc':\n",
      "        opt_model_accu = metrics.roc_auc_score(test_label, opt_model.predict(test_data))\n",
      "    return opt_model_accu, opt_model\n",
      "\n",
      "def classifiers_train_and_eval((train_data, train_label, test_data, test_label)):\n",
      "    # A bundle for training multiple classifiers and then evaluate them\n",
      "    \n",
      "    score_criteria = 'accuracy'\n",
      "    num_cv = 5\n",
      "    # shuffle the training data in case cv is not shuffling at all\n",
      "    train_data, train_label = utils.shuffle(train_data, train_label, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    scaler = preprocessing.StandardScaler().fit(train_data)  # fit does nothing\n",
      "    scaled_train_data = scaler.transform(train_data)\n",
      "    scaled_test_data = scaler.transform(test_data)\n",
      "    \n",
      "    # baseline: predict the major class of training samples to all test samples \n",
      "    mode_label = stats.mode(train_label.astype(float))[0][0] # the majority label of the training samples\n",
      "    if score_criteria == 'accuracy':\n",
      "        baseline_accu = metrics.accuracy_score(test_label, np.ones(len(test_label))*mode_label)\n",
      "    elif score_criteria == 'roc_auc':\n",
      "        baseline_accu = metrics.roc_auc_score(test_label, np.ones(len(test_label))*mode_label)\n",
      "\n",
      "    # linear models\n",
      "    # logistic regression\n",
      "    Cs = np.logspace(-3., 3., num=10)\n",
      "    LR_clf = linear_model.LogisticRegression()\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LR_accu, opt_LR = grid_search_then_eval(train_data, train_label, test_data, test_label, LR_clf, parameters, score_criteria, num_cv)\n",
      "    \n",
      "    # linear SVM\n",
      "    LinSVM_clf = svm.LinearSVC(loss='l1')\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LinSVM_accu, opt_LinSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, LinSVM_clf, parameters, score_criteria, num_cv)\n",
      "    \n",
      "    # non-linear models\n",
      "    # RBF SVM\n",
      "    gammas = np.logspace(-3., 3., num=10)\n",
      "    RBFSVM_clf = svm.SVC(kernel='rbf')\n",
      "    parameters = {'C':Cs, 'gamma':gammas}\n",
      "    opt_RBFSVM_accu, opt_RBFSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, RBFSVM_clf, parameters, score_criteria, num_cv)\n",
      "    \n",
      "    # Random Forest\n",
      "    max_depths= range(2, 10, 2) \n",
      "    min_samples_splits= [10, 20, 40, 80, 120]\n",
      "    RF_clf = ensemble.RandomForestClassifier()\n",
      "    parameters = {'max_depth': max_depths, 'min_samples_split':min_samples_splits}\n",
      "    opt_RF_accu, opt_RF = grid_search_then_eval(train_data, train_label, test_data, test_label, RF_clf, parameters, score_criteria, num_cv)\n",
      "    \n",
      "    # Adaboost Trees\n",
      "    n_estimators = [100, 300, 1000]\n",
      "    AdaTree_clf = ensemble.AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': n_estimators}\n",
      "    opt_AdaTree_accu, opt_AdaTree = grid_search_then_eval(train_data, train_label, test_data, test_label, AdaTree_clf, parameters, score_criteria, num_cv)\n",
      "    \n",
      "    return [baseline_accu, opt_LR_accu, opt_LinSVM_accu, opt_RBFSVM_accu, opt_RF_accu, opt_AdaTree_accu], [opt_LR, opt_LinSVM, opt_RBFSVM, opt_RF, opt_AdaTree]\n",
      "\n",
      "def multiTimeSplit_classifier_eval(features, labels, future_days, history_days, n_split=100):\n",
      "\n",
      "    num_of_workers = multiprocessing.cpu_count()\n",
      "    pool = multiprocessing.Pool(num_of_workers)\n",
      "    classifiers_output = pool.map(classifiers_train_and_eval, [(features[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    labels[-history_days-i_split*future_days-1:-i_split*future_days-1],\n",
      "                                                    features[-i_split*future_days-1:-(i_split-1)*future_days-1],\n",
      "                                                    labels[-i_split*future_days-1:-(i_split-1)*future_days-1]) \n",
      "                                                   for i_split in range(1, n_split+1)])\n",
      "    pool.close()\n",
      "    pool.join()\n",
      "\n",
      "    classification_accus_and_models = pd.DataFrame(classifiers_output, columns=['accus', 'models'])\n",
      "    classification_accus = []\n",
      "    for i in range(len(classification_accus_and_models)):\n",
      "        classification_accus.append(classification_accus_and_models['accus'][i])\n",
      "    classification_accus = pd.DataFrame(classification_accus, columns=['baseline', 'logistic_regression','linear_svm', 'rbf_svm', 'random_forrest', 'adaboost_trees'])\n",
      "    classification_models = classification_accus_and_models['models'] \n",
      "    \n",
      "    return classification_accus, classification_models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting classification_bundle.py\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "future_days = 1\n",
      "history_days = 100\n",
      "n_split = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "percentile = 70\n",
      "classification_labels = np.abs(linRegress_target) > np.percentile(np.abs(linRegress_target[-n_split*future_days-1:-1]), percentile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time1 = time.time()\n",
      "output = multiTimeSplit_classifier_eval(linRegress_features, classification_labels, future_days, history_days, n_split)\n",
      "print time.time()-time1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2989.77828693\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classification_accus_and_models = pd.DataFrame(output, columns=['accus', 'models'])\n",
      "classification_accus = []\n",
      "for i in range(len(classification_accus_and_models)):\n",
      "    classification_accus.append(classification_accus_and_models['accus'][i])\n",
      "classification_accus = pd.DataFrame(classification_accus, columns=['logistic_regression','linear_svm', 'rbf_svm', 'random_forrest', 'adaboost_trees'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classification_accus.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "logistic_regression    0.66\n",
        "linear_svm             0.67\n",
        "rbf_svm                0.69\n",
        "random_forrest         0.71\n",
        "adaboost_trees         0.57\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.sum(classification_labels[-101:-1] == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "70\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}