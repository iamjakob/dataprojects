{
 "metadata": {
  "name": "",
  "signature": "sha256:445433eb51b472eb7bb712a4ccd2136270189e74c1d2bcaeecae9c92888860a4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The program \"ProSharesUltraProShort_SQQQ_vs_Nasdaq100\" is used for single pair exploration so that we could understand the details of the problem and the data. This program is to apply what we formulate there to multiple fund-index pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the data frame way is not quite convinient, so we make it dictionary\n",
      "# The last value of each fund index code pair is the direction that the fund claims to moving relative to the index\n",
      "import pandas as pd\n",
      "start_date = \"2005-01-01\"\n",
      "days_back = 3\n",
      "df_fund_index_pair_codes = pd.DataFrame(\n",
      "[(\"GOOG/NYSE_SQQQ\", \"YAHOO/INDEX_NDX\", -3),\n",
      "(\"GOOG/NYSEARCA_QID\", \"YAHOO/INDEX_NDX\", -2),\n",
      "(\"GOOG/NYSE_TZA\", \"YAHOO/INDEX_RUT\", -3),\n",
      "(\"GOOG/NYSEARCA_SSO\", \"YAHOO/INDEX_GSPC\", 2),\n",
      "(\"GOOG/NYSEARCA_SPXL\", \"YAHOO/INDEX_GSPC\", 3),\n",
      "(\"GOOG/NYSEARCA_IYY\", \"YAHOO/DWCF\", 1),\n",
      "(\"GOOG/NYSEARCA_IVV\", \"YAHOO/INDEX_GSPC\", 1)\n",
      "], columns=['fund_code', 'index_code', 'direction'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/wuyang/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pull_fund_and_index_data(fund_code, index_code, start_date):\n",
      "    # load data either from Quandl or local csv if they exist there\n",
      "    # local csv file names\n",
      "    import Quandl\n",
      "    import pandas as pd\n",
      "    import os.path\n",
      "    fund_file_name = \"../data/\" + fund_code.replace(\"/\", \"_\") + \".csv\"\n",
      "    index_file_name = \"../data/\" + index_code.replace(\"/\", \"_\") + \".csv\"\n",
      "    if os.path.isfile(fund_file_name): # file exists at local\n",
      "        fund_data = pd.io.parsers.read_csv(fund_file_name, index_col=0) # the csv file has to be parsed to have date as index\n",
      "    else: # download from Quandl and save it to local as csv file\n",
      "        fund_data = Quandl.get(fund_code, trim_start=start_date, authtoken=\"XANwfFd9CmdoE3PdFzRg\")\n",
      "        fund_data.to_csv(fund_file_name)\n",
      "    if os.path.isfile(index_file_name):\n",
      "        index_data = pd.io.parsers.read_csv(index_file_name, index_col=0) # the csv file has to be parsed to have date as index\n",
      "    else:\n",
      "        index_data = Quandl.get(index_code, trim_start=start_date, authtoken=\"XANwfFd9CmdoE3PdFzRg\")\n",
      "        index_data.to_csv(index_file_name)\n",
      "\n",
      "    # rename columns so that the two dataframes don't share any common names\n",
      "    index_data.columns = map(''.join, zip([index_code+'_']*index_data.shape[1], list(index_data.columns))) # rename the columns with index_code as prefix\n",
      "    fund_data.columns = map(''.join, zip([fund_code+'_']*fund_data.shape[1], list(fund_data.columns)))\n",
      "    \n",
      "    # join the two data frames by date\n",
      "    fund_and_index = fund_data.join(index_data, how='inner') \n",
      "    \n",
      "    return fund_and_index    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove Outliers\n",
      "def outliers_by_moving_average(data, num_neighbor, threshold):\n",
      "    # This function returns the indexes of samples that moves far away (greater than a threshold)\n",
      "    # from the mean of its neighbors\n",
      "    # data: an array contains the data\n",
      "    # num_neighbor: number of neighbors\n",
      "    # threshold: threshold to be considered large\n",
      "    # Note: the first and last num_neighbor samples are simply considered normal\n",
      "    \n",
      "    import numpy as np\n",
      "    outlier = []\n",
      "    for i_spl in xrange(num_neighbor, len(data)-num_neighbor):\n",
      "        if np.abs(data[i_spl]/np.mean(np.append(data[i_spl-num_neighbor:i_spl],data[i_spl+1:i_spl+num_neighbor+1])) -1) > threshold:\n",
      "            outlier.append(i_spl)\n",
      "    return outlier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feature_preparation(fund_and_index, direction, days_back):\n",
      "    import numpy as np\n",
      "    # transform the data into array for applying scikit learn\n",
      "    # nan's are filled by interpolation.\n",
      "    array_fund_and_index = np.array(fund_and_index.interpolate())\n",
      "    \n",
      "    # remove outliers of index value\n",
      "    index_outliers = outliers_by_moving_average(array_fund_and_index[:,10], 1, 0.5) # get the row numbers of outliers in index\n",
      "                                                                                    # column 10 is the adjusted close price of index\n",
      "    array_FnI = np.delete(array_fund_and_index, index_outliers, axis=0)\n",
      "    \n",
      "    # daily changes of fund close price and index adjusted close price\n",
      "    fund_change_pcg = (array_FnI[1:,3:4] - array_FnI[:-1,3:4])/array_FnI[:-1,3:4]   # column 3 is the close price of fund\n",
      "    index_change_pcg = (array_FnI[1:,10:11] - array_FnI[:-1,10:11])/array_FnI[:-1,10:11]  # daily rative change of index value\n",
      "    \n",
      "    # absolute changes, maybe more useful\n",
      "    fund_abs_change_pcg = np.abs(fund_change_pcg)\n",
      "    index_abs_change_pcg = np.abs(index_change_pcg)\n",
      "    \n",
      "    # difference and absolute difference bwtween the changes of fund and index\n",
      "    diff_pcg = fund_change_pcg - index_change_pcg*direction # difference between the leveraged index move and fund move;\n",
      "    abs_diff_pcg = np.abs(diff_pcg)\n",
      "\n",
      "    # target variable\n",
      "#     target_variable = diff_pcg[days_back:]\n",
      "    target_variable = abs_diff_pcg[days_back:] # maybe only absolute difference is easier to calculate\n",
      "\n",
      "    # concatenate the data of past as features\n",
      "    ## maybe should exclude some features\n",
      "    features = np.concatenate((array_FnI[days_back:-1,:], diff_pcg[(days_back-1):-1]), axis=1)\n",
      "    for i_dayback in xrange(1, days_back):\n",
      "        features = np.concatenate((features, array_FnI[(days_back-i_dayback):(-1-i_dayback),:], \n",
      "                                   abs_diff_pcg[(days_back-i_dayback-1):(-1-i_dayback)]), axis=1)\n",
      "\n",
      "    # remove points that jump on fund price, due to e.g. stock split or merge\n",
      "    target_variable = target_variable[np.abs(fund_change_pcg[days_back:]) < 0.2]\n",
      "    features = features[(np.abs(fund_change_pcg[days_back:]) < 0.2).flatten(),:]\n",
      "    \n",
      "    return features, target_variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_error(clf, X, y, score_criteria='mean_squared_error', regression_or_classifiation=1): # test a classifier for given data with cross validation\n",
      "    from sklearn import cross_validation\n",
      "    # fix the \"random\" patition of cross validation\n",
      "    cv = cross_validation.ShuffleSplit(len(y), n_iter=20, test_size=0.2, random_state=42)\n",
      "    \n",
      "    # the regression score is negative mean square error and thus multiply result by -1\n",
      "    # this is not necessary for classification\n",
      "    # therefore, we use regression_or_classification to offset (1 for regression, -1 for classification)    \n",
      "    return - cross_validation.cross_val_score(clf, X, y, cv=cv, scoring=score_criteria).mean()*regression_or_classifiation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Linear Regressions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def regression_scores(features, target_variable): # use cross validation to test various regression methods\n",
      "    import sklearn as sk\n",
      "    from sklearn import linear_model\n",
      "    import pandas as pd\n",
      "    \n",
      "    # shuffle the data in case cv is not shuffling at all\n",
      "    features, target_variable = sk.utils.shuffle(features, target_variable, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    normalized_features = sk.preprocessing.normalize(features, axis=0)\n",
      "    \n",
      "    # tuning parameter\n",
      "    alphas = np.logspace(-5., 3., num=20)\n",
      "\n",
      "    # regular linear regression\n",
      "    linear_model_MSE = compute_error(linear_model.LinearRegression(), normalized_features, target_variable)\n",
      "    \n",
      "    # ridge regression models\n",
      "    ridge_models = pd.DataFrame(\n",
      "        [(alpha,\n",
      "          \"Ridge Regression with alpha = %f\" % alpha, \n",
      "          compute_error(linear_model.Ridge(alpha=alpha), normalized_features, target_variable)) for alpha in alphas]\n",
      "    , columns=['alpha', 'Model', 'MSE'])\n",
      "    \n",
      "    # lasso regression models\n",
      "    lasso_models = pd.DataFrame(\n",
      "        [(alpha,\n",
      "          \"Lasso Regression with alpha = %f\" % alpha,\n",
      "          compute_error(linear_model.LassoLars(alpha=alpha), normalized_features, target_variable)) for alpha in alphas]\n",
      "    , columns=['alpha', 'Model', 'MSE'])\n",
      "    \n",
      "    return linear_model_MSE, ridge_models, lasso_models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def linear_model_for_fund_index_regression(fund_code, index_code, direction, days_back):\n",
      "    fund_and_index = pull_fund_and_index_data(fund_code, index_code, start_date)\n",
      "    features, target_variable = feature_preparation(fund_and_index, direction, days_back)\n",
      "    linear_model_mse, ridge_models, lasso_models = regression_scores(features, target_variable)\n",
      "    return linear_model_mse, ridge_models, lasso_models, target_variable.var()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "for index, row in df_fund_index_pair_codes:\n",
      "    linear_regress_mse, ridge_models, lasso_models, var_y = linear_model_for_fund_index_regression(fund_code, fund_index_pair_codes[fund_code][0], fund_index_pair_codes[fund_code][1], days_back)\n",
      "    print fund_code\n",
      "    print linear_regress_mse, var_y\n",
      "    ridge_models.plot(x='alpha', y='MSE', logx=True, title='MSE')\n",
      "    plt.show()\n",
      "    lasso_models.plot(x='alpha', y='MSE', logx=True, title='MSE')\n",
      "    plt.show()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Linear Classifications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def classification_score(features, labels):\n",
      "    import sklearn as sk\n",
      "    from sklearn import linear_model\n",
      "    import pandas as pd\n",
      "    \n",
      "    # shuffle the data in case cv is not shuffling at all\n",
      "    features, labels = sk.utils.shuffle(features, labels, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    normalized_features = sk.preprocessing.normalize(features, axis=0)\n",
      "    \n",
      "    # tuning parameter\n",
      "    Cs = np.logspace(-3., 3., num=10)\n",
      "\n",
      "    # logistic regression models\n",
      "    logistic_models = pd.DataFrame(\n",
      "        [(C,\n",
      "          \"Logistic Regression with C = %f\" % C, \n",
      "          compute_error(linear_model.LogisticRegression(C=C), normalized_features, labels, score_criteria='accuracy', regression_or_classifiation=-1)) for C in Cs]\n",
      "    , columns=['C', 'Model', 'Accuracy'])\n",
      "    \n",
      "    # linear SVM models\n",
      "    linSVM_models = pd.DataFrame(\n",
      "        [(C,\n",
      "          \"Linear SVM with C = %f\" % C,\n",
      "          compute_error(sk.svm.LinearSVC(C=C, loss='l1'), normalized_features, labels, score_criteria='accuracy', regression_or_classifiation=-1)) for C in Cs]\n",
      "    , columns=['C', 'Model', 'Accuracy'])\n",
      "    \n",
      "    return logistic_models, linSVM_models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "percentile = 70\n",
      "for fund_code in fund_index_pair_codes:\n",
      "    logistic_regression, linearSVM = linear_model_for_fund_index_classification(fund_code, fund_index_pair_codes[fund_code][0], fund_index_pair_codes[fund_code][1], days_back, percentile)\n",
      "    print fund_code\n",
      "    logistic_regression.plot(x='C', y='Accuracy', logx=True, title='logistic regression')\n",
      "    plt.show()\n",
      "    linearSVM.plot(x='C', y='Accuracy', logx=True, title='linear SVM')\n",
      "    plt.show()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifiers_train_and_eval(train_data, train_label, test_data, test_label):\n",
      "    # A bundle for training multiple classifiers and then evaluate them\n",
      "    import sklearn as sk\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    import time\n",
      "    from sklearn import linear_model\n",
      "    from sklearn import svm\n",
      "    from sklearn import ensemble\n",
      "    \n",
      "    score_criteria = 'accuracy'\n",
      "    num_cv = 5\n",
      "    # shuffle the training data in case cv is not shuffling at all\n",
      "    train_data, train_label = sk.utils.shuffle(train_data, train_label, random_state=42)\n",
      "\n",
      "    # normalized the data as a standard procedure\n",
      "    scaler = sk.preprocessing.StandardScaler().fit(train_data)  # fit does nothing\n",
      "    scaled_train_data = scaler.transform(train_data)\n",
      "    scaled_test_data = scaler.transform(test_data)\n",
      "    \n",
      "    # linear models\n",
      "    Cs = np.logspace(-3., 3., num=10)\n",
      "\n",
      "    # logistic regression\n",
      "    start_time = time.time()\n",
      "    LR_clf = linear_model.LogisticRegression()\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LR_accu, opt_LR = grid_search_then_eval(train_data, train_label, test_data, test_label, LR_clf, parameters, score_criteria, num_cv)\n",
      "    print 'logisitc regression'\n",
      "    print time.time()-start_time\n",
      "    \n",
      "    # linear SVM\n",
      "    start_time = time.time()\n",
      "    LinSVM_clf = svm.LinearSVC(loss='l1')\n",
      "    parameters = {'C':Cs}\n",
      "    opt_LinSVM_accu, opt_LinSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, LinSVM_clf, parameters, score_criteria, num_cv)\n",
      "    print 'linear SVM'\n",
      "    print time.time()-start_time\n",
      "    \n",
      "    # non-linear models\n",
      "    # RBF SVM\n",
      "    start_time = time.time()\n",
      "    gammas = np.logspace(-3., 3., num=10)\n",
      "    RBFSVM_clf = svm.SVC(kernel='rbf')\n",
      "    parameters = {'C':Cs, 'gamma':gammas}\n",
      "    opt_RBFSVM_accu, opt_RBFSVM = grid_search_then_eval(train_data, train_label, test_data, test_label, RBFSVM_clf, parameters, score_criteria, num_cv)\n",
      "    print 'RBF SVM'\n",
      "    print time.time()-start_time\n",
      "\n",
      "    \n",
      "    # Random Forest\n",
      "    start_time = time.time()\n",
      "    max_depths= range(2, 10, 2) \n",
      "    min_samples_splits= [10, 20, 40, 80, 120]\n",
      "    RF_clf = ensemble.RandomForestClassifier()\n",
      "    parameters = {'max_depth': max_depths, 'min_samples_split':min_samples_splits}\n",
      "    opt_RF_accu, opt_RF = grid_search_then_eval(train_data, train_label, test_data, test_label, RF_clf, parameters, score_criteria, num_cv)\n",
      "    print 'Random Forrest'\n",
      "    print time.time()-start_time\n",
      "\n",
      "    return [opt_LR_accu, opt_LinSVM_accu, opt_RBFSVM_accu, opt_RF_accu], [opt_LR, opt_LinSVM, opt_RBFSVM, opt_RF]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grid_search_then_eval(train_data, train_label, test_data, test_label, clf, parameters, score_criteria, num_cv):\n",
      "    import sklearn as sk\n",
      "    models = sk.grid_search.GridSearchCV(clf, parameters, scoring=score_criteria, cv=num_cv)\n",
      "    models.fit(train_data, train_label)\n",
      "    opt_model = models.best_estimator_\n",
      "    opt_model_accu = sk.metrics.accuracy_score(test_label, opt_model.predict(test_data))\n",
      "    return opt_model_accu, opt_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiRun_classifier_eval(features, labels):\n",
      "    import numpy as np\n",
      "    n_iter = 2\n",
      "    test_size = 0.2\n",
      "    \n",
      "    from sklearn import cross_validation\n",
      "    mrun = cross_validation.ShuffleSplit(len(labels), n_iter=n_iter, test_size=test_size)\n",
      "    model_accus = []\n",
      "    for train_index, test_index in mrun:\n",
      "        t_accus, t_models = classifiers_train_and_eval(features[train_index], labels[train_index], features[test_index], labels[test_index])\n",
      "        model_accus.append(t_accus)\n",
      "        \n",
      "    return np.mean(model_accus, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linear_model_for_fund_index_classification(fund_code, index_code, direction, days_back, percentile):\n",
      "    import numpy as np\n",
      "    fund_and_index = pull_fund_and_index_data(fund_code, index_code, start_date)\n",
      "    features, target_variable = feature_preparation(fund_and_index, direction, days_back)\n",
      "    labels = np.abs(target_variable) > np.percentile(np.abs(target_variable), percentile)\n",
      "#     logistic_regression, linearSVM = classification_score(features, labels)\n",
      "    model_accus = multiRun_classifier_eval(features, labels)\n",
      "    return model_accus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pairs_deviation(df_fund_index_pair_codes, days_back, percentile):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    \n",
      "    average_accuracies = pd.DataFrame([\n",
      "        linear_model_for_fund_index_classification(row['fund_code'], row['index_code'], row['direction'], days_back, percentile) for index, row in df_fund_index_pair_codes.iterrows()]\n",
      "        , columns= ['logistic regression', 'linear SVM', 'RBF SVM', 'random forest']\n",
      "        )\n",
      "    return df_fund_index_pair_codes.join(average_accuracies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "days_back = 3\n",
      "percentile = 60"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_pairs_deviation = pairs_deviation(df_fund_index_pair_codes, days_back, percentile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "logisitc regression\n",
        "1.17411088943\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10.6455259323\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "85.4062809944\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3.6429901123\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.521536827087\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11.0085999966\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "86.115238905\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3.73104906082\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.61189699173\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11.9538998604\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "95.3236029148\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4.05131196976\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.658246040344\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11.5045990944\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "93.1507411003\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3.944024086\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.01841402054\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8.45331501961\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "49.3506040573\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.86438679695\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.03399205208\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8.02262997627\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48.0277588367\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.85897898674\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.19549107552\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.0797331333\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102.328613043\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.74215197563\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.64625310898\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14.8646528721\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "96.780203104\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3.91622495651\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.206818819046\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.42121911049\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.16771912575\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.65850710869\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.425187110901\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.42671513557\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.10932183266\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.33402395248\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.196938991547\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.43502306938\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.70243597031\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.35968017578\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.211071968079\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.36212396622\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6.56965708733\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.38077688217\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.741515874863\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13.9940199852\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "148.723400116\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9.51148676872\n",
        "logisitc regression"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.63451004028\n",
        "linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28.9812328815\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "286.933379889\n",
        "Random Forrest"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5.72304797173\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_pairs_deviation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>fund_code</th>\n",
        "      <th>index_code</th>\n",
        "      <th>direction</th>\n",
        "      <th>logistic regression</th>\n",
        "      <th>linear SVM</th>\n",
        "      <th>RBF SVM</th>\n",
        "      <th>random forest</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     GOOG/NYSE_SQQQ</td>\n",
        "      <td>  YAHOO/INDEX_NDX</td>\n",
        "      <td>-3</td>\n",
        "      <td> 0.589189</td>\n",
        "      <td> 0.589189</td>\n",
        "      <td> 0.589189</td>\n",
        "      <td> 0.624324</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  GOOG/NYSEARCA_QID</td>\n",
        "      <td>  YAHOO/INDEX_NDX</td>\n",
        "      <td>-2</td>\n",
        "      <td> 0.591371</td>\n",
        "      <td> 0.591371</td>\n",
        "      <td> 0.591371</td>\n",
        "      <td> 0.625635</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      GOOG/NYSE_TZA</td>\n",
        "      <td>  YAHOO/INDEX_RUT</td>\n",
        "      <td>-3</td>\n",
        "      <td> 0.600358</td>\n",
        "      <td> 0.496416</td>\n",
        "      <td> 0.584229</td>\n",
        "      <td> 0.654122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  GOOG/NYSEARCA_SSO</td>\n",
        "      <td> YAHOO/INDEX_GSPC</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0.646250</td>\n",
        "      <td> 0.601250</td>\n",
        "      <td> 0.601250</td>\n",
        "      <td> 0.716250</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> GOOG/NYSEARCA_SPXL</td>\n",
        "      <td> YAHOO/INDEX_GSPC</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0.535714</td>\n",
        "      <td> 0.530612</td>\n",
        "      <td> 0.530612</td>\n",
        "      <td> 0.561224</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>  GOOG/NYSEARCA_IYY</td>\n",
        "      <td>       YAHOO/DWCF</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.631068</td>\n",
        "      <td> 0.592233</td>\n",
        "      <td> 0.650485</td>\n",
        "      <td> 0.645631</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>  GOOG/NYSEARCA_IVV</td>\n",
        "      <td> YAHOO/INDEX_GSPC</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.586316</td>\n",
        "      <td> 0.506316</td>\n",
        "      <td> 0.596842</td>\n",
        "      <td> 0.670526</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "            fund_code        index_code  direction  logistic regression  \\\n",
        "0      GOOG/NYSE_SQQQ   YAHOO/INDEX_NDX         -3             0.589189   \n",
        "1   GOOG/NYSEARCA_QID   YAHOO/INDEX_NDX         -2             0.591371   \n",
        "2       GOOG/NYSE_TZA   YAHOO/INDEX_RUT         -3             0.600358   \n",
        "3   GOOG/NYSEARCA_SSO  YAHOO/INDEX_GSPC          2             0.646250   \n",
        "4  GOOG/NYSEARCA_SPXL  YAHOO/INDEX_GSPC          3             0.535714   \n",
        "5   GOOG/NYSEARCA_IYY        YAHOO/DWCF          1             0.631068   \n",
        "6   GOOG/NYSEARCA_IVV  YAHOO/INDEX_GSPC          1             0.586316   \n",
        "\n",
        "   linear SVM   RBF SVM  random forest  \n",
        "0    0.589189  0.589189       0.624324  \n",
        "1    0.591371  0.591371       0.625635  \n",
        "2    0.496416  0.584229       0.654122  \n",
        "3    0.601250  0.601250       0.716250  \n",
        "4    0.530612  0.530612       0.561224  \n",
        "5    0.592233  0.650485       0.645631  \n",
        "6    0.506316  0.596842       0.670526  "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_pairs_deviation.to_csv('pairs_deviation_various_methods')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame([t1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "   0  1  2  3\n",
        "0  1  2  3  4"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = [3, 2, 4, 2]\n",
      "pd.DataFrame([t1,t2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> 4</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "   0  1  2  3\n",
        "0  1  2  3  4\n",
        "1  3  2  4  2"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(t2, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([ 1.,  2.,  3.,  4.])"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}