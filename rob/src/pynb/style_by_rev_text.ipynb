{
 "metadata": {
  "name": "",
  "signature": "sha256:4e35f593347099cd93ae536c4a3758b4ce9552f6e0143591d255085c1f82d30c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import nltk.tokenize\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, TfidfTransformer\n",
      "from sklearn import cross_validation as c_v #,neighbors, datasets, grid_search\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 280
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to db\n",
      "%load_ext sql\n",
      "%sql mysql://root:rootpwd@localhost/beerad\n",
      "\n",
      "# suppress row counts\n",
      "%config SqlMagic.feedback = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The sql extension is already loaded. To reload it, use:\n",
        "  %reload_ext sql\n"
       ]
      }
     ],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get top 10 styles by review count\n",
      "styles = %sql \\\n",
      "select be.style_id, count(r.review) as b_ct \\\n",
      "from \\\n",
      "    beers be inner join reviews r \\\n",
      "        on be.id = r.beer_id \\\n",
      "    inner join styles s \\\n",
      "        on be.style_id = s.id \\\n",
      "group by be.style_id \\\n",
      "order by b_ct desc \\\n",
      "limit 5\n",
      "\n",
      "styles = styles.DataFrame()[\"style_id\"].values\n",
      "styles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 304,
       "text": [
        "array([116, 140,  97,  84, 159])"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get 1000 reviews for each of the top 10 styles\n",
      "# need to go back and re-upload reviews to account for\n",
      "# \"Presentation\" error. These are actually the best reviews,\n",
      "# i.e. from The Bros, and used the delimiter \"Presentation:\" to start\n",
      "# the review text. Other 'power users' probably did the same\n",
      "revs = pd.DataFrame()\n",
      "for i in styles:\n",
      "    dt = %sql  \\\n",
      "        select r.review, be.style_id \\\n",
      "        from reviews r inner join beers be \\\n",
      "            on r.beer_id = be.id \\\n",
      "        where be.style_id = :i \\\n",
      "            and char_length(replace(trim(review),'\\n','')) > 30 \\\n",
      "        limit 2000\n",
      "        #and r.review not like \"%Presentation%\" \\\n",
      "        # only using 'pro' reviews lowered precision 25% points\n",
      "        #and lower(r.review) like '%presentation%' or lower(r.review) like '%p:%' \\\n",
      "    \n",
      "    revs = pd.concat([revs, dt.DataFrame()], ignore_index=True) #revs.append(dt.DataFrame())\n",
      "\n",
      "# original data source was not at all random\n",
      "nix = np.random.permutation(revs.index)\n",
      "revs = revs.reindex(index=nix, copy=False)\n",
      "\n",
      "X = pd.Series(revs[[\"review\"]].values.ravel())\n",
      "y = pd.Series(revs[[\"style_id\"]].values.ravel())\n",
      "\n",
      "# small look at table data\n",
      "print \"Review DF\"\n",
      "print revs[:1]\n",
      "print \"Series\"\n",
      "print X[0], y[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Review DF\n",
        "                                                 review  style_id\n",
        "9892  22oz. bottle served in a nonic. Poured a dark,...       159\n",
        "Series\n",
        "22oz. bottle served in a nonic. Poured a dark, opaque brown with red highlights around the edges. Half inch tan-colored cap embedded with tiny bubbles. Some strands of watery lacing with decent adherence. Subdued nose; primarily sweet and malty. More malt and a roasted coffee character. Mouthfeel fell between light and medium (but closer to the light side) with a mild and even carbonation forming the backdrop. Easy drinking and flavorful. A solid representation of the style. 159\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "default_tokenizer = TfidfVectorizer().build_tokenizer()\n",
      "stemmer = nltk.stem.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
      "\n",
      "def non_num_tokenizer(text):\n",
      "    return default_tokenizer(re.sub(r'\\d', '', text))\n",
      "\n",
      "def tokenize_stem(text):\n",
      "    \"\"\"\n",
      "    use the default tokenizer from TfidfVectorizer, combined with the nltk SnowballStemmer.\n",
      "    \"\"\"\n",
      "    return map(stemmer.stem, non_num_tokenizer(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vect_nb(max_features, ng_range, min_df, max_df, x, y):\n",
      "    stop_words = nltk.corpus.stopwords.words('english') + \\\n",
      "        ['ever','sure','want','review','got']\n",
      "    vec = TfidfVectorizer(max_features=max_features,\n",
      "                ngram_range=ng_range,\n",
      "                min_df=min_df,\n",
      "                max_df=max_df,\n",
      "                tokenizer=tokenize_stem,\n",
      "                stop_words=map(stemmer.stem, stop_words), \n",
      "                use_idf = True, sublinear_tf = False, \n",
      "                binary=False)\n",
      "    \n",
      "    dt = vec.fit_transform(x)\n",
      "    nb = MultinomialNB()\n",
      "    nb.fit(dt, y)\n",
      "    \n",
      "    return vec, nb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Simple K-Fold cross validation. 5 folds.\n",
      "#cv = c_v.KFold(len(y), n_folds=5)#, indices=False)\n",
      "cv = c_v.StratifiedShuffleSplit(y, 3, test_size = 0.2, random_state = 0)\n",
      "#iterate through the training and test cross validation segments and\n",
      "#run the classifier on each one, aggregating the results into a list\n",
      "\n",
      "import pylab as pl\n",
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "def plot_confusion(y, pred):\n",
      "    cm = confusion_matrix(y, pred)\n",
      "    pl.matshow(cm)\n",
      "    pl.title('Confusion matrix')\n",
      "    pl.colorbar()\n",
      "    pl.ylabel('True label')\n",
      "    pl.xlabel('Predicted label')\n",
      "    pl.show()\n",
      "\n",
      "max_features = 2000\n",
      "ngram_range = (1,2)\n",
      "min_df = 0.01\n",
      "max_df = .8\n",
      "for trainix, testix in cv:\n",
      "    # vectorize reviews and fit predictor\n",
      "    vec, nb = vect_nb(max_features, ngram_range, min_df, max_df, X[trainix].values, y[trainix].values)\n",
      "    \n",
      "    # transform test set\n",
      "    test_t = vec.transform(X[testix].values)\n",
      "    \n",
      "    # predict class\n",
      "    pred = nb.predict(test_t)\n",
      "    \n",
      "    # print precision/summary/f1 report\n",
      "    print classification_report(y[testix].values, pred)\n",
      "    \n",
      "    # compute and plot confusion matrix\n",
      "    plot_confusion(y[testix].values, pred)\n",
      "    \n",
      "    break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "         84       0.93      0.89      0.91       400\n",
        "         97       0.83      0.82      0.83       400\n",
        "        116       0.75      0.82      0.79       400\n",
        "        140       0.81      0.73      0.77       400\n",
        "        159       0.90      0.94      0.92       400\n",
        "\n",
        "avg / total       0.84      0.84      0.84      2000\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD0CAYAAACSLzOZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fcc525f4890>"
       ]
      }
     ],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "train = vec.transform(X[trainix].values)\n",
      "km = KMeans(n_clusters=len(styles))\n",
      "km.fit(train)\n",
      "#km = KNeighborsClassifier(n_neighbors=len(styles))\n",
      "#km.fit(train, y[trainix].values)\n",
      "\n",
      "labels = y[testix].values\n",
      "test_t = vec.transform(X[testix].values)\n",
      "pred = km.predict(test_t)\n",
      "\n",
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, pred))\n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, pred))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, pred))\n",
      "print(\"Adjusted Rand-Index: %.3f\"\n",
      "      % metrics.adjusted_rand_score(labels, pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.500\n",
        "Completeness: 0.522\n",
        "V-measure: 0.511\n",
        "Adjusted Rand-Index: 0.404\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum([1 for p in pred if p == 0])\n",
      "#print classification_report(labels, [styles[p] for p in pred])\n",
      "#np.unique([styles[p] for p in pred])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 327,
       "text": [
        "383"
       ]
      }
     ],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idf = vec._tfidf.idf_\n",
      "w_lst = zip(vec.get_feature_names(), idf)\n",
      "w_lst.sort(key = lambda x: -x[1])\n",
      "print np.array(w_lst)[-50:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'much' u'2.66613325611']\n",
        " [u'note' u'2.6628318335']\n",
        " [u'finger' u'2.66217285489']\n",
        " [u'nose' u'2.63423989233']\n",
        " [u'leav' u'2.62214168683']\n",
        " [u'dri' u'2.57576552504']\n",
        " [u'smooth' u'2.54073671369']\n",
        " [u'golden' u'2.47689125647']\n",
        " [u'drink' u'2.43351096084']\n",
        " [u'pine' u'2.43089384341']\n",
        " [u'grapefruit' u'2.42049333364']\n",
        " [u'floral' u'2.40917634043']\n",
        " [u'great' u'2.35540529978']\n",
        " [u'littl' u'2.35298457722']\n",
        " [u'bit' u'2.33145779523']\n",
        " [u'slight' u'2.27801347946']\n",
        " [u'bottl' u'2.22685478364']\n",
        " [u'hoppi' u'2.21372734549']\n",
        " [u'amber' u'2.20368121663']\n",
        " [u'drinkabl' u'2.14582888839']\n",
        " [u'well' u'2.12984102591']\n",
        " [u'mouthfeel' u'2.10689546856']\n",
        " [u'medium' u'2.09973778119']\n",
        " [u'glass' u'2.09263096242']\n",
        " [u'light' u'2.08261789898']\n",
        " [u'like' u'2.05855549122']\n",
        " [u'balanc' u'2.0513767095']\n",
        " [u'orang' u'2.04745023649']\n",
        " [u'one' u'1.99201519256']\n",
        " [u'finish' u'1.98630185153']\n",
        " [u'bodi' u'1.95561143753']\n",
        " [u'sweet' u'1.90770378346']\n",
        " [u'flavor' u'1.88807125105']\n",
        " [u'aroma' u'1.88352509987']\n",
        " [u'carbon' u'1.85432159427']\n",
        " [u'white' u'1.8534409249']\n",
        " [u'smell' u'1.7977997021']\n",
        " [u'citrus' u'1.78319688028']\n",
        " [u'color' u'1.7655740845']\n",
        " [u'good' u'1.74246241694']\n",
        " [u'nice' u'1.65405145959']\n",
        " [u'lace' u'1.64901608149']\n",
        " [u'beer' u'1.5848662989']\n",
        " [u'malt' u'1.58039001569']\n",
        " [u'ipa' u'1.56531880844']\n",
        " [u'bitter' u'1.5117842967']\n",
        " [u'pour' u'1.50596307444']\n",
        " [u'tast' u'1.47494017843']\n",
        " [u'hop' u'1.1794011908']\n",
        " [u'head' u'1.14775530919']]\n"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "select * \n",
      "from styles\n",
      "where id in (84,97,116,140,159)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table>\n",
        "    <tr>\n",
        "        <th>id</th>\n",
        "        <th>name</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>84</td>\n",
        "        <td>Russian Imperial Stout</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>97</td>\n",
        "        <td>American Pale Ale (APA)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>116</td>\n",
        "        <td>American IPA</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>140</td>\n",
        "        <td>American Double / Imperial IPA</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>159</td>\n",
        "        <td>American Porter</td>\n",
        "    </tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "[(84L, 'Russian Imperial Stout'),\n",
        " (97L, 'American Pale Ale (APA)'),\n",
        " (116L, 'American IPA'),\n",
        " (140L, 'American Double / Imperial IPA'),\n",
        " (159L, 'American Porter')]"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pipeline vectorizer\n",
      "def vectorizer(n_features):\n",
      "    from sklearn.pipeline import Pipeline\n",
      "    \n",
      "    hasher = HashingVectorizer(\n",
      "                n_features=n_features,\n",
      "                ngram_range=ng_range,\n",
      "                min_df=min_df,\n",
      "                max_df=max_df,\n",
      "                stop_words=map(stemmer.stem, nltk.corpus.stopwords.words('english')), \n",
      "                non_negative=False,\n",
      "                norm=None, binary=False)\n",
      "    \n",
      "    vec = Pipeline((\n",
      "            ('hash', hasher),\n",
      "            ('tf_idf', TfidfTransformer(use_idf = True, sublinear_tf = False, norm='l2')),\n",
      "        ))\n",
      "    \n",
      "    return vec\n",
      "\n",
      "#def classifier():\n",
      "#    from nltk.classify import SklearnClassifier\n",
      "#    from sklearn.feature_selection import SelectKBest\n",
      "#    pipeline = Pipeline((           \n",
      "#           ('hash', hasher),\n",
      "#            ('tf_idf', TfidfTransformer(use_idf = True, sublinear_tf = True, norm='l2')),\n",
      "#            ('chi2', SelectKBest(chi2, k=1000))\n",
      "#            ('nb', MultinomialNB())\n",
      "#        ))\n",
      "#    return SklearnClassifier(pipeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 270,
       "text": [
        "['i',\n",
        " 'me',\n",
        " 'my',\n",
        " 'myself',\n",
        " 'we',\n",
        " 'our',\n",
        " 'ours',\n",
        " 'ourselves',\n",
        " 'you',\n",
        " 'your',\n",
        " 'yours',\n",
        " 'yourself',\n",
        " 'yourselves',\n",
        " 'he',\n",
        " 'him',\n",
        " 'his',\n",
        " 'himself',\n",
        " 'she',\n",
        " 'her',\n",
        " 'hers',\n",
        " 'herself',\n",
        " 'it',\n",
        " 'its',\n",
        " 'itself',\n",
        " 'they',\n",
        " 'them',\n",
        " 'their',\n",
        " 'theirs',\n",
        " 'themselves',\n",
        " 'what',\n",
        " 'which',\n",
        " 'who',\n",
        " 'whom',\n",
        " 'this',\n",
        " 'that',\n",
        " 'these',\n",
        " 'those',\n",
        " 'am',\n",
        " 'is',\n",
        " 'are',\n",
        " 'was',\n",
        " 'were',\n",
        " 'be',\n",
        " 'been',\n",
        " 'being',\n",
        " 'have',\n",
        " 'has',\n",
        " 'had',\n",
        " 'having',\n",
        " 'do',\n",
        " 'does',\n",
        " 'did',\n",
        " 'doing',\n",
        " 'a',\n",
        " 'an',\n",
        " 'the',\n",
        " 'and',\n",
        " 'but',\n",
        " 'if',\n",
        " 'or',\n",
        " 'because',\n",
        " 'as',\n",
        " 'until',\n",
        " 'while',\n",
        " 'of',\n",
        " 'at',\n",
        " 'by',\n",
        " 'for',\n",
        " 'with',\n",
        " 'about',\n",
        " 'against',\n",
        " 'between',\n",
        " 'into',\n",
        " 'through',\n",
        " 'during',\n",
        " 'before',\n",
        " 'after',\n",
        " 'above',\n",
        " 'below',\n",
        " 'to',\n",
        " 'from',\n",
        " 'up',\n",
        " 'down',\n",
        " 'in',\n",
        " 'out',\n",
        " 'on',\n",
        " 'off',\n",
        " 'over',\n",
        " 'under',\n",
        " 'again',\n",
        " 'further',\n",
        " 'then',\n",
        " 'once',\n",
        " 'here',\n",
        " 'there',\n",
        " 'when',\n",
        " 'where',\n",
        " 'why',\n",
        " 'how',\n",
        " 'all',\n",
        " 'any',\n",
        " 'both',\n",
        " 'each',\n",
        " 'few',\n",
        " 'more',\n",
        " 'most',\n",
        " 'other',\n",
        " 'some',\n",
        " 'such',\n",
        " 'no',\n",
        " 'nor',\n",
        " 'not',\n",
        " 'only',\n",
        " 'own',\n",
        " 'same',\n",
        " 'so',\n",
        " 'than',\n",
        " 'too',\n",
        " 'very',\n",
        " 's',\n",
        " 't',\n",
        " 'can',\n",
        " 'will',\n",
        " 'just',\n",
        " 'don',\n",
        " 'should',\n",
        " 'now']"
       ]
      }
     ],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec.transform(X[testix[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 296,
       "text": [
        "<451x723 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 0 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[:2].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 329,
       "text": [
        "array([ '22oz. bottle served in a nonic. Poured a dark, opaque brown with red highlights around the edges. Half inch tan-colored cap embedded with tiny bubbles. Some strands of watery lacing with decent adherence. Subdued nose; primarily sweet and malty. More malt and a roasted coffee character. Mouthfeel fell between light and medium (but closer to the light side) with a mild and even carbonation forming the backdrop. Easy drinking and flavorful. A solid representation of the style.',\n",
        "       'A- straw w/ orange tint, taunt, 2 finger foamy white head, very good retent, thin soapy lace that holds very strongly  S- pine, herbal, buttery, hop oils  T- hop dominant, crisp, leafy hop finish, dry bitter hop after, earthy, tons of hop action, citrus, dry, oily, toasted malts  M- medium body, crisp, wet finish turns into dry after, hop abuse  D- enjoyable, not a session brew, solid 2IPA, seriously a hop bitchslap, recommended for hopheads, probably scare anyone else'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 329
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}