{
 "metadata": {
  "name": "",
  "signature": "sha256:e3d5fb6485aecf1ea64e985d4a857da46e9a6a32ec02f19b2eb54e3d7010eb4a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Music Classification\n",
      "\n",
      "\n",
      "##Overview\n",
      "My overall goal was to read in a large number of MIDI files of solo piano pieces by Baroque, Classical, and Romantic composers and build a classifier that can take a new piece and guess who the composer is.\n",
      "\n",
      "* **Sample:** 460 pieces by 25 composers, downloaded from http://www.piano-midi.de/ and http://www.musedata.org/\n",
      "\n",
      "* **Training:** To compensate for the relatively small sample size, I divided each piece into 4-measure chunks for a total of approximately 13,000 chunks.  These chunks were used to train the classifier, with a random 20% of the samples held out for cross-validation.\n",
      "\n",
      "* **Features:** \n",
      "  * Range (difference between the highest and lowest note)\n",
      "  * Number of ornaments (very short notes that form grace notes, trills, mordents, and glissandos)\n",
      "  * Average number of notes sounding at once\n",
      "  * Average number of notes changing at once (a rough proxy for number of melodic lines)\n",
      "  * Number of unique note spacings in the sample (rhythmic uniformity)\n",
      "  * Largest internal interval\n",
      "  * Chords present in the sample.  These are recorded as strings and then fed to a vectorizer to produce a feature vector, much like one would do for NLP.\n",
      "\n",
      "* **Metric:** The important metric for this problem is accuracy, since assigning A to the B category is no better or worse than assigning B to the A category.\n",
      "\n",
      "* **Classifier:** I experimented with several classifiers.  Naive Bayes performs relatively poorly, Logistic Regression slightly better.  I got the best results with a Random Forest.\n",
      "\n",
      "* **Testing:** A new piece is broken up into 4-measure chunks and fed to the classifier.  The classifier spits out a list of probabilities reflecting its estimate of how likely the chunk is to be the work of each possible composer.  Each chunk then gets a \"vote\" on the classification of the whole piece, with the chunks where there was one overwhelmingly likely composer being weighted more heavily than the chunks where there was no clear winner."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing and Feature Extraction\n",
      "\n",
      "This is the preprocessing code that loads the midi files, computes the features, and builds the data frames needed for the classification.  Most of this stuff is very slow to run because it has to loop over every tick in a sample.  It should be done ONCE and the resulting arrays and data frames written out to .csv files, and only rerun when something changes.\n",
      "\n",
      "**File format:** I used the Python MIDI library available [here](https://github.com/vishnubob/python-midi) to interface with the MIDI files.  The `read_midifile` function reads in a file and returns an object with the MIDI header information, iterable tracks, and iterable MIDI events within each track.  The header information is not always accurate (the most common example is the key signature, which is often not specified or incorrect).\n",
      "\n",
      "\n",
      "*Side note: Track 0 in the MIDI file format is the tempo track, which specifies the conversion between clock time and MIDI \"ticks.\"  If the MIDI file was created by a computer program like Finale, MIDI ticks will correspond to some constant fraction of a beat, and the tempo track will give the metronome setting.  If the MIDI file was played in by a human being, MIDI ticks and the beat may have no relation to each other and the tempo track doesn't necessarily give any useful information.  I've restricted myself to computer-created MIDI files for my training sample because it makes it possible to extract rhythm features without first attempting to figure out where the beats are, but many of the features do not depend on rhythm information and the classifier still does a reasonable job on some human-played MIDI files.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import midi\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specify the directory where the music is stored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filedir = './Music/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that turns a midi track into a list of notes in the form [start tick, note value, end tick]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_note_list(pat):\n",
      "    #loop over tracks.  When a note is turned on, record it in dict active_notes as a pair of\n",
      "    #{value:start_tick}.  When we read a key off event for that note value, remove it from the\n",
      "    #active dict, add the end tick to the list [start_tick,value,end_tick] and shove it into\n",
      "    #the note list by track.\n",
      "    note_list_by_track = []\n",
      "    for p in pat:\n",
      "        notes_this_track = []\n",
      "        active_notes = {}\n",
      "        current_tick = 0\n",
      "        for ev in p:\n",
      "            if isinstance(ev, midi.events.NoteOnEvent) and ev.data[1] != 0:\n",
      "                #key down event\n",
      "                current_tick += ev.tick\n",
      "#                print \"Key down. Value = \" + str(ev.data[0]) + \". Tick = \" + str(current_tick)\n",
      "                if ev.data[0] not in active_notes:\n",
      "                    #simplest case: note is not already on\n",
      "                    active_notes[ev.data[0]]=current_tick\n",
      "                else:\n",
      "                    #note is already on.\n",
      "                    if isinstance(active_notes[ev.data[0]],int):\n",
      "                        #key has been activated once previously\n",
      "                        prev_ticks = [active_notes[ev.data[0]]]\n",
      "#                        print \"One previous activation on tick \" + str(prev_ticks)\n",
      "                    else:\n",
      "                        #key has been activated multiple times previously\n",
      "                        prev_ticks = active_notes[ev.data[0]]\n",
      "#                        print \"Previous activations on ticks \" + str(prev_ticks)\n",
      "                    prev_ticks.append(current_tick)\n",
      "                    active_notes[ev.data[0]] = prev_ticks\n",
      "#                print \"Notes on now are: \" + str(active_notes)\n",
      "#                print \"Current tick is now \" + str(current_tick)\n",
      "            elif isinstance(ev, midi.events.NoteOffEvent) or (isinstance(ev, midi.events.NoteOnEvent) and ev.data[1] == 0):\n",
      "                #key up event\n",
      "                current_tick += ev.tick\n",
      "#                print \"Key up.  Value = \" + str(ev.data[0]) + \". Tick = \" + str(current_tick)\n",
      "#                print \"Active notes are \" + str(active_notes)\n",
      "                note_val = ev.data[0]\n",
      "                tup = current_tick\n",
      "                if note_val in active_notes:\n",
      "                    #check to make sure we can't turn off a note that isn't on, because\n",
      "                    #this apparently happens once in a blue moon\n",
      "                    if isinstance(active_notes[note_val],int):\n",
      "                        #simplest case: note was turned on only once\n",
      "                        tdn = active_notes[note_val]\n",
      "    #                    print \"Removing note \" + str(ev.data[0]) + \" from the dict.\"\n",
      "                        del active_notes[note_val]\n",
      "                    else:\n",
      "                        #note was turned on twice.  take the lowest tick\n",
      "                        #in the list, assign it to tdn, and get rid of it.\n",
      "                        active_notes[note_val].sort()\n",
      "                        tdn = active_notes[note_val].pop(0)\n",
      "                        if len(active_notes[note_val])==1:\n",
      "                            active_notes[note_val] = active_notes[note_val][0]\n",
      "    #                    else:                        \n",
      "    #                        active_notes[ev.data[0]] = lticks\n",
      "                notes_this_track.append([tdn,note_val,tup])\n",
      "            else:\n",
      "                #not a note event\n",
      "                current_tick += ev.tick\n",
      "        note_list_by_track.append([pat.index(p),notes_this_track])\n",
      "    return note_list_by_track"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper function that collapses the track-separated list of notes down to a single list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collapsetracks(note_list_by_track):\n",
      "    #since the notes are now in [start_tick,value,end_tick] form, this is easier.  We can\n",
      "    #just concatenate the lists.\n",
      "\n",
      "    ticks_collapsed = []\n",
      "    for i in note_list_by_track:\n",
      "        if len(i[1])<2:\n",
      "            pass\n",
      "        else:\n",
      "            ticks_collapsed += i[1]\n",
      "    return ticks_collapsed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that reads the tempo track and makes a list of measure boundaries for use in the four-measure splitter function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_meas(pattern):\n",
      "    \n",
      "    t=[0]*len(pattern)\n",
      "    for i in range(len(pattern)):\n",
      "        #tracks\n",
      "        #print \"Track \" + str(i)\n",
      "        for j in range(len(pattern[i])):\n",
      "            t[i] += pattern[i][j].tick\n",
      "            #print \"Adding \" + str(pattern[i][j].tick) + \": total tick count now \" + str(t[i])\n",
      "    #print t\n",
      "    numticks = max(t)\n",
      "    \n",
      "    meas_ticks = [0]\n",
      "    last_ts_tick = 0\n",
      "    ticks_passed = 0\n",
      "    ts_changed = 0\n",
      "    #print \"Resolution = \" + str(pattern.resolution)\n",
      "    for i in pattern[0]:\n",
      "        if isinstance(i,midi.events.TimeSignatureEvent):\n",
      "            if i.tick == 0:\n",
      "    #            ticks_passed += i.tick\n",
      "                ts_num = i.data[0]\n",
      "                ts_den = 2**(i.data[1])\n",
      "                ts_tick = 0\n",
      "\n",
      "                #print \"Time sig = \" + str(ts_num) + \"/\" + str(ts_den) + \" at tick \" + str(ts_tick)\n",
      "                idataold = i.data\n",
      "            else:\n",
      "                if i.data == idataold:\n",
      "                    ticks_passed += i.tick\n",
      "                else:\n",
      "                    ts_changed = 1\n",
      "                    ticks_passed += i.tick\n",
      "                    to_last_ts = ticks_passed-ts_tick\n",
      "                    #print str(to_last_ts) + \" ticks of the last time sig.\"\n",
      "                    #print \"Tick conversion: \" + str(ts_conv)\n",
      "                    #print ts_num\n",
      "                    #print ts_conv\n",
      "                    #print \"Measure length is \" + str((pattern.resolution * 4/ts_den * ts_num)) + \" ticks.\"\n",
      "                    num_measures = to_last_ts / (pattern.resolution * 4/ts_den * ts_num)\n",
      "                    #print str(num_measures) + \" measures of the last time sig.\"\n",
      "                    #print \"Tick now is \" + str(ts_tick) + \".  Appending to array: \"\n",
      "                    for j in range(num_measures):\n",
      "                        meas_ticks.append(ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                        #print (ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                    ts_num = i.data[0]\n",
      "                    ts_den = 2**(i.data[1])\n",
      "                    ts_tick = ticks_passed\n",
      "                    idataold = i.data\n",
      "                    #print \"Time sig change to \" + str(ts_num) + \"/\" + str(ts_den) + \" at tick \" + str(ts_tick)\n",
      "        elif isinstance(i,midi.events.EndOfTrackEvent):\n",
      "            ticks_passed += i.tick\n",
      "            #print \"End of tempo track at tick \" + str(ticks_passed)\n",
      "            to_last_ts = ticks_passed-ts_tick\n",
      "            num_measures = to_last_ts / (pattern.resolution * 4/ts_den * ts_num)\n",
      "            for j in range(num_measures):\n",
      "                        meas_ticks.append(ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                        #print (ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "        else:\n",
      "            ticks_passed += i.tick\n",
      "    if ts_changed == 0:\n",
      "        meas_ticks = [i*pattern.resolution * 4/ts_den * ts_num for i in range(numticks/(pattern.resolution * 4/ts_den * ts_num))]\n",
      "    return meas_ticks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that takes in the midi pattern object, performs the conversion to a list of notes by track, collapses the tracks, and separates the list of notes into a list of four-measure slices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_on_four_meas(pattern):\n",
      "#    Redoing for time signature changes.  Possible structure: for loop over all possible ticks?\n",
      "#    From TimeSignatureEvent, count forward ts_num * pattern.resolution ticks. Did we pass a TimeSignatureEvent?\n",
      "#    If yes, increment the measure counter, go to the tick where the TSE occurred, get the new ts_num,\n",
      "#    count forward by new ts_num ticks.\n",
      "#    \"Ornament\" is then a note that's shorter than a (ts_den*8)th note - resolution/8?\n",
      "    slice_list = []\n",
      "    note_list_by_track = make_note_list(pattern)\n",
      "    ticks_collapsed = collapsetracks(note_list_by_track)\n",
      "    meas_ticks = get_meas(pattern)\n",
      "    #print ticks_collapsed\n",
      "    ts = np.array(ticks_collapsed)\n",
      "    testframe = pd.DataFrame(ts,columns=['start_tick','note_val','end_tick'])\n",
      "    #print testframe\n",
      "\n",
      "    slice_counter = 0\n",
      "    stop_early = False\n",
      "    while slice_counter < len(meas_ticks)/4.0:\n",
      "        low_bound = meas_ticks[slice_counter*4]\n",
      "        if (slice_counter+1)*4 < len(meas_ticks):\n",
      "            if meas_ticks[(slice_counter+1)*4] < max(testframe['end_tick']):\n",
      "                #check in case the tempo track is longer than the notes (which happens because of stupid reasons)\n",
      "                high_bound = meas_ticks[(slice_counter+1)*4]\n",
      "            else:\n",
      "                high_bound = max(testframe['end_tick'])\n",
      "                stop_early = True\n",
      "        else:\n",
      "            high_bound = max(testframe['end_tick'])\n",
      "        #print \"Starting loop.  Slice = \" + str(slice_counter) + \".  Range : Tick \" + str(low_bound) + \" to \" + str(high_bound) \n",
      "\n",
      "        if len(testframe[(testframe.start_tick > low_bound) & (testframe.start_tick < high_bound)]) != 0:\n",
      "            #don't put anything here if the whole slice is empty or one held note            \n",
      "            slice_list.append([slice_counter,testframe[(testframe.start_tick >= low_bound) & (testframe.start_tick < high_bound)]])\n",
      "        \n",
      "        if stop_early:\n",
      "            #should only hit this condition if the tempo track is longer than the note tracks.\n",
      "            break\n",
      "        \n",
      "        slice_counter += 1\n",
      "    return slice_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that holds all the calculations that require looping over the whole sample.  For a four-measure sample, calculates the average number of notes sounding simultaneously, both including rests (`avedown`) and skipping rests (`avenonzero`), and the average number of notes that move at once (`MC`).  Also calculates the \"sentence\" of chord strings for NLP chord analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_sample_stats(sample):\n",
      "    this_slice = sample[1]\n",
      "    st = this_slice.min(0)['start_tick']\n",
      "    et = this_slice.max(0)['start_tick']\n",
      "    totaldown = 0\n",
      "    totalticks = et-st\n",
      "    nonzeroticks = 0\n",
      "    this_slice['Norm note'] = this_slice['note_val'] % 12\n",
      "    chord_list = []\n",
      "    old_notes = []\n",
      "    for tk in range(st,et):\n",
      "        #Keys down at once part\n",
      "        ndown = len(this_slice[(this_slice.start_tick < tk) & (this_slice.end_tick > tk)])\n",
      "        #print \"tick = \" + str(tk)\n",
      "        #print str(ndown) + \"keys down\"\n",
      "        totaldown += ndown\n",
      "        if ndown != 0:\n",
      "            nonzeroticks += 1\n",
      "        \n",
      "        #Chord-to-string conversion\n",
      "        notes = this_slice[(this_slice.start_tick < tk) & (this_slice.end_tick > tk)]['Norm note'].ravel()\n",
      "        notes.sort()\n",
      "        if (not np.array_equal(notes,old_notes)) and (not np.array_equal(notes,np.array([]))):\n",
      "            f = list(set(notes))\n",
      "            f.sort()\n",
      "            g = [format(i,'x') for i in f]\n",
      "            h = \"\".join(g)\n",
      "            chord_list.append(h)\n",
      "        old_notes = notes\n",
      "        \n",
      "    if totalticks != 0:\n",
      "        avedown = float(totaldown)/float(totalticks)\n",
      "    else:\n",
      "        avedown = 0\n",
      "    if nonzeroticks != 0:\n",
      "        avenonzero = float(totaldown)/float(nonzeroticks)\n",
      "    else:\n",
      "        avenonzero = 0\n",
      "        \n",
      "    cstring = \" \".join(chord_list)\n",
      "    \n",
      "    \n",
      "    return [avedown,avenonzero,cstring]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The big one!  Loops over all composer directories and all midi files in those directories, reads in each file, and builds the array of features that we will turn into a data frame and use for calculations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_sample_frame(filedir,process_array):\n",
      "    #processing_frame = pd.DataFrame(np.array([]),columns=['Composer','Time sig num','Time sig den','Key sig','Highest note','Lowest note'])    \n",
      "    for composer in os.listdir(filedir):\n",
      "#    print composer\n",
      "        if os.path.isdir(filedir+composer):\n",
      "            for fn in os.listdir(filedir+composer+\"/\"):\n",
      "                if os.path.isfile(filedir+composer+\"/\" + fn) and (fn.endswith(\".mid\") or fn.endswith(\".MID\")):\n",
      "                        pattern = midi.read_midifile(filedir+composer+\"/\" + fn)\n",
      "                        #pattern = midi.read_midifile(\"./Music/Bach/0778.mid\")\n",
      "                        print composer + \"/\" + fn\n",
      "                        \n",
      "                        slice_list = split_on_four_meas(pattern)\n",
      "                        \n",
      "                        for i in slice_list:\n",
      "                            tf = i[1]\n",
      "                            tf['Nlength']=tf['end_tick']-tf['start_tick']\n",
      "                            ngrace = tf[tf['Nlength']<28]['Nlength'].count()\n",
      "                            [avedown_zeros,avedown_nozero,cstring] = calc_sample_stats(i)\n",
      "                            #a = to_next(tf)\n",
      "                            #ngrace = np.count_nonzero(np.logical_and(a>5,a<25))\n",
      "                            process_array.append([composer,max(i[1]['note_val']),min(i[1]['note_val']),ngrace,avedown_zeros,avedown_nozero,fn,cstring])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize and fill the sample array.  Convert it to a pandas data frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_array = []\n",
      "build_sample_frame(filedir,process_array)\n",
      "processing_frame = pd.DataFrame(process_array,columns=['Composer','Highest note','Lowest note','Num ornament','Avg simul notes','Avg simul nonzero notes','fname','Chord string'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'build_sample_frame' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-d4d84bca02aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprocess_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbuild_sample_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiledir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocess_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprocessing_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Composer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Highest note'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Lowest note'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Num ornament'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Avg simul notes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Avg simul nonzero notes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fname'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Chord string'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'build_sample_frame' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tack on a few derived columns and a color column for plotting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def colors(com):\n",
      "    #Convert composer names to an arbitrary integer that can be used to color them in plots.\n",
      "    a = pd.Series(processing_frame['Composer'].ravel()).unique()\n",
      "    for i in range(len(a)):\n",
      "        if a.item(i) == com:\n",
      "            return i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def period(com):\n",
      "    #Get stylistic period just in case we need it.\n",
      "    if com in ('Bach'):\n",
      "        return 'Baroque'\n",
      "    elif com in ('Albeniz','Balakirew','Beethoven','Borodin','Brahms','Burgmueller','Chopin','Debussy','Godowsky','Granados','Grieg','Liszt','Mendelssohn','Moszkowski','Mussorgsky','Rachmaninov','Ravel','Schubert','Schumann','Sinding','Tchaikovsky'):\n",
      "        return 'Romantic'\n",
      "    elif com in ('Mozart','Haydn','Clementi'):\n",
      "        return 'Classical'\n",
      "    else:\n",
      "        return 'Unknown'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def piece_num(fname):\n",
      "    #Convert composer names to an arbitrary integer that can be used to color them in plots.\n",
      "    a = pd.Series(processing_frame['fname'].ravel()).unique()\n",
      "    for i in range(len(a)):\n",
      "        if a.item(i) == fname:\n",
      "            return i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame['Note range']=processing_frame['Highest note']-processing_frame['Lowest note']\n",
      "processing_frame['To color'] = processing_frame['Composer'].apply(colors)\n",
      "processing_frame['Period'] = processing_frame['Composer'].apply(period)\n",
      "processing_frame['Piece number'] = processing_frame['fname'].apply(piece_num)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dump the entire data frame to a csv file so it can be read back in easily and we only have to do the preprocessing once!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame.to_csv('Music_frame.csv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame = pd.read_csv(\"Music_frame.csv\",sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drop null values from the dataframe - in very rare cases, it is possible to have a completely empty sample, which will result in some `NaN` cells being introduced."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame = processing_frame.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Classifier##\n",
      "\n",
      "There are some settings for the Random Forest classifier that can be passed as optional arguments to the fitting function, or you can stick with the defaults or pass `gridsearch = True` to allow the fitting function to search the parameter space for the optimal values on its own.  The fitting function prints out the accuracy score on the out-of-sample test set for the best classifier and returns the classifier and vectorizers.  The classifier can then be used to make predictions for new pieces of music.\n",
      "\n",
      "\n",
      "**Note on the NLP style treatment of chords:** I've defined a \"chord\" as the set of notes sounding at the same time, not even trying to separate out passing tones.  Then I treat each sample as a \"bag of chords\", analogous to the NLP \"bag of words\" approach.  It's astonishing how well it works, given how dumb this approach is in a music context.  Since things like NLP part-of-speech taggers don't really exist for music, I would have to roll my own set of tools to analyze context-sensitive features like chord progressions.  I'll be going back and trying to make this part of the project smarter if I have time; this is an area with major room for improvement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import linear_model, datasets\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "from sklearn import utils\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import svm\n",
      "from sklearn.feature_extraction.text import HashingVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ad_hoc_features(chordframe):\n",
      "    #chordframe['LogMC'] = log(chordframe['MC'])\n",
      "    chordframe['MCoveraveNnoz'] = chordframe['Ave moving notes']/chordframe['Ave notes no zeros']\n",
      "    b = chordframe.replace([np.inf, -np.inf], 0)\n",
      "    a = b[['Ave notes no zeros','MCoveraveNnoz','Ticks in slice','Num ornaments','Num note spacings','Largest interval','Highest note','Lowest note','Note range']].values\n",
      "    return a\n",
      "\n",
      "def makefeats(chordframe,v1,v2):\n",
      "    a = ad_hoc_features(chordframe)\n",
      "    t1 = v1.transform(chordframe['Chord string']).toarray()\n",
      "    t2 = v2.transform(chordframe['Folded chord string']).toarray()\n",
      "    return np.hstack((a,t1,t2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiclassfit(chordframe, vectorizer, gridsearch = False, C = 10, class_weight = 'auto', n_estimators = 10, max_depth=None, min_samples_split = 2, max_f = 1000, maxng = 3):\n",
      "    \n",
      "    if vectorizer==CountVectorizer or vectorizer==TfidfVectorizer:\n",
      "        ng_vectorizer = vectorizer(max_features = max_f, ngram_range = (1,maxng))\n",
      "        vec1 = ng_vectorizer.fit(chordframe['Chord string'])\n",
      "        vec2 = ng_vectorizer.fit(chordframe['Folded chord string'])\n",
      "    elif vectorizer==HashingVectorizer:\n",
      "        hv = vectorizer(n_features = max_f, ngram_range=(1, maxng))\n",
      "        vec1 = hv\n",
      "        vec2 = hv\n",
      "        \n",
      "    print \"Vectorization complete.\"\n",
      "    \n",
      "    #X = count_vec.transform(chordframe['Clist']).toarray()\n",
      "    X = makefeats(chordframe,vec1,vec2)\n",
      "    y = chordframe['To color']\n",
      "    \n",
      "    X,y = utils.shuffle(X,y)\n",
      "    \n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=39)\n",
      "    print \"Test sampling complete.  Building classifier...\"\n",
      "    \n",
      "    #classif=linear_model.LogisticRegression\n",
      "    #classifier = classif(C=C,class_weight = class_weight)\n",
      "    classif = RandomForestClassifier\n",
      "    #classif = tree.DecisionTreeClassifier\n",
      "    #classif = svm.SVC\n",
      "    #classifier = classif()\n",
      "    classifier = classif(n_estimators = n_estimators, max_depth=max_depth, min_samples_split = min_samples_split)\n",
      "    clf = OneVsRestClassifier(classifier).fit(X_train, y_train)\n",
      "    #print \"Out-of-sample classification in progress...\"\n",
      "    #res_p = clf.predict(X_test)\n",
      "    \n",
      "    print \"Cross-validating...\"\n",
      "    scores = cross_validation.cross_val_score(OneVsRestClassifier(classifier), X_train, y_train, cv=5, scoring='accuracy')\n",
      "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    \n",
      "    #print \"Categorizing unknown piece...\"\n",
      "    #blind_p = clf.predict(makefeats(blind_frame,count_vec1,count_vec2))\n",
      "    #blind_true = blind_frame['Compnum']\n",
      "    \n",
      "    #tf = blind_frame1[(blind_frame1['Compnum']==3) | (blind_frame1['Compnum']==0)]\n",
      "    #blind_p = clf.predict(makefeats(tf,count_vec1,count_vec2))\n",
      "    #blind_true = tf['Compnum']\n",
      "    #blind_probs = clf.predict_proba(makefeats(tf,count_vec1,count_vec2))\n",
      "    \n",
      "    #print blind_p\n",
      "    #print blind_true\n",
      "    #print blind_probs\n",
      "    \n",
      "    #percent_correct = 100*np.sum(blind_p==blind_true)/blind_p.shape[0]\n",
      "    #print str(percent_correct) + '% of blind samples correct.'\n",
      "    \n",
      "    #return metrics.accuracy_score(y_test,res_p)\n",
      "    print \"Done.\"\n",
      "    return [clf,vec1,vec2]\n",
      "    \n",
      "    #print \"Grid searching for best random forest parameters...\"\n",
      "    #param_grid = {'n_estimators':[10,15,20,25,30,35,40,45,50], 'max_depth':[None,1,2,3,4], 'min_samples_split':[2,3,4,5,6]}\n",
      "    #param_grid = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    #clfG = GridSearchCV(classifier,param_grid,scoring='accuracy')\n",
      "    \n",
      "    #clfG.fit(X_train,y_train)\n",
      "    #res_p = clfG.predict(X_test)\n",
      "    \n",
      "    #print clfG.best_params_\n",
      "    \n",
      "    #print clfG.predict(count_vec.transform(chords_neverseensamp).toarray())\n",
      "    #return metrics.accuracy_score(y_test,res_p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[clf,v1,v2] = multiclassfit(processing_frame,HashingVectorizer,n_estimators=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorization complete.\n",
        "Test sampling complete.  Building classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-17-17cfbb72b0eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulticlassfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing_frame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHashingVectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-16-83954a72e30d>\u001b[0m in \u001b[0;36mmulticlassfit\u001b[1;34m(chordframe, vectorizer, gridsearch, C, class_weight, n_estimators, max_depth, min_samples_split, max_f, maxng)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#classifier = classif()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print \"Out-of-sample classification in progress...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#res_p = clf.predict(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m    200\u001b[0m         self.estimators_, self.label_binarizer_ = fit_ovr(self.estimator, X, y,\n\u001b[1;32m--> 201\u001b[1;33m                                                           n_jobs=self.n_jobs)\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mfit_ovr\u001b[1;34m(estimator, X, y, n_jobs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     estimators = Parallel(n_jobs=n_jobs)(\n\u001b[0;32m     91\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         for i in range(Y.shape[1]))\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# Convert data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         X, = check_arrays(X, dtype=DTYPE, sparse_format=\"dense\",\n\u001b[1;32m--> 257\u001b[1;33m                           check_ccontiguous=True)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# Remap output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcheck_ccontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mascontiguousarray\u001b[1;34m(a, dtype)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \"\"\"\n\u001b[1;32m--> 548\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masfortranarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##A Test Case##\n",
      "\n",
      "Suppose we have a piece like this one.  I've blacked out all identifying information from the score - all we have to work with is the music.  Furthermore, this piece was not in the training sample, so the classifier has never seen any part of it before."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"Score_p1.jpg\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've built the classifier, so now we can load and process the MIDI file for this piece and apply the classifier to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 13565 entries, 0 to 13568\n",
        "Data columns (total 17 columns):\n",
        "Unnamed: 0             13565 non-null int64\n",
        "Composer               13565 non-null object\n",
        "Highest note           13565 non-null int64\n",
        "Lowest note            13565 non-null int64\n",
        "Fname                  13565 non-null object\n",
        "Ave moving notes       13565 non-null float64\n",
        "Ave notes sounding     13565 non-null float64\n",
        "Ave notes no zeros     13565 non-null float64\n",
        "Chord string           13565 non-null object\n",
        "Folded chord string    13565 non-null object\n",
        "Ticks in slice         13565 non-null int64\n",
        "Num ornaments          13565 non-null int64\n",
        "Num note spacings      13565 non-null int64\n",
        "Largest interval       13565 non-null int64\n",
        "Note range             13565 non-null int64\n",
        "To color               13565 non-null int64\n",
        "Period                 13565 non-null object\n",
        "dtypes: float64(3), int64(9), object(5)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame[['To color','Piece number']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame = pd.read_csv(\"Music_frame_2.csv\",sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame['Frac notes moving'] = piece_frame['Avg num moving notes']/piece_frame['Avg simul nonzero notes']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ad_hoc_features(chordframe):\n",
      "    return chordframe[['Note range','Num ornament','Avg simul nonzero notes','Frac notes moving','Avg num moving notes','Ticks in sample']].values\n",
      "    \n",
      "\n",
      "def makefeats(chordframe,v):\n",
      "    a = ad_hoc_features(chordframe)\n",
      "    t = v.transform(chordframe['Chord interval string']).toarray()\n",
      "    return np.hstack((a,t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiclassfit(chordframe, vectorizer, C = 10, class_weight = 'auto', n_estimators = 10, max_depth=None, min_samples_split = 2, max_f = 1000, maxng = 3):\n",
      "    ng_vectorizer = vectorizer(max_features = max_f, ngram_range = (1,maxng))\n",
      "    count_vec = ng_vectorizer.fit(chordframe['Chord interval string'])\n",
      "    print \"Vectorization complete.\"\n",
      "    \n",
      "    #X = count_vec.transform(chordframe['Chord string']).toarray()\n",
      "    X = makefeats(chordframe,count_vec)\n",
      "    y = chordframe['Pnum']\n",
      "    \n",
      "    X,y = utils.shuffle(X,y)\n",
      "    \n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=39)\n",
      "    print \"Test sampling complete.  Building classifier...\"\n",
      "    \n",
      "    #classif=linear_model.LogisticRegression\n",
      "    #classifier = classif(C=C,class_weight = class_weight)\n",
      "    classif = RandomForestClassifier\n",
      "    #classif = svm.SVC\n",
      "    classifier = classif()\n",
      "    #classifier = classif(n_estimators = n_estimators, max_depth=max_depth, min_samples_split = min_samples_split)\n",
      "    #clf = OneVsRestClassifier(classifier).fit(X_train, y_train)\n",
      "    #print \"Out-of-sample classification in progress...\"\n",
      "    #res_p = clf.predict(X_test)\n",
      "    \n",
      "    print \"Cross-validating...\"\n",
      "    scores = cross_validation.cross_val_score(OneVsRestClassifier(classifier), X_train, y_train, cv=5, scoring='accuracy')\n",
      "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    \n",
      "    #print \"Categories for blind sample:\"\n",
      "    #print clf.predict(count_vec.transform(chords_neverseensamp).toarray())\n",
      "    \n",
      "    #percent_correct = 100*np.sum(y_test==res_p)/y_test.shape[0]\n",
      "    #print str(percent_correct) + '% correct.'\n",
      "    \n",
      "    #return metrics.accuracy_score(y_test,res_p)\n",
      "    return scores.mean()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiclassfit(piece_frame, CountVectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorization complete.\n",
        "Test sampling complete.  Building classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Cross-validating...\n",
        "Accuracy: 0.88 (+/- 0.07)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0.87742454728370212"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(len(piece_frame[piece_frame['Period']=='Classical']))/float(len(piece_frame))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.13439635535307518"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pnum(p):\n",
      "    #Get stylistic period just in case we need it.\n",
      "    if p=='Baroque':\n",
      "        return 0\n",
      "    elif p=='Classical':\n",
      "        return 1\n",
      "    elif p=='Romantic':\n",
      "        return 2\n",
      "    else:\n",
      "        return 'Unknown'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame['Pnum'] = piece_frame['Period'].apply(pnum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}