{
 "metadata": {
  "name": "",
  "signature": "sha256:31ece4dbb9702f33f133e76e61ea35cd02f9c651c8d4fc5e86c548fdfddcaab9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Music Classification\n",
      "\n",
      "\n",
      "##Overview\n",
      "My overall goal was to read in a large number of MIDI files of solo piano pieces by Baroque, Classical, and Romantic composers and build a classifier that can take a new piece and guess who the composer is.\n",
      "\n",
      "* **Sample:** 460 pieces by 25 composers, downloaded from http://www.piano-midi.de/ and http://www.musedata.org/\n",
      "\n",
      "* **Training:** To compensate for the relatively small sample size, I divided each piece into 4-measure chunks for a total of approximately 13,000 chunks.  These chunks were used to train the classifier.\n",
      "\n",
      "* **Features:** \n",
      "  * Range (difference between the highest and lowest note)\n",
      "  * Number of ornaments (very short notes that form grace notes, trills, mordents, and glissandos)\n",
      "  * Average number of notes sounding at once\n",
      "  * Average number of notes changing at once (a rough proxy for number of melodic lines)\n",
      "  * Number of flats or sharps in the key signature (if available)\n",
      "  * Time signature changes\n",
      "  * Chords present in the sample.  These are recorded as strings and then fed to a vectorizer to produce a feature vector, much like one would do for NLP.\n",
      "\n",
      "* **Classifier:** I experimented with several classifiers; accuracy plots for the different classifiers are shown below.  Naive Bayes performs relatively poorly, Logistic Regression slightly better.  I got the best results with a Random Forest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing and Feature Extraction\n",
      "\n",
      "This is the preprocessing code that loads the midi files, computes the features, and builds the data frames needed for the classification.  Most of this stuff is very slow to run because it has to loop over every tick in a sample.  It should be done ONCE and the resulting arrays and data frames written out to .csv files, and only rerun when something changes.\n",
      "\n",
      "**File format:** I used the Python MIDI library available [here](https://github.com/vishnubob/python-midi) to interface with the MIDI files.  The `read_midifile` function reads in a file and returns an object with the MIDI header information, iterable tracks, and iterable MIDI events within each track.  The header information is not always accurate (the most common example is the key signature, which is often not specified or incorrect).\n",
      "\n",
      "\n",
      "*Side note: Track 0 in the MIDI file format is the tempo track, which specifies the conversion between clock time and MIDI \"ticks.\"  If the MIDI file was created by a computer program like Finale, MIDI ticks will correspond to some constant fraction of a beat, and the tempo track will give the metronome setting.  If the MIDI file was played in by a human being, MIDI ticks and the beat may have no relation to each other and the tempo track doesn't necessarily give any useful information.  I've restricted myself to computer-created MIDI files for my training sample because it makes it possible to extract rhythm features without first attempting to figure out where the beats are, but many of the features do not depend on rhythm information and the classifier still does a reasonable job on some human-played MIDI files.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import midi\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/sarah/local-python/2.7.6/py-init-env/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specify the directory where the music is stored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filedir = './Music/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that turns a midi track into a list of notes in the form [start tick, note value, end tick]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_note_list(pat):\n",
      "    #loop over tracks.  When a note is turned on, record it in dict active_notes as a pair of\n",
      "    #{value:start_tick}.  When we read a key off event for that note value, remove it from the\n",
      "    #active dict, add the end tick to the list [start_tick,value,end_tick] and shove it into\n",
      "    #the note list by track.\n",
      "    note_list_by_track = []\n",
      "    for p in pat:\n",
      "        notes_this_track = []\n",
      "        active_notes = {}\n",
      "        current_tick = 0\n",
      "        for ev in p:\n",
      "            if isinstance(ev, midi.events.NoteOnEvent) and ev.data[1] != 0:\n",
      "                #key down event\n",
      "                current_tick += ev.tick\n",
      "#                print \"Key down. Value = \" + str(ev.data[0]) + \". Tick = \" + str(current_tick)\n",
      "                if ev.data[0] not in active_notes:\n",
      "                    #simplest case: note is not already on\n",
      "                    active_notes[ev.data[0]]=current_tick\n",
      "                else:\n",
      "                    #note is already on.\n",
      "                    if isinstance(active_notes[ev.data[0]],int):\n",
      "                        #key has been activated once previously\n",
      "                        prev_ticks = [active_notes[ev.data[0]]]\n",
      "#                        print \"One previous activation on tick \" + str(prev_ticks)\n",
      "                    else:\n",
      "                        #key has been activated multiple times previously\n",
      "                        prev_ticks = active_notes[ev.data[0]]\n",
      "#                        print \"Previous activations on ticks \" + str(prev_ticks)\n",
      "                    prev_ticks.append(current_tick)\n",
      "                    active_notes[ev.data[0]] = prev_ticks\n",
      "#                print \"Notes on now are: \" + str(active_notes)\n",
      "#                print \"Current tick is now \" + str(current_tick)\n",
      "            elif isinstance(ev, midi.events.NoteOffEvent) or (isinstance(ev, midi.events.NoteOnEvent) and ev.data[1] == 0):\n",
      "                #key up event\n",
      "                current_tick += ev.tick\n",
      "#                print \"Key up.  Value = \" + str(ev.data[0]) + \". Tick = \" + str(current_tick)\n",
      "#                print \"Active notes are \" + str(active_notes)\n",
      "                note_val = ev.data[0]\n",
      "                tup = current_tick\n",
      "                if note_val in active_notes:\n",
      "                    #check to make sure we can't turn off a note that isn't on, because\n",
      "                    #this apparently happens once in a blue moon\n",
      "                    if isinstance(active_notes[note_val],int):\n",
      "                        #simplest case: note was turned on only once\n",
      "                        tdn = active_notes[note_val]\n",
      "    #                    print \"Removing note \" + str(ev.data[0]) + \" from the dict.\"\n",
      "                        del active_notes[note_val]\n",
      "                    else:\n",
      "                        #note was turned on twice.  take the lowest tick\n",
      "                        #in the list, assign it to tdn, and get rid of it.\n",
      "                        active_notes[note_val].sort()\n",
      "                        tdn = active_notes[note_val].pop(0)\n",
      "                        if len(active_notes[note_val])==1:\n",
      "                            active_notes[note_val] = active_notes[note_val][0]\n",
      "    #                    else:                        \n",
      "    #                        active_notes[ev.data[0]] = lticks\n",
      "                notes_this_track.append([tdn,note_val,tup])\n",
      "            else:\n",
      "                #not a note event\n",
      "                current_tick += ev.tick\n",
      "        note_list_by_track.append([pat.index(p),notes_this_track])\n",
      "    return note_list_by_track"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper function that collapses the track-separated list of notes down to a single list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collapsetracks(note_list_by_track):\n",
      "    #since the notes are now in [start_tick,value,end_tick] form, this is easier.  We can\n",
      "    #just concatenate the lists.\n",
      "\n",
      "    ticks_collapsed = []\n",
      "    for i in note_list_by_track:\n",
      "        if len(i[1])<2:\n",
      "            pass\n",
      "        else:\n",
      "            ticks_collapsed += i[1]\n",
      "    return ticks_collapsed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that reads the tempo track and makes a list of measure boundaries for use in the four-measure splitter function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_meas(pattern):\n",
      "    \n",
      "    t=[0]*len(pattern)\n",
      "    for i in range(len(pattern)):\n",
      "        #tracks\n",
      "        #print \"Track \" + str(i)\n",
      "        for j in range(len(pattern[i])):\n",
      "            t[i] += pattern[i][j].tick\n",
      "            #print \"Adding \" + str(pattern[i][j].tick) + \": total tick count now \" + str(t[i])\n",
      "    #print t\n",
      "    numticks = max(t)\n",
      "    \n",
      "    meas_ticks = [0]\n",
      "    last_ts_tick = 0\n",
      "    ticks_passed = 0\n",
      "    ts_changed = 0\n",
      "    #print \"Resolution = \" + str(pattern.resolution)\n",
      "    for i in pattern[0]:\n",
      "        if isinstance(i,midi.events.TimeSignatureEvent):\n",
      "            if i.tick == 0:\n",
      "    #            ticks_passed += i.tick\n",
      "                ts_num = i.data[0]\n",
      "                ts_den = 2**(i.data[1])\n",
      "                ts_tick = 0\n",
      "\n",
      "                #print \"Time sig = \" + str(ts_num) + \"/\" + str(ts_den) + \" at tick \" + str(ts_tick)\n",
      "                idataold = i.data\n",
      "            else:\n",
      "                if i.data == idataold:\n",
      "                    ticks_passed += i.tick\n",
      "                else:\n",
      "                    ts_changed = 1\n",
      "                    ticks_passed += i.tick\n",
      "                    to_last_ts = ticks_passed-ts_tick\n",
      "                    #print str(to_last_ts) + \" ticks of the last time sig.\"\n",
      "                    #print \"Tick conversion: \" + str(ts_conv)\n",
      "                    #print ts_num\n",
      "                    #print ts_conv\n",
      "                    #print \"Measure length is \" + str((pattern.resolution * 4/ts_den * ts_num)) + \" ticks.\"\n",
      "                    num_measures = to_last_ts / (pattern.resolution * 4/ts_den * ts_num)\n",
      "                    #print str(num_measures) + \" measures of the last time sig.\"\n",
      "                    #print \"Tick now is \" + str(ts_tick) + \".  Appending to array: \"\n",
      "                    for j in range(num_measures):\n",
      "                        meas_ticks.append(ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                        #print (ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                    ts_num = i.data[0]\n",
      "                    ts_den = 2**(i.data[1])\n",
      "                    ts_tick = ticks_passed\n",
      "                    idataold = i.data\n",
      "                    #print \"Time sig change to \" + str(ts_num) + \"/\" + str(ts_den) + \" at tick \" + str(ts_tick)\n",
      "        elif isinstance(i,midi.events.EndOfTrackEvent):\n",
      "            ticks_passed += i.tick\n",
      "            #print \"End of tempo track at tick \" + str(ticks_passed)\n",
      "            to_last_ts = ticks_passed-ts_tick\n",
      "            num_measures = to_last_ts / (pattern.resolution * 4/ts_den * ts_num)\n",
      "            for j in range(num_measures):\n",
      "                        meas_ticks.append(ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "                        #print (ts_tick + (j+1)*pattern.resolution * 4/ts_den * ts_num)\n",
      "        else:\n",
      "            ticks_passed += i.tick\n",
      "    if ts_changed == 0:\n",
      "        meas_ticks = [i*pattern.resolution * 4/ts_den * ts_num for i in range(numticks/(pattern.resolution * 4/ts_den * ts_num))]\n",
      "    return meas_ticks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that takes in the midi pattern object, performs the conversion to a list of notes by track, collapses the tracks, and separates the list of notes into a list of four-measure slices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_on_four_meas(pattern):\n",
      "#    Redoing for time signature changes.  Possible structure: for loop over all possible ticks?\n",
      "#    From TimeSignatureEvent, count forward ts_num * pattern.resolution ticks. Did we pass a TimeSignatureEvent?\n",
      "#    If yes, increment the measure counter, go to the tick where the TSE occurred, get the new ts_num,\n",
      "#    count forward by new ts_num ticks.\n",
      "#    \"Ornament\" is then a note that's shorter than a (ts_den*8)th note - resolution/8?\n",
      "    slice_list = []\n",
      "    note_list_by_track = make_note_list(pattern)\n",
      "    ticks_collapsed = collapsetracks(note_list_by_track)\n",
      "    meas_ticks = get_meas(pattern)\n",
      "    #print ticks_collapsed\n",
      "    ts = np.array(ticks_collapsed)\n",
      "    testframe = pd.DataFrame(ts,columns=['start_tick','note_val','end_tick'])\n",
      "    #print testframe\n",
      "\n",
      "    slice_counter = 0\n",
      "    stop_early = False\n",
      "    while slice_counter < len(meas_ticks)/4.0:\n",
      "        low_bound = meas_ticks[slice_counter*4]\n",
      "        if (slice_counter+1)*4 < len(meas_ticks):\n",
      "            if meas_ticks[(slice_counter+1)*4] < max(testframe['end_tick']):\n",
      "                #check in case the tempo track is longer than the notes (which happens because of stupid reasons)\n",
      "                high_bound = meas_ticks[(slice_counter+1)*4]\n",
      "            else:\n",
      "                high_bound = max(testframe['end_tick'])\n",
      "                stop_early = True\n",
      "        else:\n",
      "            high_bound = max(testframe['end_tick'])\n",
      "        #print \"Starting loop.  Slice = \" + str(slice_counter) + \".  Range : Tick \" + str(low_bound) + \" to \" + str(high_bound) \n",
      "\n",
      "        if len(testframe[(testframe.start_tick > low_bound) & (testframe.start_tick < high_bound)]) != 0:\n",
      "            #don't put anything here if the whole slice is empty or one held note            \n",
      "            slice_list.append([slice_counter,testframe[(testframe.start_tick >= low_bound) & (testframe.start_tick < high_bound)]])\n",
      "        \n",
      "        if stop_early:\n",
      "            #should only hit this condition if the tempo track is longer than the note tracks.\n",
      "            break\n",
      "        \n",
      "        slice_counter += 1\n",
      "    return slice_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function that holds all the calculations that require looping over the whole sample.  For a four-measure sample, calculates the average number of notes sounding simultaneously, both including rests (`avedown`) and skipping rests (`avenonzero`), and the average number of notes that move at once (`MC`).  Also calculates the \"sentence\" of chord strings for NLP chord analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_sample_stats(sample):\n",
      "    this_slice = sample[1]\n",
      "    st = this_slice.min(0)['start_tick']\n",
      "    et = this_slice.max(0)['start_tick']\n",
      "    totaldown = 0\n",
      "    totalticks = et-st\n",
      "    nonzeroticks = 0\n",
      "    this_slice['Norm note'] = this_slice['note_val'] % 12\n",
      "    chord_list = []\n",
      "    old_notes = []\n",
      "    for tk in range(st,et):\n",
      "        #Keys down at once part\n",
      "        ndown = len(this_slice[(this_slice.start_tick < tk) & (this_slice.end_tick > tk)])\n",
      "        #print \"tick = \" + str(tk)\n",
      "        #print str(ndown) + \"keys down\"\n",
      "        totaldown += ndown\n",
      "        if ndown != 0:\n",
      "            nonzeroticks += 1\n",
      "        \n",
      "        #Chord-to-string conversion\n",
      "        notes = this_slice[(this_slice.start_tick < tk) & (this_slice.end_tick > tk)]['Norm note'].ravel()\n",
      "        notes.sort()\n",
      "        if (not np.array_equal(notes,old_notes)) and (not np.array_equal(notes,np.array([]))):\n",
      "            f = list(set(notes))\n",
      "            f.sort()\n",
      "            g = [format(i,'x') for i in f]\n",
      "            h = \"\".join(g)\n",
      "            chord_list.append(h)\n",
      "        old_notes = notes\n",
      "        \n",
      "    if totalticks != 0:\n",
      "        avedown = float(totaldown)/float(totalticks)\n",
      "    else:\n",
      "        avedown = 0\n",
      "    if nonzeroticks != 0:\n",
      "        avenonzero = float(totaldown)/float(nonzeroticks)\n",
      "    else:\n",
      "        avenonzero = 0\n",
      "        \n",
      "    cstring = \" \".join(chord_list)\n",
      "    \n",
      "    \n",
      "    return [avedown,avenonzero,cstring]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The big one!  Loops over all composer directories and all midi files in those directories, reads in each file, and builds the array of features that we will turn into a data frame and use for calculations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_sample_frame(filedir,process_array):\n",
      "    #processing_frame = pd.DataFrame(np.array([]),columns=['Composer','Time sig num','Time sig den','Key sig','Highest note','Lowest note'])    \n",
      "    for composer in os.listdir(filedir):\n",
      "#    print composer\n",
      "        if os.path.isdir(filedir+composer):\n",
      "            for fn in os.listdir(filedir+composer+\"/\"):\n",
      "                if os.path.isfile(filedir+composer+\"/\" + fn) and (fn.endswith(\".mid\") or fn.endswith(\".MID\")):\n",
      "                        pattern = midi.read_midifile(filedir+composer+\"/\" + fn)\n",
      "                        #pattern = midi.read_midifile(\"./Music/Bach/0778.mid\")\n",
      "                        print composer + \"/\" + fn\n",
      "                        \n",
      "                        slice_list = split_on_four_meas(pattern)\n",
      "                        \n",
      "                        for i in slice_list:\n",
      "                            tf = i[1]\n",
      "                            tf['Nlength']=tf['end_tick']-tf['start_tick']\n",
      "                            ngrace = tf[tf['Nlength']<28]['Nlength'].count()\n",
      "                            [avedown_zeros,avedown_nozero,cstring] = calc_sample_stats(i)\n",
      "                            #a = to_next(tf)\n",
      "                            #ngrace = np.count_nonzero(np.logical_and(a>5,a<25))\n",
      "                            process_array.append([composer,max(i[1]['note_val']),min(i[1]['note_val']),ngrace,avedown_zeros,avedown_nozero,fn,cstring])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize and fill the sample array.  Convert it to a pandas data frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_array = []\n",
      "build_sample_frame(filedir,process_array)\n",
      "processing_frame = pd.DataFrame(process_array,columns=['Composer','Highest note','Lowest note','Num ornament','Avg simul notes','Avg simul nonzero notes','fname','Chord string'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'build_sample_frame' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-d4d84bca02aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprocess_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbuild_sample_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiledir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocess_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprocessing_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Composer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Highest note'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Lowest note'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Num ornament'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Avg simul notes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Avg simul nonzero notes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fname'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Chord string'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'build_sample_frame' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tack on a few derived columns and a color column for plotting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def colors(com):\n",
      "    #Convert composer names to an arbitrary integer that can be used to color them in plots.\n",
      "    a = pd.Series(processing_frame['Composer'].ravel()).unique()\n",
      "    for i in range(len(a)):\n",
      "        if a.item(i) == com:\n",
      "            return i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def period(com):\n",
      "    #Get stylistic period just in case we need it.\n",
      "    if com in ('Bach'):\n",
      "        return 'Baroque'\n",
      "    elif com in ('Albeniz','Balakirew','Beethoven','Borodin','Brahms','Burgmueller','Chopin','Debussy','Godowsky','Granados','Grieg','Liszt','Mendelssohn','Moszkowski','Mussorgsky','Rachmaninov','Ravel','Schubert','Schumann','Sinding','Tchaikovsky'):\n",
      "        return 'Romantic'\n",
      "    elif com in ('Mozart','Haydn','Clementi'):\n",
      "        return 'Classical'\n",
      "    else:\n",
      "        return 'Unknown'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame['Note range']=processing_frame['Highest note']-processing_frame['Lowest note']\n",
      "processing_frame['To color'] = processing_frame['Composer'].apply(colors)\n",
      "processing_frame['Period'] = processing_frame['Composer'].apply(period)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dump the entire data frame to a csv file so it can be read back in easily and we only have to do the preprocessing once!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame.to_csv('Music_frame.csv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame = pd.read_csv(\"Music_frame.csv\",sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drop null values from the dataframe - in very rare cases, it is possible to have a completely empty sample, which will result in some `NaN` cells being introduced."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame = processing_frame.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Classifier##\n",
      "\n",
      "Pass your preferred classifier (with any additional arguments) as an argument to the fit wrapper function.\n",
      "\n",
      "**Note on the NLP style treatment of chords:** I've defined a \"chord\" as the set of notes sounding at the same time, not even trying to separate out passing tones.  Then I treat each sample as a \"bag of chords\", analogous to the NLP \"bag of words\" approach.  It's surprising how well it works, given how dumb this approach is in a music context.  Since things like NLP part-of-speech taggers don't really exist for music, I would have to roll my own set of tools to analyze things like chord progressions.  I'll be going back and trying to make this part of the project smarter if I have time; this is an area with major room for improvement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import linear_model, datasets\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "from sklearn import utils\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ad_hoc_features(chordframe):\n",
      "    return chordframe[['Note range','Num ornament','Avg simul nonzero notes']].values\n",
      "    \n",
      "\n",
      "def makefeats(chordframe,v):\n",
      "    a = ad_hoc_features(chordframe)\n",
      "    t = v.transform(chordframe['Chord string']).toarray()\n",
      "    return np.hstack((a,t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiclassfit(chordframe, vectorizer, C = 10, class_weight = 'auto', n_estimators = 10, max_depth=None, min_samples_split = 2, max_f = 1000, maxng = 3):\n",
      "    ng_vectorizer = vectorizer(max_features = max_f, ngram_range = (1,maxng))\n",
      "    count_vec = ng_vectorizer.fit(chordframe['Chord string'])\n",
      "    print \"Vectorization complete.\"\n",
      "    \n",
      "    #X = count_vec.transform(chordframe['Chord string']).toarray()\n",
      "    X = makefeats(chordframe,count_vec)\n",
      "    y = chordframe['To color']\n",
      "    \n",
      "    X,y = utils.shuffle(X,y)\n",
      "    \n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=39)\n",
      "    print \"Test sampling complete.  Building classifier...\"\n",
      "    \n",
      "    #classif=linear_model.LogisticRegression\n",
      "    #classifier = classif(C=C,class_weight = class_weight)\n",
      "    classif = RandomForestClassifier\n",
      "    #classif = svm.SVC\n",
      "    #classifier = classif()\n",
      "    classifier = classif(n_estimators = n_estimators, max_depth=max_depth, min_samples_split = min_samples_split)\n",
      "    #clf = OneVsRestClassifier(classifier).fit(X_train, y_train)\n",
      "    #print \"Out-of-sample classification in progress...\"\n",
      "    #res_p = clf.predict(X_test)\n",
      "    \n",
      "    print \"Cross-validating...\"\n",
      "    scores = cross_validation.cross_val_score(OneVsRestClassifier(classifier), X_train, y_train, cv=5, scoring='accuracy')\n",
      "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    \n",
      "    #print \"Categories for blind sample:\"\n",
      "    #print clf.predict(count_vec.transform(chords_neverseensamp).toarray())\n",
      "    \n",
      "    #percent_correct = 100*np.sum(y_test==res_p)/y_test.shape[0]\n",
      "    #print str(percent_correct) + '% correct.'\n",
      "    \n",
      "    #return metrics.accuracy_score(y_test,res_p)\n",
      "    return scores.mean()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiclassfit(processing_frame,CountVectorizer,n_estimators=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorization complete.\n",
        "Test sampling complete.  Building classifier..."
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 13565 entries, 0 to 13568\n",
        "Data columns (total 12 columns):\n",
        "Unnamed: 0                 13565 non-null int64\n",
        "Composer                   13565 non-null object\n",
        "Highest note               13565 non-null int64\n",
        "Lowest note                13565 non-null int64\n",
        "Num ornament               13565 non-null int64\n",
        "Avg simul notes            13565 non-null float64\n",
        "Avg simul nonzero notes    13565 non-null float64\n",
        "fname                      13565 non-null object\n",
        "Chord string               13565 non-null object\n",
        "Note range                 13565 non-null int64\n",
        "To color                   13565 non-null int64\n",
        "Period                     13565 non-null object\n",
        "dtypes: float64(2), int64(6), object(4)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processing_frame[['Note range','Num ornament','Avg simul nonzero notes']].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[ 45.        ,   0.        ,   1.52033173],\n",
        "       [ 43.        ,   0.        ,   1.52033173],\n",
        "       [ 24.        ,   0.        ,   1.42179968],\n",
        "       ..., \n",
        "       [ 52.        ,   0.        ,   2.51612903],\n",
        "       [ 68.        ,   0.        ,   3.60087559],\n",
        "       [ 76.        ,   0.        ,   6.32170543]])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame = pd.read_csv(\"Music_frame_2.csv\",sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 439 entries, 0 to 438\n",
        "Data columns (total 16 columns):\n",
        "Unnamed: 0                 439 non-null int64\n",
        "Composer                   439 non-null object\n",
        "Highest note               439 non-null int64\n",
        "Lowest note                439 non-null int64\n",
        "Num ornament               439 non-null int64\n",
        "Avg num moving notes       439 non-null float64\n",
        "Avg simul notes            439 non-null float64\n",
        "Avg simul nonzero notes    439 non-null float64\n",
        "fname                      439 non-null object\n",
        "Chord interval string      439 non-null object\n",
        "Folded chord string        439 non-null object\n",
        "Ticks in sample            439 non-null int64\n",
        "Note range                 439 non-null int64\n",
        "To color                   439 non-null int64\n",
        "Period                     439 non-null object\n",
        "Frac notes moving          439 non-null float64\n",
        "dtypes: float64(4), int64(7), object(5)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame['Frac notes moving'] = piece_frame['Avg num moving notes']/piece_frame['Avg simul nonzero notes']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ad_hoc_features(chordframe):\n",
      "    return chordframe[['Note range','Num ornament','Avg simul nonzero notes','Frac notes moving','Avg num moving notes','Ticks in sample']].values\n",
      "    \n",
      "\n",
      "def makefeats(chordframe,v):\n",
      "    a = ad_hoc_features(chordframe)\n",
      "    t = v.transform(chordframe['Chord interval string']).toarray()\n",
      "    return np.hstack((a,t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multiclassfit(chordframe, vectorizer, C = 10, class_weight = 'auto', n_estimators = 10, max_depth=None, min_samples_split = 2, max_f = 1000, maxng = 3):\n",
      "    ng_vectorizer = vectorizer(max_features = max_f, ngram_range = (1,maxng))\n",
      "    count_vec = ng_vectorizer.fit(chordframe['Chord interval string'])\n",
      "    print \"Vectorization complete.\"\n",
      "    \n",
      "    #X = count_vec.transform(chordframe['Chord string']).toarray()\n",
      "    X = makefeats(chordframe,count_vec)\n",
      "    y = chordframe['Pnum']\n",
      "    \n",
      "    X,y = utils.shuffle(X,y)\n",
      "    \n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=39)\n",
      "    print \"Test sampling complete.  Building classifier...\"\n",
      "    \n",
      "    #classif=linear_model.LogisticRegression\n",
      "    #classifier = classif(C=C,class_weight = class_weight)\n",
      "    classif = RandomForestClassifier\n",
      "    #classif = svm.SVC\n",
      "    classifier = classif()\n",
      "    #classifier = classif(n_estimators = n_estimators, max_depth=max_depth, min_samples_split = min_samples_split)\n",
      "    #clf = OneVsRestClassifier(classifier).fit(X_train, y_train)\n",
      "    #print \"Out-of-sample classification in progress...\"\n",
      "    #res_p = clf.predict(X_test)\n",
      "    \n",
      "    print \"Cross-validating...\"\n",
      "    scores = cross_validation.cross_val_score(OneVsRestClassifier(classifier), X_train, y_train, cv=5, scoring='accuracy')\n",
      "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    \n",
      "    #print \"Categories for blind sample:\"\n",
      "    #print clf.predict(count_vec.transform(chords_neverseensamp).toarray())\n",
      "    \n",
      "    #percent_correct = 100*np.sum(y_test==res_p)/y_test.shape[0]\n",
      "    #print str(percent_correct) + '% correct.'\n",
      "    \n",
      "    #return metrics.accuracy_score(y_test,res_p)\n",
      "    return scores.mean()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiclassfit(piece_frame, CountVectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorization complete.\n",
        "Test sampling complete.  Building classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Cross-validating...\n",
        "Accuracy: 0.88 (+/- 0.07)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0.87742454728370212"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(len(piece_frame[piece_frame['Period']=='Classical']))/float(len(piece_frame))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.13439635535307518"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pnum(p):\n",
      "    #Get stylistic period just in case we need it.\n",
      "    if p=='Baroque':\n",
      "        return 0\n",
      "    elif p=='Classical':\n",
      "        return 1\n",
      "    elif p=='Romantic':\n",
      "        return 2\n",
      "    else:\n",
      "        return 'Unknown'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "piece_frame['Pnum'] = piece_frame['Period'].apply(pnum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}